{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"workspaceName": {
			"type": "string",
			"metadata": "Workspace name",
			"defaultValue": "ivs-synapse"
		},
		"AdventureWorksSQL_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'AdventureWorksSQL'"
		},
		"ivs-synapse-WorkspaceDefaultSqlServer_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'ivs-synapse-WorkspaceDefaultSqlServer'",
			"defaultValue": "Integrated Security=False;Encrypt=True;Connection Timeout=30;Data Source=tcp:ivs-synapse.sql.azuresynapse.net,1433;Initial Catalog=@{linkedService().DBName}"
		},
		"ivs_od_sqlpool_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'ivs_od_sqlpool'",
			"defaultValue": "Integrated Security=False;Encrypt=True;Connection Timeout=30;Data Source=ivs-synapse-ondemand.sql.azuresynapse.net;Initial Catalog=ivs_od_sqlpool"
		},
		"serverless_ARIR_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'serverless_ARIR'",
			"defaultValue": "Integrated Security=False;Encrypt=True;Connection Timeout=30;Data Source=ivs-synapse-ondemand.sql.azuresynapse.net;Initial Catalog=@{linkedService().p_database}"
		},
		"template_dedicated_ARIR_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'template_dedicated_ARIR'",
			"defaultValue": "Integrated Security=False;Encrypt=True;Connection Timeout=30;Data Source=ivs-synapse.sql.azuresynapse.net;Initial Catalog=ivssql"
		},
		"azuresynapse_REST_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "@{concat('https://', linkedService().p_workspace, '.dev.azuresynapse.net')}"
		},
		"azuresynapse_REST_properties_typeProperties_aadResourceId": {
			"type": "string",
			"defaultValue": "https://dev.azuresynapse.net/"
		},
		"ivs-synapse-WorkspaceDefaultStorage_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://ivsdatastorage.dfs.core.windows.net"
		},
		"template_kv_properties_typeProperties_baseUrl": {
			"type": "string",
			"defaultValue": "https://ivs-dwh-kv.vault.azure.net/"
		},
		"templatecurst_ARIR_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://ivscur.dfs.core.windows.net/"
		},
		"templateenrst_ARIR_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://ivsenr.dfs.core.windows.net/"
		},
		"templaterawst_ARIR_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://ivsraw.dfs.core.windows.net/"
		}
	},
	"variables": {
		"workspaceId": "[concat('Microsoft.Synapse/workspaces/', parameters('workspaceName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('workspaceName'), '/FromDeltaToWideDelta')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "GetTargetDeltaMetadata",
						"type": "GetMetadata",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 2,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "GenericEnrichedJsonFolder",
								"type": "DatasetReference",
								"parameters": {
									"p_container": {
										"value": "@pipeline().parameters.c_trg_container",
										"type": "Expression"
									},
									"p_folder": {
										"value": "@concat(pipeline().parameters.c_trg_root_folder, '/', pipeline().parameters.c_trg_object)",
										"type": "Expression"
									}
								}
							},
							"fieldList": [
								"exists"
							],
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							},
							"formatSettings": {
								"type": "JsonReadSettings"
							}
						}
					},
					{
						"name": "EnrichedLakeSettings",
						"type": "WebActivity",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 2,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"method": "GET",
							"headers": {},
							"url": {
								"value": "@concat('https://', pipeline().DataFactory, '.dev.azuresynapse.net/linkedservices/', pipeline().parameters.c_trg_linked_service, '?api-version=2020-12-01')",
								"type": "Expression"
							},
							"connectVia": {
								"referenceName": "SHIR",
								"type": "IntegrationRuntimeReference"
							},
							"authentication": {
								"type": "MSI",
								"resource": "https://dev.azuresynapse.net/"
							}
						}
					},
					{
						"name": "SourceQueryParts",
						"type": "Script",
						"dependsOn": [
							{
								"activity": "GetTargetDeltaMetadata",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "Set v_cdc",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 2,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"linkedServiceName": {
							"referenceName": "serverless_ARIR",
							"type": "LinkedServiceReference",
							"parameters": {
								"p_database": {
									"value": "@pipeline().parameters.c_serverless_db",
									"type": "Expression"
								}
							}
						},
						"typeProperties": {
							"scripts": [
								{
									"type": "Query",
									"text": {
										"value": "declare @SQLScript nvarchar(max)\n\nwith src as (\nselect *\n   FROM OPENJSON('@{replace(string(pipeline().parameters.p_src_objects), '''', '''''')}') \n   WITH (\n    iteration integer '$.iteration',\n    object NVARCHAR(max) '$.object',\n    dbschema NVARCHAR(max) '$.schema',\n    alias NVARCHAR(max) '$.alias',\n    trgKeyCol NVARCHAR(max) '$.trgKeyCol',\n    cdcCol NVARCHAR(max) '$.cdcCol',\n    selectCols NVARCHAR(max) '$.selectCols',\n    joinCondition NVARCHAR(max) '$.joinCondition',\n    joinType NVARCHAR(max) '$.joinType',\n    joinOrder integer '$.joinOrder')\n),\nkcl as (    select src.*, k.keyCols from src left outer join(select iteration, string_agg(coalesce(alias, object) + '_' + replace(replace(trgKeyCol, ' ', ''), ',', ', ' + coalesce(alias, object) + '_'), ', ') keyCols\n   FROM OPENJSON('@{replace(string(pipeline().parameters.p_src_objects), '''', '''''')}') \n   WITH (\n    iteration integer '$.iteration',\n    object NVARCHAR(max) '$.object',\n    dbschema NVARCHAR(max) '$.schema',\n    alias NVARCHAR(max) '$.alias',\n    trgKeyCol NVARCHAR(max) '$.trgKeyCol',\n    cdcCol NVARCHAR(max) '$.cdcCol',\n    selectCols NVARCHAR(max) '$.selectCols',\n    joinCondition NVARCHAR(max) '$.joinCondition',\n    joinType NVARCHAR(max) '$.joinType',\n    joinOrder integer '$.joinOrder')\n\twhere iteration = 0 group by iteration) k \non 1 = 1),\nrpl as (select kcl.*, r.replace_start, r.replace_end from kcl join\n(select iteration, string_agg('replace(', '') replace_start, \nstring_agg(', ''' + case when left(trim(object), 1) = '(' and right(trim(object), 1) = ')' \nthen alias + '.' else object + '.' end + ''', ''' + coalesce(alias, object) + '.'')', '') replace_end\n   FROM OPENJSON('@{replace(string(pipeline().parameters.p_src_objects), '''', '''''')}') \n   WITH (\n    iteration integer '$.iteration',\n    object NVARCHAR(max) '$.object',\n    dbschema NVARCHAR(max) '$.schema',\n    alias NVARCHAR(max) '$.alias',\n    trgKeyCol NVARCHAR(max) '$.trgKeyCol',\n    cdcCol NVARCHAR(max) '$.cdcCol',\n    selectCols NVARCHAR(max) '$.selectCols',\n    joinCondition NVARCHAR(max) '$.joinCondition',\n    joinType NVARCHAR(max) '$.joinType',\n    joinOrder integer '$.joinOrder')\n\tgroup by iteration) r\n\ton r.iteration = kcl.iteration)\nselect @SQLScript = STRING_AGG(cast(SQLScript as nvarchar(max)), ' union ') from (\nselect 'select ' + cast(rpl.iteration as varchar(10)) + ' as iteration, ' +\ncoalesce('''' + replace(rpl.object, char(39), char(39) + char(39)) + '''', 'null') + ' as object, ' +\ncoalesce('''' + replace(rpl.dbschema, char(39), char(39) + char(39)) + '''', 'null') + ' as dbschema, ' +\ncoalesce('''' + replace(rpl.alias, char(39), char(39) + char(39)) + '''', 'null') + ' as alias, ' +\ncoalesce('''' + replace(rpl.trgKeyCol, char(39), char(39) + char(39)) + '''', 'null') + ' as trgKeyCol, ' +\ncoalesce('''' + replace(rpl.cdcCol, char(39), char(39) + char(39)) + '''', 'null') + ' as cdcCol, ' +\ncoalesce('''' + replace(rpl.selectCols, char(39), char(39) + char(39)) + '''', 'null') + ' as selectCols, ' +\ncoalesce('''' + replace(rpl.joinCondition, char(39), char(39) + char(39)) + '''', 'null') + ' as joinCondition, ' +\ncoalesce('''' + replace(rpl.joinType, char(39), char(39) + char(39)) + '''', 'null') + ' as joinType, ' +\ncast(rpl.joinOrder as varchar(10)) + ' as joinOrder, ' +\ncoalesce('''' + replace(rpl.replace_start, char(39), char(39) + char(39)) + '''', 'null') + ' as replaceStart, ' +\ncoalesce('''' + replace(rpl.replace_end, char(39), char(39) + char(39)) + '''', 'null') + ' as replaceEnd, ' +\ncoalesce('''' + replace(rpl.keyCols, char(39), char(39) + char(39)) + '''', 'null') + ' as keyColsStatement, ' +\ncoalesce('''' + replace(CASE trim(rpl.selectCols)\n\t\t\t\tWHEN '*' THEN (select string_agg(cast('<obj>.' + c.name + ' as <obj>_' + c.name as nvarchar(max)), ', ') \n\t\t\t\t\tfrom sys.columns c \n\t\t\t\t\tjoin sys.views v on c.object_id = v.object_id\n\t\t\t\t\tjoin sys.schemas s on s.schema_id = v.schema_id\n\t\t\t\t\twhere v.name = rpl.object and s.name = rpl.dbschema)\n\t\t\t\tELSE (select string_agg(cast('<obj>.' + value + ' as <obj>_' + value as nvarchar(max)), ', ') \n\t\t\t\t\tfrom string_split(replace(replace(rpl.selectCols, char(39), char(39) + char(39)), ' ', ''), ',')\n\t\t\t\t\twhere lower(value) <> rpl.cdcCol) + coalesce(', ' + cast('<obj>.' + rpl.cdcCol + ' as <obj>_' + rpl.cdcCol as nvarchar(max)), '') END, '<obj>', coalesce(rpl.alias, rpl.object)) + '''', 'null') + ' as selectStatement, ' +\ncoalesce('''' + CASE WHEN left(trim(object), 1) = '(' and right(trim(object), 1) = ')' \n\t\t\t\tTHEN replace(replace(object, char(39), char(39) + char(39)), '<schema>', rpl.dbschema) + ' ' + alias\n\t\t\t\tELSE replace(rpl.object, rpl.object, rpl.dbschema + '.' + rpl.object + ' as ' + coalesce(rpl.alias, rpl.object)) \n\t\t\t\tEND + '''', 'null') + ' as fromStatement, ' + \ncoalesce('' + rpl.replace_start + char(39) + \nreplace(CASE WHEN rpl.iteration = 0 THEN rpl.joinCondition ELSE replace(rpl.joinCondition, '<trgtab>', '_stg') END, char(39), char(39) + char(39)) + char(39) + rpl.replace_end, 'null') + ' as joinStatement, ' + \ncoalesce('''' + coalesce(alias, object) +'.' + rpl.cdcCol + ' > '''''' + ' + coalesce('cast(max(' + @{if(empty(pipeline().parameters.p_datetime_from), if(activity('GetTargetDeltaMetadata').output.exists, 'dbSys.colName', '''''''1900-01-01'''''''), concat('''', pipeline().parameters.p_datetime_from, ''''))} + ') as varchar(50)) ', '''1900-01-01''') + ' + ''''''''', 'null') + ' as whereStatement' +\ncase when dbSys.colName is null or @{if(activity('GetTargetDeltaMetadata').output.exists, '1=0', '1=1')} then '' else ' from @{pipeline().parameters.c_trg_schema}.@{pipeline().parameters.c_trg_object}' end as SQLScript\nfrom rpl\nleft outer join \n(select c.name as colName, v.name as viewName, s.name as schemaName\nfrom sys.columns c\njoin sys.views v on c.object_id = v.object_id \njoin sys.schemas s on v.schema_id = s.schema_id) dbSys \non dbSys.ColName = coalesce(rpl.alias, rpl.object) + '_' + cdcCol\nand dbSys.schemaName = '@{pipeline().parameters.c_trg_schema}'\nand dbSys.viewName = '@{pipeline().parameters.c_trg_object}') q\n\nexec('select * from (' + @SQLScript + ') q order by iteration, joinOrder')",
										"type": "Expression"
									}
								}
							],
							"scriptBlockExecutionTimeout": "02:00:00"
						}
					},
					{
						"name": "SourceQuery",
						"type": "Script",
						"dependsOn": [
							{
								"activity": "SourceQueryParts",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 2,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"linkedServiceName": {
							"referenceName": "serverless_ARIR",
							"type": "LinkedServiceReference",
							"parameters": {
								"p_database": {
									"value": "@pipeline().parameters.c_serverless_db",
									"type": "Expression"
								}
							}
						},
						"typeProperties": {
							"scripts": [
								{
									"type": "Query",
									"text": {
										"value": "declare @SQLScript nvarchar(max)\n\nSELECT @SQLScript = STRING_AGG('select ' + cast(iteration as nvarchar(max)) + ' as iteration, ''' \n+ keyCols + ''' as keyCols, ' + sourceQuery + ' as sourceQuery, ' + pruningQuery + ' as pruningQuery', ' union ') FROM (\nSELECT iteration, min(keyColsStatement) as keyCols, '''select '''\n+ coalesce(' + ''@{pipeline().parameters.c_trg_alias}.' + replace(replace(replace(min(case iteration when 0 then null else keyColsStatement end), ' ', ''), ',', ', @{pipeline().parameters.c_trg_alias}.'), char(39), char(39) + char(39)) + ', ''', '')\n+ (' + ''' + replace(STRING_AGG(selectStatement, ', '), char(39), char(39) + char(39)) + '''')\n+ coalesce(' + '', '' + ' + CASE WHEN iteration = 0 THEN min(replaceStart) + ''''\n+ replace('@{replace(pipeline().parameters.c_partition_formula, '''', '''''')}', char(39), char(39) + char(39)) + '''' + min(replaceEnd) ELSE '''@{pipeline().parameters.c_trg_alias}.@{pipeline().parameters.c_trg_partition_col}''' END + ' + '' as @{pipeline().parameters.c_trg_partition_col}''', '')\n+ @{if(empty(pipeline().parameters.c_trg_cdc_col), '', concat(''' + '''', cast(''''''''', variables('v_cdc'), ''''''''' as datetime2) as ', pipeline().parameters.c_trg_cdc_col, ''''''''))}\n+ coalesce(' + '' from ' + CASE WHEN iteration = 0 THEN '' ELSE '@{concat(pipeline().parameters.c_trg_schema, '.', pipeline().parameters.c_trg_object, ' as ', pipeline().parameters.c_trg_alias)} ' END + replace(STRING_AGG(coalesce(coalesce(joinType + ' join ', '') + fromStatement, '')\n+ coalesce(' on ' +  joinStatement, ''), ' '), char(39), char(39) + char(39)) + '''', '')\n+ coalesce(' + '' where (' + replace(STRING_AGG(whereStatement, ' or ') + CASE WHEN iteration = 0 THEN '' ELSE ' or @{pipeline().parameters.c_trg_alias}.@{pipeline().parameters.c_trg_cdc_col} = ''@{variables('v_cdc')}''' END, char(39), char(39) + char(39)) + ')''', '') as sourceQuery,\n'''select distinct(''' + coalesce(' + ' + CASE WHEN iteration = 0 THEN min(replaceStart) + '''' + replace('@{replace(pipeline().parameters.c_partition_formula, '''', '''''')}', char(39), char(39) + char(39)) + '''' + min(replaceEnd) ELSE '''_stg._PARTITION''' END + ' + '') as _PARTITION''', '') \n+ coalesce(' + '' from ' + CASE WHEN iteration = 0 THEN '' ELSE '@{concat(pipeline().parameters.c_trg_schema, '.', pipeline().parameters.c_trg_object, ' as ', pipeline().parameters.c_trg_alias)} ' END + replace(STRING_AGG(coalesce(coalesce(joinType + ' join ', '') + fromStatement, '')\n+ coalesce(' on ' +  joinStatement, ''), ' '), char(39), char(39) + char(39)) + '''', '')\n+ coalesce(' + '' where (' + replace(STRING_AGG(whereStatement, ' or ') + CASE WHEN iteration = 0 THEN '' ELSE ' or @{pipeline().parameters.c_trg_alias}.@{pipeline().parameters.c_trg_cdc_col} = ''@{variables('v_cdc')}''' END, char(39), char(39) + char(39)) + ')''', '') as pruningQuery\nFROM OPENJSON('@{replace(string(activity('SourceQueryParts').output.resultSets[0].rows), '''', '''''')}')\nWITH (\n    iteration integer '$.iteration',\n    object NVARCHAR(max) '$.object',\n    alias NVARCHAR(max) '$.alias',\n    trgKeyCol NVARCHAR(max) '$.trgKeyCol',\n    cdcCol NVARCHAR(max) '$.cdcCol',\n    selectCols NVARCHAR(max) '$.selectCols',\n    joinCondition NVARCHAR(max) '$.joinCondition',\n    joinType NVARCHAR(max) '$.joinType',\n    joinOrder integer '$.joinOrder',\n    replaceStart NVARCHAR(max) '$.replaceStart',\n    replaceEnd NVARCHAR(max) '$.replaceEnd',\n    keyColsStatement NVARCHAR(max) '$.keyColsStatement',\n    selectStatement NVARCHAR(max) '$.selectStatement',\n    fromStatement NVARCHAR(max) '$.fromStatement',\n    joinStatement NVARCHAR(max) '$.joinStatement',\n    whereStatement NVARCHAR(max) '$.whereStatement')\ngroup by iteration\n) q\n\nexec(@SQLScript)",
										"type": "Expression"
									}
								}
							],
							"scriptBlockExecutionTimeout": "02:00:00"
						}
					},
					{
						"name": "Set v_cdc",
						"type": "SetVariable",
						"dependsOn": [],
						"policy": {
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"variableName": "v_cdc",
							"value": {
								"value": "@utcNow()",
								"type": "Expression"
							}
						}
					},
					{
						"name": "ForEachIteration",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "SourceQuery",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "EnrichedLakeSettings",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('SourceQuery').output.resultSets[0].rows",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "FromDeltaToWideDelta",
									"type": "ExecuteDataFlow",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 2,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataflow": {
											"referenceName": "FromDeltaToWideDelta",
											"type": "DataFlowReference",
											"parameters": {
												"c_trg_object": {
													"value": "'@{pipeline().parameters.c_trg_object}'",
													"type": "Expression"
												},
												"c_trg_container": {
													"value": "'@{pipeline().parameters.c_trg_container}'",
													"type": "Expression"
												},
												"c_trg_root_folder": {
													"value": "'@{pipeline().parameters.c_trg_root_folder}'",
													"type": "Expression"
												},
												"p_keyCols": {
													"value": "'@{item().keyCols}'",
													"type": "Expression"
												},
												"p_source_query": {
													"value": "@concat('\"', item().sourceQuery, '\"')",
													"type": "Expression"
												},
												"p_pruning_query": {
													"value": "@concat('\"', item().pruningQuery, '\"')",
													"type": "Expression"
												},
												"c_trg_partition_col": {
													"value": "'@{pipeline().parameters.c_trg_partition_col}'",
													"type": "Expression"
												},
												"p_iteration": {
													"value": "@item().iteration",
													"type": "Expression"
												}
											},
											"datasetParameters": {
												"sourceWide": {
													"p_database": {
														"value": "@pipeline().parameters.c_serverless_db",
														"type": "Expression"
													},
													"p_schema": "dbo",
													"p_table": "dummy"
												},
												"sourcePartitionPruning": {
													"p_database": {
														"value": "@pipeline().parameters.c_serverless_db",
														"type": "Expression"
													},
													"p_schema": "dbo",
													"p_table": "dummy"
												},
												"sinkWide": {},
												"sinkPartitionPruning": {}
											}
										},
										"staging": {},
										"compute": {
											"coreCount": 8,
											"computeType": "General"
										},
										"traceLevel": "Fine"
									}
								},
								{
									"name": "CreateTargetView",
									"type": "Script",
									"dependsOn": [
										{
											"activity": "FromDeltaToWideDelta",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 2,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "serverless_ARIR",
										"type": "LinkedServiceReference",
										"parameters": {
											"p_database": {
												"value": "@pipeline().parameters.c_serverless_db",
												"type": "Expression"
											}
										}
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "Query",
												"text": {
													"value": "create or alter view @{pipeline().parameters.c_trg_schema}.@{pipeline().parameters.c_trg_object} as\nselect * from OPENROWSET(\n        BULK '@{activity('EnrichedLakeSettings').output.properties.typeProperties.url}@{if(endswith(activity('EnrichedLakeSettings').output.properties.typeProperties.url, '/'), '', '/')}@{pipeline().parameters.c_trg_container}/@{pipeline().parameters.c_trg_root_folder}/@{pipeline().parameters.c_trg_object}/',\n        FORMAT = 'DELTA'\n    ) AS [result]",
													"type": "Expression"
												}
											}
										],
										"scriptBlockExecutionTimeout": "02:00:00"
									}
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"p_src_objects": {
						"type": "array",
						"defaultValue": [
							{
								"iteration": 0,
								"object": "dataflows_datasets_REST_API",
								"schema": "enr",
								"alias": "dataflows_datasets",
								"trgKeyCol": "name,propertiestypePropertiessourcesdatasetreferenceName",
								"cdcCol": "enrTimestamp",
								"selectCols": "*",
								"joinCondition": null,
								"joinType": null,
								"joinOrder": 0
							},
							{
								"iteration": 0,
								"object": "dataflows_REST_API",
								"schema": "enr",
								"alias": "dataflows",
								"trgKeyCol": null,
								"cdcCol": "enrTimestamp",
								"selectCols": "*",
								"joinCondition": "dataflows.name = dataflows_datasets.name",
								"joinType": "left outer",
								"joinOrder": 1
							},
							{
								"iteration": 0,
								"object": "datasets_REST_API",
								"schema": "enr",
								"alias": "datasets",
								"trgKeyCol": null,
								"cdcCol": "enrTimestamp",
								"selectCols": "*",
								"joinCondition": "datasets.name = dataflows_datasets.propertiestypePropertiessourcesdatasetreferenceName",
								"joinType": "left outer",
								"joinOrder": 2
							}
						]
					},
					"p_datetime_from": {
						"type": "string"
					},
					"c_trg_object": {
						"type": "string",
						"defaultValue": "dataflows_datasets_WIDE"
					},
					"c_trg_container": {
						"type": "string",
						"defaultValue": "template"
					},
					"c_trg_root_folder": {
						"type": "string",
						"defaultValue": "FromDeltaToWideDelta"
					},
					"c_serverless_db": {
						"type": "string",
						"defaultValue": "templateDB"
					},
					"c_trg_schema": {
						"type": "string",
						"defaultValue": "enr"
					},
					"c_partition_formula": {
						"type": "string",
						"defaultValue": "dataflows_datasets_REST_API.DELTA_PARTITION"
					},
					"c_trg_partition_col": {
						"type": "string",
						"defaultValue": "_PARTITION"
					},
					"c_trg_cdc_col": {
						"type": "string",
						"defaultValue": "_DSS_UPDATE_TIME"
					},
					"c_trg_alias": {
						"type": "string",
						"defaultValue": "_stg"
					},
					"c_trg_linked_service": {
						"type": "string",
						"defaultValue": "templateenrst_ARIR"
					}
				},
				"variables": {
					"v_master_query_parts": {
						"type": "Array"
					},
					"v_slave_row_count": {
						"type": "Integer"
					},
					"v_cdc": {
						"type": "String"
					}
				},
				"folder": {
					"name": "Templates"
				},
				"annotations": [],
				"lastPublishTime": "2024-01-24T18:40:41Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/GenericEnrichedJsonFolder')]",
				"[concat(variables('workspaceId'), '/integrationRuntimes/SHIR')]",
				"[concat(variables('workspaceId'), '/linkedServices/serverless_ARIR')]",
				"[concat(variables('workspaceId'), '/dataflows/FromDeltaToWideDelta')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/FromJsonToDeltaParquet')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "ForEachDataset",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "GenericRawJson linked service",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "GenericEnrichedParquet linked service",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "Set v_dss_update_time",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@pipeline().parameters.p_datasets",
								"type": "Expression"
							},
							"isSequential": false,
							"activities": [
								{
									"name": "copyFileList",
									"type": "Copy",
									"dependsOn": [
										{
											"activity": "DatetimeFrom",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 2,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "SqlDWSource",
											"sqlReaderQuery": {
												"value": "@concat('SELECT STRING_AGG(cast(jsonName as varchar(max)), char(10)) ListOfFiles ',\n        'FROM ( SELECT right(result.filepath(), ',\n        'len(result.filepath()) - charindex(''', \n        pipeline().parameters.c_raw_root_folder, \n        ''', result.filepath()) + 1) jsonName, max(',\n        item().keyCol, ') ', item().keyCol, ' FROM OPENROWSET(',\n        'BULK ''', activity('GenericRawJson linked service').output.properties.typeProperties.url, \n        pipeline().parameters.c_raw_container, '/', \n        pipeline().parameters.c_raw_root_folder, '/',\n        item().target, '/*.json'',  FORMAT = ''CSV'', FIELDQUOTE = ''0x0b'', ',\n        'FIELDTERMINATOR =''0x0b'', ROWTERMINATOR = ''\\n'') ',\n        'WITH (jsonContent nvarchar(MAX)) ',\n        'AS [result] CROSS apply ',\n        'openjson(JSON_QUERY(jsonContent, ''$.value'')) ',\n        'WITH (', item().keyCol, ' nvarchar(1000) ''$.\"',\n        item().keyCol, '\"'') WHERE reverse(substring(reverse(result.filepath()), 1, charindex(''/'', reverse(result.filepath())) - 1))',\n        if(\n                not(empty(pipeline().parameters.p_datetime_to)), \n                ' between ',\n                ' >= '\n        ),\n        '''', item().target, '_', \n        activity('DatetimeFrom').output.resultSets[0].rows[0].CDCTimestamp, '.json''',\n        if(not(empty(pipeline().parameters.p_datetime_to)), \n            concat(' and ''', item().target, '_', \n                replace(replace(replace(replace(replace(\n                    formatDateTime(\n                        pipeline().parameters.p_datetime_to, \n                        'yyyy-MM-ddTHH:mm:ss.fffffffZ'\n                    ), \n                    '0000Z', 'Z'), '000Z', 'Z'), '00Z', 'Z'), '0Z', 'Z'), '.Z', 'Z'\n                ), \n                '.json'''\n            ), \n            ''\n        ), \n        ' GROUP BY result.filepath()) q'\n)",
												"type": "Expression"
											},
											"queryTimeout": "02:00:00",
											"partitionOption": "None"
										},
										"sink": {
											"type": "DelimitedTextSink",
											"storeSettings": {
												"type": "AzureBlobFSWriteSettings"
											},
											"formatSettings": {
												"type": "DelimitedTextWriteSettings",
												"quoteAllText": true,
												"fileExtension": ".txt"
											}
										},
										"enableStaging": false,
										"translator": {
											"type": "TabularTranslator",
											"mappings": [
												{
													"source": {
														"name": "ListOfFiles",
														"physicalType": "nvarchar"
													},
													"sink": {
														"ordinal": 1
													}
												}
											],
											"typeConversion": true,
											"typeConversionSettings": {
												"allowDataTruncation": true,
												"treatBooleanAsNumber": false
											}
										}
									},
									"inputs": [
										{
											"referenceName": "GenericServerlessSQL",
											"type": "DatasetReference",
											"parameters": {
												"p_database": {
													"value": "@pipeline().parameters.c_serverless_db",
													"type": "Expression"
												},
												"p_schema": "dummy",
												"p_table": "master"
											}
										}
									],
									"outputs": [
										{
											"referenceName": "GenericRawCSV_NoHeaderNoQuote",
											"type": "DatasetReference",
											"parameters": {
												"p_container": {
													"value": "@pipeline().parameters.c_raw_monitoring_container",
													"type": "Expression"
												},
												"p_folder": {
													"value": "@concat(pipeline().parameters.c_raw_monitoring_folder, '/',\n    pipeline().parameters.c_raw_root_folder, '/', \n    item().target)",
													"type": "Expression"
												},
												"p_file": {
													"value": "@pipeline().parameters.c_file_list_blob",
													"type": "Expression"
												}
											}
										}
									]
								},
								{
									"name": "countRows",
									"type": "Script",
									"dependsOn": [
										{
											"activity": "DatetimeFrom",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 2,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "serverless_ARIR",
										"type": "LinkedServiceReference",
										"parameters": {
											"p_database": "master"
										}
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "Query",
												"text": {
													"value": "@concat('select count(*) countRows FROM OPENROWSET(',\n        'BULK ''', activity('GenericRawJson linked service').output.properties.typeProperties.url, \n        pipeline().parameters.c_raw_container, '/', \n        pipeline().parameters.c_raw_root_folder, '/',\n        item().target, '/*.json'',  FORMAT = ''CSV'', FIELDQUOTE = ''0x0b'', ',\n        'FIELDTERMINATOR =''0x0b'', ROWTERMINATOR = ''\\n'') ',\n        'WITH (jsonContent nvarchar(MAX)) ',\n        'AS [result] CROSS apply ',\n        'openjson(JSON_QUERY(jsonContent, ''$.value'')) ',\n        'WITH (', item().keyCol, ' nvarchar(1000) ''$.\"',\n        item().keyCol, '\"'')  WHERE reverse(substring(reverse(result.filepath()), 1, charindex(''/'', reverse(result.filepath())) - 1))',\n        if(not(empty(pipeline().parameters.p_datetime_to)), \n           ' between ',\n           ' >= '),\n        '''', item().target, '_', \n        activity('DatetimeFrom').output.resultSets[0].rows[0].CDCTimestamp, '.json''',\n        if(not(empty(pipeline().parameters.p_datetime_to)), \n            concat(' and ''', item().target, '_', \n                replace(replace(replace(replace(replace(\n                    formatDateTime(\n                        pipeline().parameters.p_datetime_to, \n                        'yyyy-MM-ddTHH:mm:ss.fffffffZ'\n                    ), \n                    '0000Z', 'Z'), '000Z', 'Z'), '00Z', 'Z'), '0Z', 'Z'), '.Z', 'Z'\n                ), \n                '.json'''\n            ), \n            ''\n        )\n)",
													"type": "Expression"
												}
											}
										],
										"scriptBlockExecutionTimeout": "02:00:00"
									}
								},
								{
									"name": "switchTypes",
									"type": "Switch",
									"dependsOn": [
										{
											"activity": "copyFileList",
											"dependencyConditions": [
												"Succeeded"
											]
										},
										{
											"activity": "countRows",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"userProperties": [],
									"typeProperties": {
										"on": {
											"value": "@if(greater(activity('countRows').output.resultSets[0].rows[0].countRows, 0),\nitem().type, 'none')",
											"type": "Expression"
										},
										"cases": [
											{
												"value": "relationsMM",
												"activities": [
													{
														"name": "FromJsonToDeltaParquet_RelationsMM",
														"type": "ExecuteDataFlow",
														"dependsOn": [],
														"policy": {
															"timeout": "0.12:00:00",
															"retry": 2,
															"retryIntervalInSeconds": 30,
															"secureOutput": false,
															"secureInput": false
														},
														"userProperties": [],
														"typeProperties": {
															"dataflow": {
																"referenceName": "FromJsonToDeltaParquet_RelationsMM",
																"type": "DataFlowReference",
																"parameters": {
																	"c_target_container": {
																		"value": "'@{pipeline().parameters.c_enriched_container}'",
																		"type": "Expression"
																	},
																	"c_target_folder": {
																		"value": "'@{concat(pipeline().parameters.c_enriched_root_folder, '/',\nitem().target)}'",
																		"type": "Expression"
																	},
																	"c_key_column_name": {
																		"value": "'@{item().keyCol}'",
																		"type": "Expression"
																	},
																	"c_cdc_column_name": {
																		"value": "'@{coalesce(item().cdcCol, 'fileName')}'",
																		"type": "Expression"
																	},
																	"c_enriched_cdc_column": {
																		"value": "'@{pipeline().parameters.c_enriched_cdc_column}'",
																		"type": "Expression"
																	},
																	"c_relation_column_name": {
																		"value": "'@{item().relCol}'",
																		"type": "Expression"
																	},
																	"p_partition_formula": {
																		"value": "@concat('\"', item().partitionFormula, '\"')",
																		"type": "Expression"
																	},
																	"p_dss_update_time": {
																		"value": "'@{formatDateTime(variables('v_dss_update_time'), 'yyyy-MM-ddTHH:mm:ssZ')}'",
																		"type": "Expression"
																	},
																	"c_raw_cdc_column": {
																		"value": "'@{pipeline().parameters.c_raw_cdc_column}'",
																		"type": "Expression"
																	}
																},
																"datasetParameters": {
																	"RawDataset": {
																		"p_container": {
																			"value": "@pipeline().parameters.c_raw_monitoring_container",
																			"type": "Expression"
																		},
																		"p_folder": {
																			"value": "@concat(pipeline().parameters.c_raw_monitoring_folder, '/', \npipeline().parameters.c_raw_root_folder, '/',\nitem().target)",
																			"type": "Expression"
																		},
																		"p_file": {
																			"value": "@concat(pipeline().parameters.c_file_list_blob, '.csv')",
																			"type": "Expression"
																		}
																	},
																	"PartitionPruning": {
																		"p_container": {
																			"value": "@pipeline().parameters.c_raw_monitoring_container",
																			"type": "Expression"
																		},
																		"p_folder": {
																			"value": "@concat(pipeline().parameters.c_raw_monitoring_folder, '/', \npipeline().parameters.c_raw_root_folder, '/',\nitem().target)",
																			"type": "Expression"
																		},
																		"p_file": {
																			"value": "@concat(pipeline().parameters.c_file_list_blob, '.csv')",
																			"type": "Expression"
																		}
																	},
																	"dummyPartitionPruning": {
																		"p_database": "master",
																		"p_schema": "dummy",
																		"p_table": "dummy"
																	},
																	"EnrichedDeltaLake": {},
																	"sinkPartitionPruning": {}
																}
															},
															"staging": {},
															"compute": {
																"coreCount": 8,
																"computeType": "General"
															},
															"traceLevel": "Fine"
														}
													}
												]
											},
											{
												"value": "relations11",
												"activities": [
													{
														"name": "FromJsonToDeltaParquet_Relations11",
														"type": "ExecuteDataFlow",
														"dependsOn": [],
														"policy": {
															"timeout": "0.12:00:00",
															"retry": 2,
															"retryIntervalInSeconds": 30,
															"secureOutput": false,
															"secureInput": false
														},
														"userProperties": [],
														"typeProperties": {
															"dataflow": {
																"referenceName": "FromJsonToDeltaParquet_Relations11",
																"type": "DataFlowReference",
																"parameters": {
																	"c_target_container": {
																		"value": "'@{pipeline().parameters.c_enriched_container}'",
																		"type": "Expression"
																	},
																	"c_target_folder": {
																		"value": "'@{concat(pipeline().parameters.c_enriched_root_folder, '/',\nitem().target)}'",
																		"type": "Expression"
																	},
																	"c_key_column_name": {
																		"value": "'@{item().keyCol}'",
																		"type": "Expression"
																	},
																	"c_cdc_column_name": {
																		"value": "'@{coalesce(item().cdcCol, 'fileName')}'",
																		"type": "Expression"
																	},
																	"c_enriched_cdc_column": {
																		"value": "'@{pipeline().parameters.c_enriched_cdc_column}'",
																		"type": "Expression"
																	},
																	"p_partition_formula": {
																		"value": "@concat('\"', item().partitionFormula, '\"')",
																		"type": "Expression"
																	},
																	"p_dss_update_time": {
																		"value": "'@{formatDateTime(variables('v_dss_update_time'), 'yyyy-MM-ddTHH:mm:ssZ')}'",
																		"type": "Expression"
																	},
																	"c_raw_cdc_column": {
																		"value": "'@{pipeline().parameters.c_raw_cdc_column}'",
																		"type": "Expression"
																	}
																},
																"datasetParameters": {
																	"RawDataset": {
																		"p_container": {
																			"value": "@pipeline().parameters.c_raw_monitoring_container",
																			"type": "Expression"
																		},
																		"p_folder": {
																			"value": "@concat(pipeline().parameters.c_raw_monitoring_folder, '/', \npipeline().parameters.c_raw_root_folder, '/',\nitem().target)",
																			"type": "Expression"
																		},
																		"p_file": {
																			"value": "@concat(pipeline().parameters.c_file_list_blob, '.csv')",
																			"type": "Expression"
																		}
																	},
																	"PartitionPruning": {
																		"p_container": {
																			"value": "@pipeline().parameters.c_raw_monitoring_container",
																			"type": "Expression"
																		},
																		"p_folder": {
																			"value": "@concat(pipeline().parameters.c_raw_monitoring_folder, '/', \npipeline().parameters.c_raw_root_folder, '/',\nitem().target)",
																			"type": "Expression"
																		},
																		"p_file": {
																			"value": "@concat(pipeline().parameters.c_file_list_blob, '.csv')",
																			"type": "Expression"
																		}
																	},
																	"dummyPartitionPruning": {
																		"p_database": "master",
																		"p_schema": "dummy",
																		"p_table": "dummy"
																	},
																	"EnrichedDeltaLake": {},
																	"sinkPartitionPruning": {}
																}
															},
															"staging": {},
															"compute": {
																"coreCount": 8,
																"computeType": "General"
															},
															"traceLevel": "Fine"
														}
													}
												]
											},
											{
												"value": "basic",
												"activities": [
													{
														"name": "FromJsonToDeltaParquet_Basic",
														"type": "ExecuteDataFlow",
														"dependsOn": [],
														"policy": {
															"timeout": "0.12:00:00",
															"retry": 2,
															"retryIntervalInSeconds": 30,
															"secureOutput": false,
															"secureInput": false
														},
														"userProperties": [],
														"typeProperties": {
															"dataflow": {
																"referenceName": "FromJsonToDeltaParquet_Basic",
																"type": "DataFlowReference",
																"parameters": {
																	"c_target_container": {
																		"value": "'@{pipeline().parameters.c_enriched_container}'",
																		"type": "Expression"
																	},
																	"c_target_folder": {
																		"value": "'@{concat(pipeline().parameters.c_enriched_root_folder, '/',\nitem().target)}'",
																		"type": "Expression"
																	},
																	"c_key_column_name": {
																		"value": "'@{item().keyCol}'",
																		"type": "Expression"
																	},
																	"c_cdc_column_name": {
																		"value": "'@{coalesce(item().cdcCol, 'fileName')}'",
																		"type": "Expression"
																	},
																	"c_enriched_cdc_column": {
																		"value": "'@{pipeline().parameters.c_enriched_cdc_column}'",
																		"type": "Expression"
																	},
																	"p_partition_formula": {
																		"value": "@concat('\"', item().partitionFormula, '\"')",
																		"type": "Expression"
																	},
																	"p_dss_update_time": {
																		"value": "'@{formatDateTime(variables('v_dss_update_time'), 'yyyy-MM-ddTHH:mm:ssZ')}'",
																		"type": "Expression"
																	},
																	"c_raw_cdc_column": {
																		"value": "'@{pipeline().parameters.c_raw_cdc_column}'",
																		"type": "Expression"
																	}
																},
																"datasetParameters": {
																	"RawDataset": {
																		"p_container": {
																			"value": "@pipeline().parameters.c_raw_monitoring_container",
																			"type": "Expression"
																		},
																		"p_folder": {
																			"value": "@concat(pipeline().parameters.c_raw_monitoring_folder, '/',\n    pipeline().parameters.c_raw_root_folder, '/', \n    item().target)",
																			"type": "Expression"
																		},
																		"p_file": {
																			"value": "@concat(pipeline().parameters.c_file_list_blob, '.csv')",
																			"type": "Expression"
																		}
																	},
																	"PartitionPruning": {
																		"p_container": {
																			"value": "@pipeline().parameters.c_raw_monitoring_container",
																			"type": "Expression"
																		},
																		"p_folder": {
																			"value": "@concat(pipeline().parameters.c_raw_monitoring_folder, '/',\n    pipeline().parameters.c_raw_root_folder, '/', \n    item().target)",
																			"type": "Expression"
																		},
																		"p_file": {
																			"value": "@concat(pipeline().parameters.c_file_list_blob, '.csv')",
																			"type": "Expression"
																		}
																	},
																	"dummyPartitionPruning": {
																		"p_database": "master",
																		"p_schema": "dummy",
																		"p_table": "dummy"
																	},
																	"EnrichedDeltaLake": {},
																	"sinkPartitionPruning": {}
																}
															},
															"staging": {},
															"compute": {
																"coreCount": 8,
																"computeType": "General"
															},
															"traceLevel": "Fine"
														}
													}
												]
											}
										]
									}
								},
								{
									"name": "If dataTypeReplace not empty",
									"type": "IfCondition",
									"dependsOn": [
										{
											"activity": "If RowCount not Zero",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"userProperties": [],
									"typeProperties": {
										"expression": {
											"value": "@and(not(empty(item().dataTypeReplace)),\ngreater(activity('countRows').output.resultSets[0].rows[0].countRows, 0))",
											"type": "Expression"
										},
										"ifTrueActivities": [
											{
												"name": "Generate SQL",
												"type": "Script",
												"dependsOn": [],
												"policy": {
													"timeout": "0.12:00:00",
													"retry": 2,
													"retryIntervalInSeconds": 30,
													"secureOutput": false,
													"secureInput": false
												},
												"userProperties": [],
												"linkedServiceName": {
													"referenceName": "serverless_ARIR",
													"type": "LinkedServiceReference",
													"parameters": {
														"p_database": {
															"value": "@pipeline().parameters.c_serverless_db",
															"type": "Expression"
														}
													}
												},
												"typeProperties": {
													"scripts": [
														{
															"type": "Query",
															"text": {
																"value": "select 'create or alter view  \n@{concat(if(empty(pipeline().parameters.c_enriched_schema), '', concat(pipeline().parameters.c_enriched_schema, '.')), item().target)}\nas select * from OPENROWSET(\n      BULK ''@{activity('GenericEnrichedParquet linked service').output.properties.typeProperties.url}@{pipeline().parameters.c_enriched_container}/@{pipeline().parameters.c_enriched_root_folder}/@{item().target}'',\t\n\tFORMAT = ''Delta''\n) WITH (' +\nSTRING_AGG('[' + \ncast(colName as varchar(max)) + '] ' + \ndataType, ',' + char(10)) \nWITHIN GROUP (ORDER BY column_id ASC) +\n') as r' as SQL\nfrom (select \nc.name colName, coalesce(r.dataType,\nCASE \n      WHEN t.[name] IN ('varchar', 'char', 'varbinary') THEN t.[name] + '(' + IIF(c.max_length = -1, 'max', CAST(c.max_length AS VARCHAR(25))) + ')' \n      WHEN t.[name] IN ('nvarchar','nchar') THEN t.[name] + '(' + IIF(c.max_length = -1, 'max', CAST(c.max_length / 2 AS VARCHAR(25)))+ ')'      \n      WHEN t.[name] IN ('decimal', 'numeric') THEN t.[name] + '(' + CAST(c.[precision] AS VARCHAR(25)) + ', ' + CAST(c.[scale] AS VARCHAR(25)) + ')'\n      WHEN t.[name] IN ('datetime2') THEN t.[name] + '(' + CAST(c.[scale] AS VARCHAR(25)) + ')'\n      ELSE t.[name]\nEND) AS dataType,\nc.column_id\nfrom sys.columns c\njoin sys.views v on v.object_id = c.object_id\njoin sys.schemas s on s.schema_id = v.schema_id\njoin sys.types t on c.user_type_id = t.user_type_id \nleft outer join (select * from OpenJson(N'@{item().dataTypeReplace}')\nWITH (col varchar(255), dataType varchar(255)) as r) r\non r.col = c.name\nwhere s.name = '@{pipeline().parameters.c_enriched_schema}' and v.name = '@{item().target}') q",
																"type": "Expression"
															}
														}
													],
													"scriptBlockExecutionTimeout": "02:00:00"
												}
											},
											{
												"name": "rebuildView",
												"type": "Script",
												"dependsOn": [
													{
														"activity": "Generate SQL",
														"dependencyConditions": [
															"Succeeded"
														]
													}
												],
												"policy": {
													"timeout": "0.12:00:00",
													"retry": 2,
													"retryIntervalInSeconds": 30,
													"secureOutput": false,
													"secureInput": false
												},
												"userProperties": [],
												"linkedServiceName": {
													"referenceName": "serverless_ARIR",
													"type": "LinkedServiceReference",
													"parameters": {
														"p_database": {
															"value": "@pipeline().parameters.c_serverless_db",
															"type": "Expression"
														}
													}
												},
												"typeProperties": {
													"scripts": [
														{
															"type": "NonQuery",
															"text": {
																"value": "@activity('Generate SQL').output.resultSets[0].rows[0].SQL",
																"type": "Expression"
															}
														}
													],
													"scriptBlockExecutionTimeout": "02:00:00"
												}
											}
										]
									}
								},
								{
									"name": "DatetimeFrom",
									"type": "Script",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 2,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "serverless_ARIR",
										"type": "LinkedServiceReference",
										"parameters": {
											"p_database": {
												"value": "@pipeline().parameters.c_serverless_db",
												"type": "Expression"
											}
										}
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "Query",
												"text": {
													"value": "@if(and(empty(pipeline().parameters.p_datetime_from),\n        not(empty(pipeline().parameters.c_raw_cdc_column))\n    ),\n    concat('if exists (select 1 from sys.columns c join sys.views v on v.object_id = c.object_id join sys.schemas s on s.schema_id = v.schema_id where s.name = ''', pipeline().parameters.c_enriched_schema, ''' and v.name = ''', item().target, ''' and c.name = ''', pipeline().parameters.c_raw_cdc_column, ''') ',\n        'exec(''select dateadd(mcs, 1, cast(max(', pipeline().parameters.c_raw_cdc_column, ') as datetime2)) CDCTimestamp from ',\n        if(empty(pipeline().parameters.c_enriched_schema), '', concat(pipeline().parameters.c_enriched_schema, '.')), item().target,\n        ''') else select ''1900-01-01'' as CDCTimestamp'\n    ),\n    concat('select ''', replace(replace(replace(replace(replace(\n                    formatDateTime(\n                        pipeline().parameters.p_datetime_from, \n                        'yyyy-MM-ddTHH:mm:ss.fffffffZ'\n                    ), \n                    '0000Z', 'Z'), '000Z', 'Z'), '00Z', 'Z'), '0Z', 'Z'), '.Z', 'Z'\n                ),\n        ''' as CDCTimestamp'\n    )\n)",
													"type": "Expression"
												}
											}
										],
										"scriptBlockExecutionTimeout": "02:00:00"
									}
								},
								{
									"name": "If RowCount not Zero",
									"type": "IfCondition",
									"dependsOn": [
										{
											"activity": "switchTypes",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"userProperties": [],
									"typeProperties": {
										"expression": {
											"value": "@greater(activity('countRows').output.resultSets[0].rows[0].countRows, 0)",
											"type": "Expression"
										},
										"ifTrueActivities": [
											{
												"name": "createView",
												"type": "Script",
												"dependsOn": [],
												"policy": {
													"timeout": "0.12:00:00",
													"retry": 2,
													"retryIntervalInSeconds": 30,
													"secureOutput": false,
													"secureInput": false
												},
												"userProperties": [],
												"linkedServiceName": {
													"referenceName": "serverless_ARIR",
													"type": "LinkedServiceReference",
													"parameters": {
														"p_database": {
															"value": "@pipeline().parameters.c_serverless_db",
															"type": "Expression"
														}
													}
												},
												"typeProperties": {
													"scripts": [
														{
															"type": "Query",
															"text": {
																"value": "create or alter view \n@{if(empty(pipeline().parameters.c_enriched_schema), item().target, concat(pipeline().parameters.c_enriched_schema, '.', item().target))}\nas select * from OPENROWSET(\n\tBULK '@{activity('GenericEnrichedParquet linked service').output.properties.typeProperties.url}@{pipeline().parameters.c_enriched_container}/@{pipeline().parameters.c_enriched_root_folder}/@{item().target}',\n\tFORMAT = 'Delta'\n) as r",
																"type": "Expression"
															}
														}
													],
													"scriptBlockExecutionTimeout": "02:00:00"
												}
											}
										]
									}
								}
							]
						}
					},
					{
						"name": "GenericRawJson attributes",
						"type": "WebActivity",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"method": "GET",
							"headers": {},
							"url": {
								"value": "@concat('https://', pipeline().DataFactory, '.dev.azuresynapse.net/datasets/GenericRawJson?api-version=2020-12-01')",
								"type": "Expression"
							},
							"connectVia": {
								"referenceName": "SHIR",
								"type": "IntegrationRuntimeReference"
							},
							"authentication": {
								"type": "MSI",
								"resource": "https://dev.azuresynapse.net/"
							}
						}
					},
					{
						"name": "GenericRawJson linked service",
						"type": "WebActivity",
						"dependsOn": [
							{
								"activity": "GenericRawJson attributes",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"method": "GET",
							"headers": {},
							"url": {
								"value": "@concat('https://', pipeline().DataFactory, '.dev.azuresynapse.net/linkedservices/', activity('GenericRawJson attributes').output.properties.linkedServiceName.referenceName, '?api-version=2020-12-01')",
								"type": "Expression"
							},
							"connectVia": {
								"referenceName": "SHIR",
								"type": "IntegrationRuntimeReference"
							},
							"authentication": {
								"type": "MSI",
								"resource": "https://dev.azuresynapse.net/"
							}
						}
					},
					{
						"name": "GenericEnrichedParquet attributes",
						"type": "WebActivity",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"method": "GET",
							"headers": {},
							"url": {
								"value": "@concat('https://', pipeline().DataFactory, '.dev.azuresynapse.net/datasets/GenericEnrichedParquet?api-version=2020-12-01')",
								"type": "Expression"
							},
							"connectVia": {
								"referenceName": "SHIR",
								"type": "IntegrationRuntimeReference"
							},
							"authentication": {
								"type": "MSI",
								"resource": "https://dev.azuresynapse.net/"
							}
						}
					},
					{
						"name": "GenericEnrichedParquet linked service",
						"type": "WebActivity",
						"dependsOn": [
							{
								"activity": "GenericEnrichedParquet attributes",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"method": "GET",
							"headers": {},
							"url": {
								"value": "@concat('https://', pipeline().DataFactory, '.dev.azuresynapse.net/linkedservices/', activity('GenericEnrichedParquet attributes').output.properties.linkedServiceName.referenceName, '?api-version=2020-12-01')",
								"type": "Expression"
							},
							"connectVia": {
								"referenceName": "SHIR",
								"type": "IntegrationRuntimeReference"
							},
							"authentication": {
								"type": "MSI",
								"resource": "https://dev.azuresynapse.net/"
							}
						}
					},
					{
						"name": "Set v_dss_update_time",
						"type": "SetVariable",
						"dependsOn": [],
						"policy": {
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"variableName": "v_dss_update_time",
							"value": {
								"value": "@utcNow()",
								"type": "Expression"
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"p_datasets": {
						"type": "array",
						"defaultValue": [
							{
								"type": "basic",
								"target": "dataflows_REST_API",
								"cdcCol": null,
								"keyCol": "name",
								"dataTypeReplace": [
									{
										"col": "type",
										"dataType": "nvarchar(200)"
									}
								],
								"relCol": null,
								"partitionFormula": "'dummy'"
							},
							{
								"type": "basic",
								"target": "datasets_REST_API",
								"cdcCol": null,
								"keyCol": "name",
								"dataTypeReplace": [
									{
										"col": "type",
										"dataType": "nvarchar(200)"
									}
								],
								"relCol": null,
								"partitionFormula": "'dummy'"
							},
							{
								"type": "relationsMM",
								"target": "dataflows_datasets_REST_API",
								"cdcCol": null,
								"keyCol": "name",
								"dataTypeReplace": null,
								"relCol": "properties.typeProperties.sources.dataset.referenceName",
								"partitionFormula": "'dummy'"
							},
							{
								"type": "relations11",
								"target": "datasets_relations11_REST_API",
								"cdcCol": null,
								"keyCol": "name",
								"dataTypeReplace": null,
								"relCol": null,
								"partitionFormula": "'dummy'"
							}
						]
					},
					"p_datetime_from": {
						"type": "string"
					},
					"p_datetime_to": {
						"type": "string"
					},
					"c_raw_root_folder": {
						"type": "string",
						"defaultValue": "FromRESTAPIToJson"
					},
					"c_raw_container": {
						"type": "string",
						"defaultValue": "template"
					},
					"c_enriched_container": {
						"type": "string",
						"defaultValue": "template"
					},
					"c_enriched_root_folder": {
						"type": "string",
						"defaultValue": "FromJsonToDeltaParquet"
					},
					"c_file_list_blob": {
						"type": "string",
						"defaultValue": "fileList"
					},
					"c_serverless_db": {
						"type": "string",
						"defaultValue": "templateDB"
					},
					"c_raw_monitoring_folder": {
						"type": "string",
						"defaultValue": "PipelineMonitoring"
					},
					"c_external_data_source": {
						"type": "string",
						"defaultValue": "template"
					},
					"c_enriched_schema": {
						"type": "string",
						"defaultValue": "enr"
					},
					"c_enriched_cdc_column": {
						"type": "string",
						"defaultValue": "enrTimestamp"
					},
					"c_raw_monitoring_container": {
						"type": "string",
						"defaultValue": "template"
					},
					"c_raw_cdc_column": {
						"type": "string",
						"defaultValue": "rawTimestamp"
					}
				},
				"variables": {
					"v_datetime_from": {
						"type": "String"
					},
					"v_datetime_to": {
						"type": "String"
					},
					"v_array": {
						"type": "Array"
					},
					"v_array_tmp": {
						"type": "Array"
					},
					"v_string": {
						"type": "String"
					},
					"v_dss_update_time": {
						"type": "String"
					}
				},
				"folder": {
					"name": "Templates"
				},
				"annotations": [],
				"lastPublishTime": "2023-10-16T14:40:57Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/SHIR')]",
				"[concat(variables('workspaceId'), '/datasets/GenericServerlessSQL')]",
				"[concat(variables('workspaceId'), '/datasets/GenericRawCSV_NoHeaderNoQuote')]",
				"[concat(variables('workspaceId'), '/linkedServices/serverless_ARIR')]",
				"[concat(variables('workspaceId'), '/dataflows/FromJsonToDeltaParquet_RelationsMM')]",
				"[concat(variables('workspaceId'), '/dataflows/FromJsonToDeltaParquet_Relations11')]",
				"[concat(variables('workspaceId'), '/dataflows/FromJsonToDeltaParquet_Basic')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/FromParquetToDeltaParquet')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "ForEachDataset",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "GenericRawParquet linked service",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "Set v_dss_update_time",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "GenericEnrichedParquet linked service",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@pipeline().parameters.p_datasets",
								"type": "Expression"
							},
							"isSequential": false,
							"activities": [
								{
									"name": "copyFileList",
									"type": "Copy",
									"dependsOn": [
										{
											"activity": "DatetimeFrom",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 2,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "SqlDWSource",
											"sqlReaderQuery": {
												"value": "@concat('SELECT STRING_AGG(cast(parquetName as varchar(max)), char(10)) ListOfFiles ',\n        'FROM ( SELECT right(result.filepath(), ',\n        'len(result.filepath()) - charindex(''', \n        pipeline().parameters.c_raw_root_folder, \n        ''', result.filepath()) + 1) parquetName, max(',\n        first(item().keyCol), ') ', first(item().keyCol), ' FROM OPENROWSET(',\n        'BULK ''', activity('GenericRawParquet linked service').output.properties.typeProperties.url, \n        pipeline().parameters.c_raw_container, '/', \n        pipeline().parameters.c_raw_root_folder, '/',\n        if(equals(length(item().target), 0), item().sourceObject, item().target), '/*.parquet'',  FORMAT = ''PARQUET'') ',\n        'AS [result] WHERE reverse(substring(reverse(result.filepath()), 1, charindex(''/'', reverse(result.filepath())) - 1))',\n        if(\n                not(empty(pipeline().parameters.p_datetime_to)), \n                ' between ',\n                ' >= '\n        ),\n        '''', if(equals(length(item().target), 0), item().sourceObject, item().target), if(empty(item().cdcCol), '', concat('_', activity('DatetimeFrom').output.resultSets[0].rows[0].CDCTimestamp)), '.parquet''',\n        if(not(empty(pipeline().parameters.p_datetime_to)), \n            concat(' and ''', if(equals(length(item().target), 0), item().sourceObject, item().target), '_', \n                replace(replace(replace(replace(replace(\n                    formatDateTime(\n                        pipeline().parameters.p_datetime_to, \n                        'yyyy-MM-ddTHH:mm:ss.fffffffZ'\n                    ), \n                    '0000Z', 'Z'), '000Z', 'Z'), '00Z', 'Z'), '0Z', 'Z'), '.Z', 'Z'\n                ), \n                '.parquet'''\n            ), \n            ''\n        ), \n        ' GROUP BY result.filepath()) q'\n)",
												"type": "Expression"
											},
											"queryTimeout": "02:00:00",
											"partitionOption": "None"
										},
										"sink": {
											"type": "DelimitedTextSink",
											"storeSettings": {
												"type": "AzureBlobFSWriteSettings"
											},
											"formatSettings": {
												"type": "DelimitedTextWriteSettings",
												"quoteAllText": true,
												"fileExtension": ".txt"
											}
										},
										"enableStaging": false,
										"translator": {
											"type": "TabularTranslator",
											"mappings": [
												{
													"source": {
														"name": "ListOfFiles",
														"physicalType": "nvarchar"
													},
													"sink": {
														"ordinal": 1
													}
												}
											],
											"typeConversion": true,
											"typeConversionSettings": {
												"allowDataTruncation": true,
												"treatBooleanAsNumber": false
											}
										}
									},
									"inputs": [
										{
											"referenceName": "GenericServerlessSQL",
											"type": "DatasetReference",
											"parameters": {
												"p_database": "master",
												"p_schema": "dummy",
												"p_table": "dummy"
											}
										}
									],
									"outputs": [
										{
											"referenceName": "GenericRawCSV_NoHeaderNoQuote",
											"type": "DatasetReference",
											"parameters": {
												"p_container": {
													"value": "@pipeline().parameters.c_raw_monitoring_container",
													"type": "Expression"
												},
												"p_folder": {
													"value": "@concat(pipeline().parameters.c_raw_monitoring_folder, '/',\n    pipeline().parameters.c_raw_root_folder, '/', \n    if(equals(length(item().target), 0), item().sourceObject, item().target))",
													"type": "Expression"
												},
												"p_file": {
													"value": "@concat(pipeline().parameters.c_file_list_blob)",
													"type": "Expression"
												}
											}
										}
									]
								},
								{
									"name": "countRows",
									"type": "Script",
									"dependsOn": [
										{
											"activity": "DatetimeFrom",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 2,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "serverless_ARIR",
										"type": "LinkedServiceReference",
										"parameters": {
											"p_database": "master"
										}
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "Query",
												"text": {
													"value": "@concat('select count(*) countRows FROM OPENROWSET(',\n        'BULK ''', activity('GenericRawParquet linked service').output.properties.typeProperties.url, \n        pipeline().parameters.c_raw_container, '/', \n        pipeline().parameters.c_raw_root_folder, '/',\n        if(equals(length(item().target), 0), item().sourceObject, item().target), '/*.parquet'',  FORMAT = ''PARQUET'') ', 'AS [result] WHERE reverse(substring(reverse(result.filepath()), 1, charindex(''/'', reverse(result.filepath())) - 1))',\n        if(not(empty(pipeline().parameters.p_datetime_to)), \n           ' between ',\n           ' >= '),\n        '''', if(equals(length(item().target), 0), item().sourceObject, item().target), if(empty(item().cdcCol), '', concat('_', activity('DatetimeFrom').output.resultSets[0].rows[0].CDCTimestamp)), '.parquet''',\n        if(not(empty(pipeline().parameters.p_datetime_to)), \n            concat(' and ''', if(equals(length(item().target), 0), item().sourceObject, item().target), '_', \n                replace(replace(replace(replace(replace(\n                    formatDateTime(\n                        pipeline().parameters.p_datetime_to, \n                        'yyyy-MM-ddTHH:mm:ss.fffffffZ'\n                    ), \n                    '0000Z', 'Z'), '000Z', 'Z'), '00Z', 'Z'), '0Z', 'Z'), '.Z', 'Z'\n                ), \n                '.parquet'''\n            ), \n            ''\n        )\n)",
													"type": "Expression"
												}
											}
										],
										"scriptBlockExecutionTimeout": "02:00:00"
									}
								},
								{
									"name": "If dataTypeReplace not empty",
									"type": "IfCondition",
									"dependsOn": [
										{
											"activity": "If RowCount not Zero",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"userProperties": [],
									"typeProperties": {
										"expression": {
											"value": "@and(not(empty(item().dataTypeReplace)),\ngreater(activity('countRows').output.resultSets[0].rows[0].countRows, 0))",
											"type": "Expression"
										},
										"ifTrueActivities": [
											{
												"name": "Generate SQL",
												"type": "Script",
												"dependsOn": [],
												"policy": {
													"timeout": "0.12:00:00",
													"retry": 2,
													"retryIntervalInSeconds": 30,
													"secureOutput": false,
													"secureInput": false
												},
												"userProperties": [],
												"linkedServiceName": {
													"referenceName": "serverless_ARIR",
													"type": "LinkedServiceReference",
													"parameters": {
														"p_database": "ICP_Data_Store"
													}
												},
												"typeProperties": {
													"scripts": [
														{
															"type": "Query",
															"text": {
																"value": "select 'create or alter view  \n@{concat(if(empty(pipeline().parameters.c_enriched_schema), '', concat(pipeline().parameters.c_enriched_schema, '.')), item().target)}\nas select * from OPENROWSET(\n      BULK ''@{activity('GenericEnrichedParquet linked service').output.properties.typeProperties.url}@{pipeline().parameters.c_enriched_container}/@{pipeline().parameters.c_enriched_root_folder}/@{item().target}'', \t\n\tFORMAT = ''Delta''\n) WITH (' +\nSTRING_AGG('[' + \ncast(colName as varchar(max)) + '] ' + \ndataType, ',' + char(10)) \nWITHIN GROUP (ORDER BY column_id ASC) +\n') as r' as SQL\nfrom (select \nc.name colName, coalesce(r.dataType,\nCASE \n      WHEN t.[name] IN ('varchar', 'char', 'varbinary') THEN t.[name] + '(' + IIF(c.max_length = -1, 'max', CAST(c.max_length AS VARCHAR(25))) + ')' \n      WHEN t.[name] IN ('nvarchar','nchar') THEN t.[name] + '(' + IIF(c.max_length = -1, 'max', CAST(c.max_length / 2 AS VARCHAR(25)))+ ')'      \n      WHEN t.[name] IN ('decimal', 'numeric') THEN t.[name] + '(' + CAST(c.[precision] AS VARCHAR(25)) + ', ' + CAST(c.[scale] AS VARCHAR(25)) + ')'\n      WHEN t.[name] IN ('datetime2') THEN t.[name] + '(' + CAST(c.[scale] AS VARCHAR(25)) + ')'\n      ELSE t.[name]\nEND) AS dataType,\nc.column_id\nfrom sys.columns c\njoin sys.views v on v.object_id = c.object_id\njoin sys.schemas s on s.schema_id = v.schema_id\njoin sys.types t on c.user_type_id = t.user_type_id \nleft outer join (select * from OpenJson(N'@{item().dataTypeReplace}')\nWITH (col varchar(255), dataType varchar(255)) as r) r\non r.col = c.name\nwhere s.name = '@{pipeline().parameters.c_enriched_schema}' and v.name = '@{item().target}') q",
																"type": "Expression"
															}
														}
													],
													"scriptBlockExecutionTimeout": "02:00:00"
												}
											},
											{
												"name": "rebuildView",
												"type": "Script",
												"dependsOn": [
													{
														"activity": "Generate SQL",
														"dependencyConditions": [
															"Succeeded"
														]
													}
												],
												"policy": {
													"timeout": "0.12:00:00",
													"retry": 2,
													"retryIntervalInSeconds": 30,
													"secureOutput": false,
													"secureInput": false
												},
												"userProperties": [],
												"linkedServiceName": {
													"referenceName": "serverless_ARIR",
													"type": "LinkedServiceReference",
													"parameters": {
														"p_database": "ICP_Data_Store"
													}
												},
												"typeProperties": {
													"scripts": [
														{
															"type": "NonQuery",
															"text": {
																"value": "@activity('Generate SQL').output.resultSets[0].rows[0].SQL",
																"type": "Expression"
															}
														}
													],
													"scriptBlockExecutionTimeout": "02:00:00"
												}
											}
										]
									}
								},
								{
									"name": "DatetimeFrom",
									"type": "Script",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 2,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "serverless_ARIR",
										"type": "LinkedServiceReference",
										"parameters": {
											"p_database": {
												"value": "@pipeline().parameters.c_serverless_db",
												"type": "Expression"
											}
										}
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "Query",
												"text": {
													"value": "@if(and(empty(pipeline().parameters.p_datetime_from),\n        not(empty(pipeline().parameters.c_raw_cdc_column))\n    ),\n    concat('if exists (select 1 from sys.columns c join sys.views v on v.object_id = c.object_id join sys.schemas s on s.schema_id = v.schema_id where s.name = ''', pipeline().parameters.c_enriched_schema, ''' and v.name = ''', item().target, ''' and c.name = ''', pipeline().parameters.c_raw_cdc_column, ''') ',\n        'exec(''select dateadd(mcs, 1, cast(max(', pipeline().parameters.c_raw_cdc_column, ') as datetime2)) CDCTimestamp from ',\n        if(empty(pipeline().parameters.c_enriched_schema), '', concat(pipeline().parameters.c_enriched_schema, '.')), item().target,\n        ''') else select ''1900-01-01'' as CDCTimestamp'\n    ),\n    concat('select ''', replace(replace(replace(replace(replace(\n                    formatDateTime(\n                        pipeline().parameters.p_datetime_from, \n                        'yyyy-MM-ddTHH:mm:ss.fffffffZ'\n                    ), \n                    '0000Z', 'Z'), '000Z', 'Z'), '00Z', 'Z'), '0Z', 'Z'), '.Z', 'Z'\n                ),\n        ''' as CDCTimestamp'\n    )\n)",
													"type": "Expression"
												}
											}
										],
										"scriptBlockExecutionTimeout": "02:00:00"
									}
								},
								{
									"name": "If RowCount not Zero",
									"type": "IfCondition",
									"dependsOn": [
										{
											"activity": "copyFileList",
											"dependencyConditions": [
												"Succeeded"
											]
										},
										{
											"activity": "countRows",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"userProperties": [],
									"typeProperties": {
										"expression": {
											"value": "@greater(activity('countRows').output.resultSets[0].rows[0].countRows, 0)",
											"type": "Expression"
										},
										"ifTrueActivities": [
											{
												"name": "createView",
												"type": "Script",
												"dependsOn": [
													{
														"activity": "FromParquetToDeltaParquet",
														"dependencyConditions": [
															"Succeeded"
														]
													}
												],
												"policy": {
													"timeout": "0.12:00:00",
													"retry": 2,
													"retryIntervalInSeconds": 30,
													"secureOutput": false,
													"secureInput": false
												},
												"userProperties": [],
												"linkedServiceName": {
													"referenceName": "serverless_ARIR",
													"type": "LinkedServiceReference",
													"parameters": {
														"p_database": {
															"value": "@pipeline().parameters.c_serverless_db",
															"type": "Expression"
														}
													}
												},
												"typeProperties": {
													"scripts": [
														{
															"type": "Query",
															"text": {
																"value": "create or alter view \n@{if(empty(pipeline().parameters.c_enriched_schema), item().target, concat(pipeline().parameters.c_enriched_schema, '.', item().target))}\nas select * from OPENROWSET(\n\tBULK '@{activity('GenericEnrichedParquet linked service').output.properties.typeProperties.url}@{pipeline().parameters.c_enriched_container}/@{pipeline().parameters.c_enriched_root_folder}/@{item().target}', \t\n\tFORMAT = 'Delta'\n) as r",
																"type": "Expression"
															}
														}
													],
													"scriptBlockExecutionTimeout": "02:00:00"
												}
											},
											{
												"name": "FromParquetToDeltaParquet",
												"type": "ExecuteDataFlow",
												"dependsOn": [],
												"policy": {
													"timeout": "0.12:00:00",
													"retry": 2,
													"retryIntervalInSeconds": 30,
													"secureOutput": false,
													"secureInput": false
												},
												"userProperties": [],
												"typeProperties": {
													"dataflow": {
														"referenceName": "FromParquetToDeltaParquet",
														"type": "DataFlowReference",
														"parameters": {
															"c_target_container": {
																"value": "'@{pipeline().parameters.c_enriched_container}'",
																"type": "Expression"
															},
															"c_key_column_name": {
																"value": "@item().keyCol",
																"type": "Expression"
															},
															"c_raw_cdc_column": {
																"value": "'@{pipeline().parameters.c_raw_cdc_column}'",
																"type": "Expression"
															},
															"p_dss_update_time": {
																"value": "'@{formatDateTime(variables('v_dss_update_time'), 'yyyy-MM-ddTHH:mm:ssZ')}'",
																"type": "Expression"
															},
															"c_enr_cdc_column": {
																"value": "'@{pipeline().parameters.c_enr_cdc_column}'",
																"type": "Expression"
															},
															"p_partition_formula": {
																"value": "@concat('\"', item().partitionFormula, '\"')",
																"type": "Expression"
															},
															"c_target_root_folder": {
																"value": "'@{pipeline().parameters.c_enriched_root_folder}'",
																"type": "Expression"
															},
															"p_object": {
																"value": "'@{item().target}'",
																"type": "Expression"
															},
															"p_processing_mode": {
																"value": "'@{item().processingMode}'",
																"type": "Expression"
															}
														},
														"datasetParameters": {
															"RawDataset": {
																"p_container": {
																	"value": "@pipeline().parameters.c_raw_monitoring_container",
																	"type": "Expression"
																},
																"p_folder": {
																	"value": "@concat(pipeline().parameters.c_raw_monitoring_folder, '/',\n    pipeline().parameters.c_raw_root_folder, '/', \n    if(equals(length(item().target), 0), item().sourceObject, item().target))",
																	"type": "Expression"
																},
																"p_file": {
																	"value": "@concat(pipeline().parameters.c_file_list_blob, '.csv')",
																	"type": "Expression"
																}
															},
															"RawPartitionPruning": {
																"p_container": {
																	"value": "@pipeline().parameters.c_raw_monitoring_container",
																	"type": "Expression"
																},
																"p_folder": {
																	"value": "@concat(pipeline().parameters.c_raw_monitoring_folder, '/',\n    pipeline().parameters.c_raw_root_folder, '/', \n    if(equals(length(item().target), 0), item().sourceObject, item().target))",
																	"type": "Expression"
																},
																"p_file": {
																	"value": "@concat(pipeline().parameters.c_file_list_blob, '.csv')",
																	"type": "Expression"
																}
															},
															"dummyPartitionPruning": {
																"p_database": "master",
																"p_schema": "dummy",
																"p_table": "dummy"
															},
															"EnrichedDeltaLake": {},
															"sinkPartitionPruning": {}
														}
													},
													"staging": {},
													"compute": {
														"coreCount": 8,
														"computeType": "General"
													},
													"traceLevel": "Fine"
												}
											}
										]
									}
								}
							]
						}
					},
					{
						"name": "GenericRawParquet attributes",
						"type": "WebActivity",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"method": "GET",
							"headers": {},
							"url": {
								"value": "@concat('https://', pipeline().DataFactory, '.dev.azuresynapse.net/datasets/GenericRawParquet?api-version=2020-12-01')",
								"type": "Expression"
							},
							"connectVia": {
								"referenceName": "SHIR",
								"type": "IntegrationRuntimeReference"
							},
							"authentication": {
								"type": "MSI",
								"resource": "https://dev.azuresynapse.net/"
							}
						}
					},
					{
						"name": "GenericRawParquet linked service",
						"type": "WebActivity",
						"dependsOn": [
							{
								"activity": "GenericRawParquet attributes",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"method": "GET",
							"headers": {},
							"url": {
								"value": "@concat('https://', pipeline().DataFactory, '.dev.azuresynapse.net/linkedservices/', activity('GenericRawParquet attributes').output.properties.linkedServiceName.referenceName, '?api-version=2020-12-01')",
								"type": "Expression"
							},
							"connectVia": {
								"referenceName": "SHIR",
								"type": "IntegrationRuntimeReference"
							},
							"authentication": {
								"type": "MSI",
								"resource": "https://dev.azuresynapse.net/"
							}
						}
					},
					{
						"name": "Set v_dss_update_time",
						"type": "SetVariable",
						"dependsOn": [],
						"policy": {
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"variableName": "v_dss_update_time",
							"value": {
								"value": "@utcNow()",
								"type": "Expression"
							}
						}
					},
					{
						"name": "GenericEnrichedParquet attributes",
						"type": "WebActivity",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"method": "GET",
							"headers": {},
							"url": {
								"value": "@concat('https://', pipeline().DataFactory, '.dev.azuresynapse.net/datasets/GenericEnrichedParquet?api-version=2020-12-01')",
								"type": "Expression"
							},
							"connectVia": {
								"referenceName": "SHIR",
								"type": "IntegrationRuntimeReference"
							},
							"authentication": {
								"type": "MSI",
								"resource": "https://dev.azuresynapse.net/"
							}
						}
					},
					{
						"name": "GenericEnrichedParquet linked service",
						"type": "WebActivity",
						"dependsOn": [
							{
								"activity": "GenericEnrichedParquet attributes",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"method": "GET",
							"headers": {},
							"url": {
								"value": "@concat('https://', pipeline().DataFactory, '.dev.azuresynapse.net/linkedservices/', activity('GenericEnrichedParquet attributes').output.properties.linkedServiceName.referenceName, '?api-version=2020-12-01')",
								"type": "Expression"
							},
							"connectVia": {
								"referenceName": "SHIR",
								"type": "IntegrationRuntimeReference"
							},
							"authentication": {
								"type": "MSI",
								"resource": "https://dev.azuresynapse.net/"
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"p_datasets": {
						"type": "array",
						"defaultValue": [
							{
								"sourceObject": "dataflows_REST_API",
								"sourceSchema": "enr",
								"whereStatement": "",
								"target": "dataflows_SQL",
								"processingMode": "bulk",
								"cdcCol": "",
								"keyCol": [
									"name"
								],
								"dataTypeReplace": null,
								"partitionFormula": "'dummy'"
							},
							{
								"sourceObject": "datasets_REST_API",
								"sourceSchema": "enr",
								"whereStatement": "",
								"target": "datasets_SQL",
								"processingMode": "bulk",
								"cdcCol": "",
								"keyCol": [
									"name"
								],
								"dataTypeReplace": null,
								"partitionFormula": "'dummy'"
							},
							{
								"sourceObject": "datasets_relations11_REST_API",
								"sourceSchema": "enr",
								"whereStatement": "",
								"target": "datasets_relations11_SQL",
								"processingMode": "incremental",
								"cdcCol": "enrTimestamp",
								"keyCol": [
									"name"
								],
								"dataTypeReplace": null,
								"partitionFormula": "'dummy'"
							},
							{
								"sourceObject": "dataflows_datasets_REST_API",
								"sourceSchema": "enr",
								"whereStatement": "",
								"target": "dataflows_datasets_SQL",
								"processingMode": "incremental",
								"cdcCol": "enrTimestamp",
								"keyCol": [
									"name",
									"propertiestypePropertiessourcesdatasetreferenceName"
								],
								"dataTypeReplace": null,
								"partitionFormula": "'dummy'"
							}
						]
					},
					"p_datetime_from": {
						"type": "string"
					},
					"p_datetime_to": {
						"type": "string"
					},
					"c_raw_root_folder": {
						"type": "string",
						"defaultValue": "FromSQLToParquet"
					},
					"c_raw_container": {
						"type": "string",
						"defaultValue": "template"
					},
					"c_enriched_container": {
						"type": "string",
						"defaultValue": "template"
					},
					"c_enriched_root_folder": {
						"type": "string",
						"defaultValue": "FromParquetToDeltaParquet"
					},
					"c_file_list_blob": {
						"type": "string",
						"defaultValue": "fileList"
					},
					"c_serverless_db": {
						"type": "string",
						"defaultValue": "templateDB"
					},
					"c_raw_monitoring_folder": {
						"type": "string",
						"defaultValue": "PipelineMonitoring"
					},
					"c_enriched_schema": {
						"type": "string",
						"defaultValue": "enr"
					},
					"c_enr_cdc_column": {
						"type": "string",
						"defaultValue": "enrTimestamp_ParquetToDeltaParquet"
					},
					"c_raw_monitoring_container": {
						"type": "string",
						"defaultValue": "template"
					},
					"c_raw_cdc_column": {
						"type": "string",
						"defaultValue": "rawTimestamp_ParquetToDeltaParquet"
					}
				},
				"variables": {
					"v_datetime_from": {
						"type": "String"
					},
					"v_datetime_to": {
						"type": "String"
					},
					"v_array": {
						"type": "Array"
					},
					"v_array_tmp": {
						"type": "Array"
					},
					"v_string": {
						"type": "String"
					},
					"v_dss_update_time": {
						"type": "String"
					}
				},
				"folder": {
					"name": "Templates"
				},
				"annotations": [],
				"lastPublishTime": "2023-10-16T14:40:58Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/SHIR')]",
				"[concat(variables('workspaceId'), '/datasets/GenericServerlessSQL')]",
				"[concat(variables('workspaceId'), '/datasets/GenericRawCSV_NoHeaderNoQuote')]",
				"[concat(variables('workspaceId'), '/linkedServices/serverless_ARIR')]",
				"[concat(variables('workspaceId'), '/dataflows/FromParquetToDeltaParquet')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/FromRESTAPIToJson')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "ForEachDataset",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Set v_datetime_to",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "GenericRawJson linked service",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@pipeline().parameters.p_datasets",
								"type": "Expression"
							},
							"isSequential": false,
							"activities": [
								{
									"name": "CopyDataset",
									"type": "Copy",
									"dependsOn": [
										{
											"activity": "ReadMonitoringBlob",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 3,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "RestSource",
											"httpRequestTimeout": "00:01:40",
											"requestInterval": "00.00:00:00.010",
											"requestMethod": "GET"
										},
										"sink": {
											"type": "JsonSink",
											"storeSettings": {
												"type": "AzureBlobFSWriteSettings"
											},
											"formatSettings": {
												"type": "JsonWriteSettings"
											}
										},
										"enableStaging": false
									},
									"inputs": [
										{
											"referenceName": "azuresynapse",
											"type": "DatasetReference",
											"parameters": {
												"p_workspace": {
													"value": "@pipeline().DataFactory",
													"type": "Expression"
												},
												"p_relative_url": {
													"value": "@if(\n    and(\n        item().delta, \n        equals(length(activity('ReadMonitoringBlob').output.firstRow.DeltaLink), 0)\n    ),\n    concat(item().path, \n        item().source, \n        '/delta',\n        if(\n            and(\n                empty(item().select), \n                empty(item().filter)), '',\n            concat('?', item().select, item().filter)\n        )\n    ), \n    if(\n        item().delta,\n        activity('ReadMonitoringBlob').output.firstRow.DeltaLink,\n        concat(\n            item().path, \n            item().source, \n            if(\n                and(\n                    empty(item().select), \n                    and(empty(item().filter), empty(item().cdcCol))), '',\n                concat('?', \n                    if(empty(item().select), '', concat(item().select, '&')),\n                    if(empty(item().filter),\n                        if(not(empty(item().cdcCol)), '$filter=', ''),\n                        if(not(empty(item().cdcCol)), concat(item().filter, '&'), item().filter)\n                    ),\n                    if(and(not(item().delta), not(empty(item().cdcCol))),\n                        concat('(DateModified gt ',\n                            formatDateTime(\n                                if(empty(pipeline().parameters.p_datetime_from),\n                                    addHours(\n                                        activity('ReadMonitoringBlob').output.firstRow.CDCTimestamp,\n                                        pipeline().parameters.c_cdc_offset_hr\n                                    ),                                        \n                                    pipeline().parameters.p_datetime_from\n                                ),\n                            'yyyy-MM-ddTHH:mm:ss.fffffffZ'),\n                            ' and DateModified le ',\n                            formatDateTime(\n                                variables('v_datetime_to'), \n                                'yyyy-MM-ddTHH:mm:ss.fffffffZ'\n                            ), ')'\n                        ), ''\n                    )\n                )\n            )\n        )\n    )\n)",
													"type": "Expression"
												}
											}
										}
									],
									"outputs": [
										{
											"referenceName": "GenericRawJson",
											"type": "DatasetReference",
											"parameters": {
												"p_container": {
													"value": "@pipeline().parameters.c_raw_container",
													"type": "Expression"
												},
												"p_folder": {
													"value": "@concat(pipeline().parameters.c_raw_root_folder, '/',\nif(equals(length(item().target), 0), item().source, item().target))",
													"type": "Expression"
												},
												"p_file": {
													"value": "@concat(if(\n    equals(length(item().target), 0), item().source, item().target),\n    '_', variables('v_cdc_timestamp'))",
													"type": "Expression"
												}
											}
										}
									]
								},
								{
									"name": "CheckPipelineMonitoringBlob",
									"type": "GetMetadata",
									"dependsOn": [],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 2,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataset": {
											"referenceName": "GenericRawJson",
											"type": "DatasetReference",
											"parameters": {
												"p_container": {
													"value": "@pipeline().parameters.c_raw_monitoring_container",
													"type": "Expression"
												},
												"p_folder": {
													"value": "@concat(pipeline().parameters.c_raw_monitoring_folder, '/',\n    pipeline().parameters.c_raw_root_folder, '/', \n    item().target)",
													"type": "Expression"
												},
												"p_file": {
													"value": "@item().target",
													"type": "Expression"
												}
											}
										},
										"fieldList": [
											"exists",
											"lastModified"
										],
										"storeSettings": {
											"type": "AzureBlobFSReadSettings",
											"recursive": true,
											"enablePartitionDiscovery": false
										},
										"formatSettings": {
											"type": "JsonReadSettings"
										}
									}
								},
								{
									"name": "If Monitoring Blob Exists",
									"type": "IfCondition",
									"dependsOn": [
										{
											"activity": "CheckPipelineMonitoringBlob",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"userProperties": [],
									"typeProperties": {
										"expression": {
											"value": "@activity('CheckPipelineMonitoringBlob').output.exists",
											"type": "Expression"
										},
										"ifFalseActivities": [
											{
												"name": "CopyDefaultMonitoringData",
												"type": "Copy",
												"dependsOn": [],
												"policy": {
													"timeout": "7.00:00:00",
													"retry": 2,
													"retryIntervalInSeconds": 30,
													"secureOutput": false,
													"secureInput": false
												},
												"userProperties": [],
												"typeProperties": {
													"source": {
														"type": "JsonSource",
														"additionalColumns": [
															{
																"name": "PipelineName",
																"value": {
																	"value": "@pipeline().Pipeline",
																	"type": "Expression"
																}
															},
															{
																"name": "BlobRootDirectory",
																"value": {
																	"value": "@concat(pipeline().parameters.c_raw_root_folder)",
																	"type": "Expression"
																}
															},
															{
																"name": "DatetimeFrom",
																"value": ""
															},
															{
																"name": "DatetimeTo",
																"value": ""
															},
															{
																"name": "CDCTimestamp",
																"value": {
																	"value": "@concat('1900-01-01')",
																	"type": "Expression"
																}
															},
															{
																"name": "CurrentUTC",
																"value": {
																	"value": "@utcnow()",
																	"type": "Expression"
																}
															},
															{
																"name": "DeltaLink",
																"value": ""
															},
															{
																"name": "RowCount",
																"value": ""
															}
														],
														"storeSettings": {
															"type": "AzureBlobFSReadSettings",
															"recursive": true,
															"enablePartitionDiscovery": false
														},
														"formatSettings": {
															"type": "JsonReadSettings"
														}
													},
													"sink": {
														"type": "JsonSink",
														"storeSettings": {
															"type": "AzureBlobFSWriteSettings"
														},
														"formatSettings": {
															"type": "JsonWriteSettings"
														}
													},
													"enableStaging": false
												},
												"inputs": [
													{
														"referenceName": "DummyJson",
														"type": "DatasetReference",
														"parameters": {}
													}
												],
												"outputs": [
													{
														"referenceName": "GenericRawJson",
														"type": "DatasetReference",
														"parameters": {
															"p_container": {
																"value": "@pipeline().parameters.c_raw_monitoring_container",
																"type": "Expression"
															},
															"p_folder": {
																"value": "@concat(pipeline().parameters.c_raw_monitoring_folder, '/',\n    pipeline().parameters.c_raw_root_folder, '/', \n    item().target)",
																"type": "Expression"
															},
															"p_file": {
																"value": "@item().target",
																"type": "Expression"
															}
														}
													}
												]
											}
										]
									}
								},
								{
									"name": "ReadMonitoringBlob",
									"type": "Lookup",
									"dependsOn": [
										{
											"activity": "If Monitoring Blob Exists",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 2,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "JsonSource",
											"storeSettings": {
												"type": "AzureBlobFSReadSettings",
												"recursive": false,
												"enablePartitionDiscovery": false
											},
											"formatSettings": {
												"type": "JsonReadSettings"
											}
										},
										"dataset": {
											"referenceName": "GenericRawJson",
											"type": "DatasetReference",
											"parameters": {
												"p_container": {
													"value": "@pipeline().parameters.c_raw_monitoring_container",
													"type": "Expression"
												},
												"p_folder": {
													"value": "@concat(pipeline().parameters.c_raw_monitoring_folder, '/',\n    pipeline().parameters.c_raw_root_folder, '/', \n    item().target)",
													"type": "Expression"
												},
												"p_file": {
													"value": "@item().target",
													"type": "Expression"
												}
											}
										}
									}
								},
								{
									"name": "countRows",
									"type": "Script",
									"dependsOn": [
										{
											"activity": "CopyDataset",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 2,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "serverless_ARIR",
										"type": "LinkedServiceReference",
										"parameters": {
											"p_database": "master"
										}
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "Query",
												"text": {
													"value": "SELECT count(@{if(empty(item().crossApplyField), concat('JSON_VALUE (jsonContent, ''$.', item().keyCol, ''')'), 'keyColumn')}) countRows\n   FROM OPENROWSET(\n          BULK '@{activity('GenericRawJson linked service').output.properties.typeProperties.url}@{pipeline().parameters.c_raw_container}/@{pipeline().parameters.c_raw_root_folder}/@{item().target}/@{concat(if(equals(length(item().target), 0), item().source, item().target), '_', variables('v_cdc_timestamp'))}.json', \n          FORMAT = 'CSV', FIELDQUOTE = '0x0b', FIELDTERMINATOR ='0x0b', ROWTERMINATOR = '\\n') \n          WITH (jsonContent varchar(MAX)) AS [result]\n@{if(empty(item().crossApplyField), '', concat(' cross apply openjson(JSON_QUERY(jsonContent, ''$.', item().crossApplyField, ''')) with (keyColumn varchar(100) ''$.', item().keyCol, ''')'))}\n",
													"type": "Expression"
												}
											}
										],
										"scriptBlockExecutionTimeout": "02:00:00"
									}
								},
								{
									"name": "If RowCount not zero",
									"type": "IfCondition",
									"dependsOn": [
										{
											"activity": "countRows",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"userProperties": [],
									"typeProperties": {
										"expression": {
											"value": "@greater(\n    activity('countRows').output.resultSets[0].rows[0].countRows,\n    0)",
											"type": "Expression"
										},
										"ifFalseActivities": [
											{
												"name": "Delete Blob with no Data",
												"type": "Delete",
												"dependsOn": [],
												"policy": {
													"timeout": "0.12:00:00",
													"retry": 2,
													"retryIntervalInSeconds": 30,
													"secureOutput": false,
													"secureInput": false
												},
												"userProperties": [],
												"typeProperties": {
													"dataset": {
														"referenceName": "GenericRawJson",
														"type": "DatasetReference",
														"parameters": {
															"p_container": {
																"value": "@pipeline().parameters.c_raw_container",
																"type": "Expression"
															},
															"p_folder": {
																"value": "@concat(pipeline().parameters.c_raw_root_folder, '/',\nif(equals(length(item().target), 0), item().source, item().target))",
																"type": "Expression"
															},
															"p_file": {
																"value": "@concat(if(\n    equals(length(item().target), 0), item().source, item().target),\n    '_', variables('v_cdc_timestamp'))",
																"type": "Expression"
															}
														}
													},
													"enableLogging": false,
													"storeSettings": {
														"type": "AzureBlobFSReadSettings",
														"recursive": false,
														"enablePartitionDiscovery": false
													}
												}
											}
										],
										"ifTrueActivities": [
											{
												"name": "GetIncrementalReference",
												"type": "Script",
												"dependsOn": [],
												"policy": {
													"timeout": "0.12:00:00",
													"retry": 2,
													"retryIntervalInSeconds": 30,
													"secureOutput": false,
													"secureInput": false
												},
												"userProperties": [],
												"linkedServiceName": {
													"referenceName": "serverless_ARIR",
													"type": "LinkedServiceReference",
													"parameters": {
														"p_database": "master"
													}
												},
												"typeProperties": {
													"scripts": [
														{
															"type": "Query",
															"text": {
																"value": "@if(item().delta,\n   concat('SELECT deltaLink FROM OPENROWSET(BULK ''',\n      activity('GenericRawJson linked service').output.properties.typeProperties.url,\n      pipeline().parameters.c_raw_container, '/',\n      pipeline().parameters.c_raw_root_folder, '/',\n      item().target, '/',\n      if(equals(length(item().target), 0), item().source, item().target),\n      '_', variables('v_cdc_timestamp'), '.json', \n      ''', FORMAT = ''CSV'', FIELDQUOTE = ''0x0b'', ',\n      'FIELDTERMINATOR =''0x0b'', ROWTERMINATOR = ''\\n'') ',\n      'WITH (jsonContent nvarchar(MAX)) AS [result] ',\n      'cross apply openjson(jsonContent) with (deltaLink varchar(max) ',\n      '''$.\"', pipeline().parameters.c_delta_link_field, '\"'') ',\n      'where deltaLink is not null'\n   ),\n   'SELECT '''' as deltaLink'\n)",
																"type": "Expression"
															}
														}
													],
													"scriptBlockExecutionTimeout": "02:00:00"
												}
											},
											{
												"name": "CopyMonitoringData",
												"type": "Copy",
												"dependsOn": [
													{
														"activity": "GetIncrementalReference",
														"dependencyConditions": [
															"Succeeded"
														]
													},
													{
														"activity": "GetCDCTimeStamp",
														"dependencyConditions": [
															"Succeeded"
														]
													}
												],
												"policy": {
													"timeout": "7.00:00:00",
													"retry": 2,
													"retryIntervalInSeconds": 30,
													"secureOutput": false,
													"secureInput": false
												},
												"userProperties": [],
												"typeProperties": {
													"source": {
														"type": "JsonSource",
														"additionalColumns": [
															{
																"name": "PipelineName",
																"value": {
																	"value": "@pipeline().Pipeline",
																	"type": "Expression"
																}
															},
															{
																"name": "BlobRootDirectory",
																"value": {
																	"value": "@concat(pipeline().parameters.c_raw_root_folder)",
																	"type": "Expression"
																}
															},
															{
																"name": "DatetimeFrom",
																"value": {
																	"value": "@pipeline().parameters.p_datetime_from",
																	"type": "Expression"
																}
															},
															{
																"name": "DatetimeTo",
																"value": {
																	"value": "@pipeline().parameters.p_datetime_to",
																	"type": "Expression"
																}
															},
															{
																"name": "CDCTimestamp",
																"value": {
																	"value": "@if(\n    greaterOrEquals(\n        formatDateTime(\n            variables('v_datetime_to'), \n            'yyyy-MM-ddTHH:mm:ss.fffffffZ'\n        ), \n        activity('GetCDCTimeStamp').output.resultSets[0].rows[0].CDCTimestamp\n    ),\n    activity('GetCDCTimeStamp').output.resultSets[0].rows[0].CDCTimestamp,\n    activity('ReadMonitoringBlob').output.firstRow.CDCTimestamp\n)\n",
																	"type": "Expression"
																}
															},
															{
																"name": "CurrentUTC",
																"value": {
																	"value": "@utcnow()",
																	"type": "Expression"
																}
															},
															{
																"name": "DeltaLink",
																"value": {
																	"value": "@activity('GetIncrementalReference').output.resultSets[0].rows[0].deltaLink",
																	"type": "Expression"
																}
															},
															{
																"name": "RowCount",
																"value": {
																	"value": "@activity('countRows').output.resultSets[0].rows[0].countRows",
																	"type": "Expression"
																}
															}
														],
														"storeSettings": {
															"type": "AzureBlobFSReadSettings",
															"recursive": true,
															"enablePartitionDiscovery": false
														},
														"formatSettings": {
															"type": "JsonReadSettings"
														}
													},
													"sink": {
														"type": "JsonSink",
														"storeSettings": {
															"type": "AzureBlobFSWriteSettings"
														},
														"formatSettings": {
															"type": "JsonWriteSettings"
														}
													},
													"enableStaging": false
												},
												"inputs": [
													{
														"referenceName": "DummyJson",
														"type": "DatasetReference",
														"parameters": {}
													}
												],
												"outputs": [
													{
														"referenceName": "GenericRawJson",
														"type": "DatasetReference",
														"parameters": {
															"p_container": {
																"value": "@pipeline().parameters.c_raw_monitoring_container",
																"type": "Expression"
															},
															"p_folder": {
																"value": "@concat(pipeline().parameters.c_raw_monitoring_folder, '/',\n    pipeline().parameters.c_raw_root_folder, '/', \n    item().target)",
																"type": "Expression"
															},
															"p_file": {
																"value": "@item().target",
																"type": "Expression"
															}
														}
													}
												]
											},
											{
												"name": "GetCDCTimeStamp",
												"type": "Script",
												"dependsOn": [],
												"policy": {
													"timeout": "0.12:00:00",
													"retry": 2,
													"retryIntervalInSeconds": 30,
													"secureOutput": false,
													"secureInput": false
												},
												"userProperties": [],
												"linkedServiceName": {
													"referenceName": "serverless_ARIR",
													"type": "LinkedServiceReference",
													"parameters": {
														"p_database": "master"
													}
												},
												"typeProperties": {
													"scripts": [
														{
															"type": "Query",
															"text": {
																"value": "@if(or(item().delta, empty(item().cdcCol)),\n   concat('SELECT ''', variables('v_cdc_timestamp'), ''' as CDCTimestamp'),\n   concat('SELECT max(CDCTimestamp) CDCTimestamp ',\n      'FROM OPENROWSET(BULK ''',\n      activity('GenericRawJson linked service').output.properties.typeProperties.url,\n      pipeline().parameters.c_raw_container, '/',\n      pipeline().parameters.c_raw_root_folder, '/',\n      item().target, '/',\n      if(equals(length(item().target), 0), item().source, item().target),\n      '_', variables('v_cdc_timestamp'), '.json', \n      ''', FORMAT = ''CSV'', FIELDQUOTE = ''0x0b'', ',\n      'FIELDTERMINATOR =''0x0b'', ROWTERMINATOR = ''\\n'') ',\n      'WITH (jsonContent nvarchar(MAX)) AS [result] ',\n      'cross apply openjson(JSON_QUERY(jsonContent, ''$.value'')) ',\n      ' WITH (CDCTimestamp nvarchar(max) ''$.\"', item().cdcCol, '\"'')'\n   )\n)",
																"type": "Expression"
															}
														}
													],
													"scriptBlockExecutionTimeout": "02:00:00"
												}
											}
										]
									}
								}
							]
						}
					},
					{
						"name": "Set v_cdc_timestamp",
						"type": "SetVariable",
						"dependsOn": [],
						"policy": {
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"variableName": "v_cdc_timestamp",
							"value": {
								"value": "@if(empty(pipeline().parameters.c_cdc_timestamp), utcNow(),\npipeline().parameters.c_cdc_timestamp)",
								"type": "Expression"
							}
						}
					},
					{
						"name": "Set v_datetime_to",
						"type": "SetVariable",
						"dependsOn": [
							{
								"activity": "Set v_cdc_timestamp",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"variableName": "v_datetime_to",
							"value": {
								"value": "@if(empty(pipeline().parameters.p_datetime_to),\nvariables('v_cdc_timestamp'),\npipeline().parameters.p_datetime_to)",
								"type": "Expression"
							}
						}
					},
					{
						"name": "GenericRawJson attributes",
						"type": "WebActivity",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"method": "GET",
							"headers": {},
							"url": {
								"value": "@concat('https://', pipeline().DataFactory, '.dev.azuresynapse.net/datasets/GenericRawJson?api-version=2020-12-01')",
								"type": "Expression"
							},
							"connectVia": {
								"referenceName": "SHIR",
								"type": "IntegrationRuntimeReference"
							},
							"authentication": {
								"type": "MSI",
								"resource": "https://dev.azuresynapse.net/"
							}
						}
					},
					{
						"name": "GenericRawJson linked service",
						"type": "WebActivity",
						"dependsOn": [
							{
								"activity": "GenericRawJson attributes",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"method": "GET",
							"headers": {},
							"url": {
								"value": "@concat('https://', pipeline().DataFactory, '.dev.azuresynapse.net/linkedservices/', activity('GenericRawJson attributes').output.properties.linkedServiceName.referenceName, '?api-version=2020-12-01')",
								"type": "Expression"
							},
							"connectVia": {
								"referenceName": "SHIR",
								"type": "IntegrationRuntimeReference"
							},
							"authentication": {
								"type": "MSI",
								"resource": "https://dev.azuresynapse.net/"
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"p_datasets": {
						"type": "array",
						"defaultValue": [
							{
								"source": "dataflows",
								"target": "dataflows_REST_API",
								"path": "/",
								"delta": false,
								"crossApplyField": "value",
								"select": null,
								"filter": "api-version=2020-12-01",
								"cdcCol": null,
								"keyCol": "name",
								"relCol": null
							},
							{
								"source": "datasets",
								"target": "datasets_REST_API",
								"path": "/",
								"delta": false,
								"crossApplyField": "value",
								"select": null,
								"filter": "api-version=2020-12-01",
								"cdcCol": null,
								"keyCol": "name",
								"relCol": null
							},
							{
								"source": "datasets",
								"target": "datasets_relations11_REST_API",
								"path": "/",
								"delta": false,
								"crossApplyField": "value",
								"select": null,
								"filter": "api-version=2020-12-01",
								"cdcCol": null,
								"keyCol": "name",
								"relCol": null
							},
							{
								"source": "dataflows",
								"target": "dataflows_datasets_REST_API",
								"path": "/",
								"delta": false,
								"crossApplyField": "value",
								"select": null,
								"filter": "api-version=2020-12-01",
								"cdcCol": null,
								"keyCol": "name",
								"relCol": "properties.typeProperties.sources.dataset.referenceName"
							}
						]
					},
					"c_raw_root_folder": {
						"type": "string",
						"defaultValue": "FromRESTAPIToJson"
					},
					"c_raw_monitoring_container": {
						"type": "string",
						"defaultValue": "template"
					},
					"c_raw_container": {
						"type": "string",
						"defaultValue": "template"
					},
					"p_datetime_from": {
						"type": "string"
					},
					"p_datetime_to": {
						"type": "string"
					},
					"c_raw_monitoring_folder": {
						"type": "string",
						"defaultValue": "PipelineMonitoring"
					},
					"c_delta_link_field": {
						"type": "string"
					},
					"c_cdc_timestamp": {
						"type": "string"
					},
					"c_cdc_offset_hr": {
						"type": "int",
						"defaultValue": 0
					}
				},
				"variables": {
					"v_cdc_timestamp": {
						"type": "String"
					},
					"v_datetime_to": {
						"type": "String"
					},
					"v_monitor": {
						"type": "String"
					},
					"v_test": {
						"type": "String"
					}
				},
				"folder": {
					"name": "Templates"
				},
				"annotations": [],
				"lastPublishTime": "2023-10-16T14:40:59Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/SHIR')]",
				"[concat(variables('workspaceId'), '/datasets/azuresynapse')]",
				"[concat(variables('workspaceId'), '/datasets/GenericRawJson')]",
				"[concat(variables('workspaceId'), '/linkedServices/serverless_ARIR')]",
				"[concat(variables('workspaceId'), '/datasets/DummyJson')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/FromSQLtoRawParquet')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "ForEach in p_datasets",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Set v_cdc_timestamp",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "GenericRawParquet linked service",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@pipeline().parameters.p_datasets",
								"type": "Expression"
							},
							"activities": [
								{
									"name": "CopyDataset",
									"type": "Copy",
									"dependsOn": [
										{
											"activity": "ReadMonitoringBlob",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 2,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "SqlDWSource",
											"sqlReaderQuery": {
												"value": "select * from @{item().sourceSchema}.@{item().sourceObject}\n@{if(equals(item().processingMode, 'bulk'), '', concat(' where ', item().cdcCol, ' > ''', if(and(empty(pipeline().parameters.p_datetime_from), empty(pipeline().parameters.p_datetime_to)), activity('ReadMonitoringBlob').output.firstRow.CDCTimestamp, if(and(empty(pipeline().parameters.p_datetime_from), not(empty(pipeline().parameters.p_datetime_to))), '1900-01-01', pipeline().parameters.p_datetime_from)), ''''))}\n@{if(equals(item().processingMode, 'bulk'), '', concat(' and ', item().cdcCol, ' <= ''', if(empty(pipeline().parameters.p_datetime_to), '9999-12-31', pipeline().parameters.p_datetime_to), ''''))}\n@{if(equals(length(item().whereStatement), 0), '', concat(if(equals(item().processingMode, 'bulk'), ' where ', ' and '), item().whereStatement))}",
												"type": "Expression"
											},
											"queryTimeout": "02:00:00",
											"partitionOption": "None"
										},
										"sink": {
											"type": "ParquetSink",
											"storeSettings": {
												"type": "AzureBlobFSWriteSettings"
											},
											"formatSettings": {
												"type": "ParquetWriteSettings"
											}
										},
										"enableStaging": false,
										"translator": {
											"type": "TabularTranslator",
											"typeConversion": true,
											"typeConversionSettings": {
												"allowDataTruncation": true,
												"treatBooleanAsNumber": false
											}
										}
									},
									"inputs": [
										{
											"referenceName": "GenericServerlessSQL",
											"type": "DatasetReference",
											"parameters": {
												"p_database": {
													"value": "@pipeline().parameters.c_sql_db",
													"type": "Expression"
												},
												"p_schema": {
													"value": "@item().sourceSchema",
													"type": "Expression"
												},
												"p_table": {
													"value": "@item().sourceObject",
													"type": "Expression"
												}
											}
										}
									],
									"outputs": [
										{
											"referenceName": "GenericRawParquet",
											"type": "DatasetReference",
											"parameters": {
												"p_container": {
													"value": "@pipeline().parameters.c_raw_container",
													"type": "Expression"
												},
												"p_folder": {
													"value": "@concat(pipeline().parameters.c_raw_root_folder, '/', if(equals(length(item().target), 0), item().source, item().target))",
													"type": "Expression"
												},
												"p_file": {
													"value": "@concat(if(equals(length(item().target), 0), item().sourceObject, item().target), if(equals(item().processingMode, 'bulk'), '', concat('_', variables('v_cdc_timestamp'))))",
													"type": "Expression"
												}
											}
										}
									]
								},
								{
									"name": "CheckMonitoringBlob",
									"type": "GetMetadata",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 2,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataset": {
											"referenceName": "GenericRawJson",
											"type": "DatasetReference",
											"parameters": {
												"p_container": {
													"value": "@pipeline().parameters.c_raw_monitoring_container",
													"type": "Expression"
												},
												"p_folder": {
													"value": "@concat(pipeline().parameters.c_raw_monitoring_folder, '/',\n    pipeline().parameters.c_raw_root_folder, '/', \n    if(equals(length(item().target), 0), item().sourceObject, item().target))",
													"type": "Expression"
												},
												"p_file": {
													"value": "@if(equals(length(item().target), 0), item().sourceObject, item().target)",
													"type": "Expression"
												}
											}
										},
										"fieldList": [
											"exists"
										],
										"storeSettings": {
											"type": "AzureBlobFSReadSettings",
											"recursive": true,
											"enablePartitionDiscovery": false
										},
										"formatSettings": {
											"type": "JsonReadSettings"
										}
									}
								},
								{
									"name": "IfMonitoringBlobExists",
									"type": "IfCondition",
									"dependsOn": [
										{
											"activity": "CheckMonitoringBlob",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"userProperties": [],
									"typeProperties": {
										"expression": {
											"value": "@activity('CheckMonitoringBlob').output.exists",
											"type": "Expression"
										},
										"ifFalseActivities": [
											{
												"name": "CopyDefaultMonitoringBlob",
												"type": "Copy",
												"dependsOn": [],
												"policy": {
													"timeout": "0.12:00:00",
													"retry": 2,
													"retryIntervalInSeconds": 30,
													"secureOutput": false,
													"secureInput": false
												},
												"userProperties": [],
												"typeProperties": {
													"source": {
														"type": "JsonSource",
														"additionalColumns": [
															{
																"name": "pipelineName",
																"value": {
																	"value": "@pipeline().Pipeline",
																	"type": "Expression"
																}
															},
															{
																"name": "blobDirectory",
																"value": {
																	"value": "@concat(pipeline().parameters.c_raw_root_folder, '/', item().sourceObject)",
																	"type": "Expression"
																}
															},
															{
																"name": "datetimeFrom",
																"value": ""
															},
															{
																"name": "datetimeTo",
																"value": ""
															},
															{
																"name": "CDCTimestamp",
																"value": "1900-01-01"
															},
															{
																"name": "currentUTC",
																"value": {
																	"value": "@utcNow()",
																	"type": "Expression"
																}
															},
															{
																"name": "deltaLink",
																"value": ""
															},
															{
																"name": "rowCount",
																"value": ""
															}
														],
														"storeSettings": {
															"type": "AzureBlobFSReadSettings",
															"recursive": true,
															"enablePartitionDiscovery": false
														},
														"formatSettings": {
															"type": "JsonReadSettings"
														}
													},
													"sink": {
														"type": "JsonSink",
														"storeSettings": {
															"type": "AzureBlobFSWriteSettings"
														},
														"formatSettings": {
															"type": "JsonWriteSettings"
														}
													},
													"enableStaging": false
												},
												"inputs": [
													{
														"referenceName": "DummyJson",
														"type": "DatasetReference",
														"parameters": {}
													}
												],
												"outputs": [
													{
														"referenceName": "GenericRawJson",
														"type": "DatasetReference",
														"parameters": {
															"p_container": {
																"value": "@pipeline().parameters.c_raw_monitoring_container",
																"type": "Expression"
															},
															"p_folder": {
																"value": "@concat(pipeline().parameters.c_raw_monitoring_folder, '/',\n    pipeline().parameters.c_raw_root_folder, '/', \n    if(equals(length(item().target), 0), item().sourceObject, item().target))",
																"type": "Expression"
															},
															"p_file": {
																"value": "@if(equals(length(item().target), 0), item().sourceObject, item().target)",
																"type": "Expression"
															}
														}
													}
												]
											}
										]
									}
								},
								{
									"name": "ReadMonitoringBlob",
									"type": "Lookup",
									"dependsOn": [
										{
											"activity": "IfMonitoringBlobExists",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 2,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "JsonSource",
											"storeSettings": {
												"type": "AzureBlobFSReadSettings",
												"recursive": true,
												"enablePartitionDiscovery": false
											},
											"formatSettings": {
												"type": "JsonReadSettings"
											}
										},
										"dataset": {
											"referenceName": "GenericRawJson",
											"type": "DatasetReference",
											"parameters": {
												"p_container": {
													"value": "@pipeline().parameters.c_raw_monitoring_container",
													"type": "Expression"
												},
												"p_folder": {
													"value": "@concat(pipeline().parameters.c_raw_monitoring_folder, '/',\n    pipeline().parameters.c_raw_root_folder, '/', \n    if(equals(length(item().target), 0), item().sourceObject, item().target))",
													"type": "Expression"
												},
												"p_file": {
													"value": "@if(equals(length(item().target), 0), item().sourceObject, item().target)",
													"type": "Expression"
												}
											}
										}
									}
								},
								{
									"name": "IfRowsCopiedNotZero",
									"type": "IfCondition",
									"dependsOn": [
										{
											"activity": "CopyDataset",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"userProperties": [],
									"typeProperties": {
										"expression": {
											"value": "@greater(activity('CopyDataset').output.rowsCopied, 0)",
											"type": "Expression"
										},
										"ifFalseActivities": [
											{
												"name": "DeleteBlob",
												"type": "Delete",
												"dependsOn": [],
												"policy": {
													"timeout": "0.12:00:00",
													"retry": 2,
													"retryIntervalInSeconds": 30,
													"secureOutput": false,
													"secureInput": false
												},
												"userProperties": [],
												"typeProperties": {
													"dataset": {
														"referenceName": "GenericRawParquet",
														"type": "DatasetReference",
														"parameters": {
															"p_container": {
																"value": "@pipeline().parameters.c_raw_container",
																"type": "Expression"
															},
															"p_folder": {
																"value": "@concat(pipeline().parameters.c_raw_root_folder, '/', item().sourceObject)",
																"type": "Expression"
															},
															"p_file": {
																"value": "@concat(if(equals(length(item().target), 0), item().sourceObject, item().target), if(equals(item().processingMode, 'bulk'), '', concat('_', variables('v_cdc_timestamp'))))",
																"type": "Expression"
															}
														}
													},
													"enableLogging": false,
													"storeSettings": {
														"type": "AzureBlobFSReadSettings",
														"recursive": true,
														"enablePartitionDiscovery": false
													}
												}
											}
										],
										"ifTrueActivities": [
											{
												"name": "GetCDCTimeStamp",
												"type": "Script",
												"dependsOn": [],
												"policy": {
													"timeout": "0.12:00:00",
													"retry": 2,
													"retryIntervalInSeconds": 30,
													"secureOutput": false,
													"secureInput": false
												},
												"userProperties": [],
												"linkedServiceName": {
													"referenceName": "serverless_ARIR",
													"type": "LinkedServiceReference",
													"parameters": {
														"p_database": "master"
													}
												},
												"typeProperties": {
													"scripts": [
														{
															"type": "Query",
															"text": {
																"value": "@if(or(equals(item().processingMode, 'bulk'), not(empty(pipeline().parameters.p_datetime_to))), concat('select ''', activity('ReadMonitoringBlob').output.firstRow.CDCTimestamp, ''' CDCTimestamp'), concat('select max(', item().cdcCol, ') CDCTimestamp from OPENROWSET(BULK ''', activity('GenericRawParquet linked service').output.properties.typeProperties.url, pipeline().parameters.c_raw_container, '/', pipeline().parameters.c_raw_root_folder, '/', if(equals(length(item().target), 0), item().sourceObject, item().target), '/', if(equals(length(item().target), 0), item().sourceObject, item().target), if(equals(item().processingMode, 'bulk'), '', concat('_', variables('v_cdc_timestamp'))), '.parquet'', FORMAT = ''PARQUET'') as r'))",
																"type": "Expression"
															}
														}
													],
													"scriptBlockExecutionTimeout": "02:00:00"
												}
											},
											{
												"name": "CopyMonitoringBlob",
												"type": "Copy",
												"dependsOn": [
													{
														"activity": "GetCDCTimeStamp",
														"dependencyConditions": [
															"Succeeded"
														]
													}
												],
												"policy": {
													"timeout": "0.12:00:00",
													"retry": 2,
													"retryIntervalInSeconds": 30,
													"secureOutput": false,
													"secureInput": false
												},
												"userProperties": [],
												"typeProperties": {
													"source": {
														"type": "JsonSource",
														"additionalColumns": [
															{
																"name": "pipelineName",
																"value": {
																	"value": "@pipeline().Pipeline",
																	"type": "Expression"
																}
															},
															{
																"name": "blobDirectory",
																"value": {
																	"value": "@concat(pipeline().parameters.c_raw_root_folder, '/', item().sourceObject)",
																	"type": "Expression"
																}
															},
															{
																"name": "datetimeFrom",
																"value": {
																	"value": "@pipeline().parameters.p_datetime_from",
																	"type": "Expression"
																}
															},
															{
																"name": "datetimeTo",
																"value": {
																	"value": "@pipeline().parameters.p_datetime_to",
																	"type": "Expression"
																}
															},
															{
																"name": "CDCTimestamp",
																"value": {
																	"value": "@if(empty(pipeline().parameters.p_datetime_to), activity('GetCDCTimeStamp').output.resultSets[0].rows[0].CDCTimestamp, activity('ReadMonitoringBlob').output.firstRow.CDCTimestamp)",
																	"type": "Expression"
																}
															},
															{
																"name": "currentUTC",
																"value": {
																	"value": "@utcnow()",
																	"type": "Expression"
																}
															},
															{
																"name": "deltaLink",
																"value": ""
															},
															{
																"name": "rowCount",
																"value": {
																	"value": "@activity('CopyDataset').output.rowsCopied",
																	"type": "Expression"
																}
															}
														],
														"storeSettings": {
															"type": "AzureBlobFSReadSettings",
															"recursive": true,
															"enablePartitionDiscovery": false
														},
														"formatSettings": {
															"type": "JsonReadSettings"
														}
													},
													"sink": {
														"type": "JsonSink",
														"storeSettings": {
															"type": "AzureBlobFSWriteSettings"
														},
														"formatSettings": {
															"type": "JsonWriteSettings"
														}
													},
													"enableStaging": false
												},
												"inputs": [
													{
														"referenceName": "DummyJson",
														"type": "DatasetReference",
														"parameters": {}
													}
												],
												"outputs": [
													{
														"referenceName": "GenericRawJson",
														"type": "DatasetReference",
														"parameters": {
															"p_container": {
																"value": "@pipeline().parameters.c_raw_monitoring_container",
																"type": "Expression"
															},
															"p_folder": {
																"value": "@concat(pipeline().parameters.c_raw_monitoring_folder, '/',\n    pipeline().parameters.c_raw_root_folder, '/', \n    if(equals(length(item().target), 0), item().sourceObject, item().target))",
																"type": "Expression"
															},
															"p_file": {
																"value": "@if(equals(length(item().target), 0), item().sourceObject, item().target)",
																"type": "Expression"
															}
														}
													}
												]
											}
										]
									}
								}
							]
						}
					},
					{
						"name": "Set v_cdc_timestamp",
						"type": "SetVariable",
						"dependsOn": [],
						"policy": {
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"variableName": "v_cdc_timestamp",
							"value": {
								"value": "@utcNow()",
								"type": "Expression"
							}
						}
					},
					{
						"name": "GenericRawParquet attributes",
						"type": "WebActivity",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"method": "GET",
							"headers": {},
							"url": {
								"value": "@concat('https://', pipeline().DataFactory, '.dev.azuresynapse.net/datasets/GenericRawParquet?api-version=2020-12-01')",
								"type": "Expression"
							},
							"connectVia": {
								"referenceName": "SHIR",
								"type": "IntegrationRuntimeReference"
							},
							"authentication": {
								"type": "MSI",
								"resource": "https://dev.azuresynapse.net/"
							}
						}
					},
					{
						"name": "GenericRawParquet linked service",
						"type": "WebActivity",
						"dependsOn": [
							{
								"activity": "GenericRawParquet attributes",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"method": "GET",
							"headers": {},
							"url": {
								"value": "@concat('https://', pipeline().DataFactory, '.dev.azuresynapse.net/linkedservices/', activity('GenericRawParquet attributes').output.properties.linkedServiceName.referenceName, '?api-version=2020-12-01')",
								"type": "Expression"
							},
							"connectVia": {
								"referenceName": "SHIR",
								"type": "IntegrationRuntimeReference"
							},
							"authentication": {
								"type": "MSI",
								"resource": "https://dev.azuresynapse.net/"
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"p_datasets": {
						"type": "array",
						"defaultValue": [
							{
								"sourceObject": "dataflows_REST_API",
								"sourceSchema": "enr",
								"whereStatement": "",
								"target": "dataflows_SQL",
								"processingMode": "bulk",
								"cdcCol": ""
							},
							{
								"sourceObject": "datasets_REST_API",
								"sourceSchema": "enr",
								"whereStatement": "lower(name) like '%template%' or lower(name) like '%generic%'",
								"target": "datasets_SQL",
								"processingMode": "bulk",
								"cdcCol": ""
							},
							{
								"sourceObject": "datasets_relations11_REST_API",
								"sourceSchema": "enr",
								"whereStatement": "",
								"target": "datasets_relations11_SQL",
								"processingMode": "incremental",
								"cdcCol": "enrTimestamp"
							},
							{
								"sourceObject": "dataflows_datasets_REST_API",
								"sourceSchema": "enr",
								"whereStatement": "",
								"target": "dataflows_datasets_SQL",
								"processingMode": "incremental",
								"cdcCol": "enrTimestamp"
							}
						]
					},
					"c_raw_container": {
						"type": "string",
						"defaultValue": "template"
					},
					"c_raw_root_folder": {
						"type": "string",
						"defaultValue": "FromSQLToParquet"
					},
					"p_datetime_from": {
						"type": "string"
					},
					"p_datetime_to": {
						"type": "string"
					},
					"c_raw_monitoring_container": {
						"type": "string",
						"defaultValue": "template"
					},
					"c_raw_monitoring_folder": {
						"type": "string",
						"defaultValue": "PipelineMonitoring"
					},
					"c_sql_db": {
						"type": "string",
						"defaultValue": "templateDB"
					}
				},
				"variables": {
					"v_cdc_timestamp": {
						"type": "String"
					}
				},
				"folder": {
					"name": "Templates"
				},
				"annotations": [],
				"lastPublishTime": "2023-10-16T14:40:59Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/SHIR')]",
				"[concat(variables('workspaceId'), '/datasets/GenericServerlessSQL')]",
				"[concat(variables('workspaceId'), '/datasets/GenericRawParquet')]",
				"[concat(variables('workspaceId'), '/datasets/GenericRawJson')]",
				"[concat(variables('workspaceId'), '/datasets/DummyJson')]",
				"[concat(variables('workspaceId'), '/linkedServices/serverless_ARIR')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQLPoolStartStop')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Use p_action = 'resume' to start or 'pause to stop dedicated SQL pool",
				"activities": [
					{
						"name": "If not PROD",
						"type": "IfCondition",
						"dependsOn": [
							{
								"activity": "FilterSystem",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"expression": {
								"value": "@equals(activity('FilterSystem').output.FilteredItemsCount, 0)",
								"type": "Expression"
							},
							"ifFalseActivities": [
								{
									"name": "Start SQL Pool",
									"type": "WebActivity",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 2,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"method": "POST",
										"headers": {},
										"url": {
											"value": "@concat('https://management.azure.com/subscriptions/', \nactivity('FilterSystem').output.Value[0].subscriptionId, \n'/resourceGroups/', \nactivity('FilterSystem').output.Value[0].resourceGroup, \n'/providers/Microsoft.Synapse/workspaces/', \npipeline().DataFactory, \n'/sqlPools/', activity('FilterSystem').output.Value[0].sqlPool,\n'/', pipeline().parameters.p_action, '?api-version=2019-06-01-preview')",
											"type": "Expression"
										},
										"connectVia": {
											"referenceName": "SHIR",
											"type": "IntegrationRuntimeReference"
										},
										"body": "'{ }'",
										"authentication": {
											"type": "MSI",
											"resource": "https://management.azure.com/"
										}
									}
								}
							]
						}
					},
					{
						"name": "FilterSystem",
						"type": "Filter",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@pipeline().parameters.c_system_landscape",
								"type": "Expression"
							},
							"condition": {
								"value": "@equals(item().SynapseWorkspace, pipeline().DataFactory)",
								"type": "Expression"
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"p_action": {
						"type": "string",
						"defaultValue": "pause"
					},
					"c_system_landscape": {
						"type": "array",
						"defaultValue": [
							{
								"environment": "DV",
								"SynapseWorkspace": "ivs-synapse",
								"resourceGroup": "ivs-dwh-rg",
								"subscriptionId": "f939f8f3-2652-4a45-88ae-78a7782ec9df",
								"sqlPool": "ivssql"
							}
						]
					}
				},
				"folder": {
					"name": "Templates"
				},
				"annotations": [],
				"lastPublishTime": "2023-10-16T14:39:39Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/SHIR')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ServerlessDBDeploy')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Pipeline runs automatically after release deploy to create serverless DB, master key and default credentials",
				"activities": [
					{
						"name": "ForEachServerlessDB",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "FilterKeyVault",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@pipeline().parameters.p_serverless_db",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "MasterKeySecret",
									"type": "WebActivity",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 2,
										"retryIntervalInSeconds": 30,
										"secureOutput": true,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"method": "GET",
										"headers": {},
										"url": {
											"value": "@concat(activity('FilterKeyVault').output.Value[0].properties.typeProperties.baseUrl,\n'secrets/', item().MasterKeySecret, '?api-version=7.3')",
											"type": "Expression"
										},
										"connectVia": {
											"referenceName": "SHIR",
											"type": "IntegrationRuntimeReference"
										},
										"authentication": {
											"type": "MSI",
											"resource": "https://vault.azure.net"
										}
									}
								},
								{
									"name": "ServerlessDBCreate",
									"type": "Script",
									"dependsOn": [
										{
											"activity": "MasterKeySecret",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 2,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "serverless_ARIR",
										"type": "LinkedServiceReference",
										"parameters": {
											"p_database": "master"
										}
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "NonQuery",
												"text": {
													"value": "if not exists (select name from sys.databases WHERE name = '@{item().serverlessDB}')\nbegin create database @{item().serverlessDB} end\n",
													"type": "Expression"
												}
											}
										],
										"scriptBlockExecutionTimeout": "02:00:00"
									}
								},
								{
									"name": "ServerlessDBCredentials",
									"type": "Script",
									"dependsOn": [
										{
											"activity": "ServerlessDBCreate",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 2,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": true
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "serverless_ARIR",
										"type": "LinkedServiceReference",
										"parameters": {
											"p_database": {
												"value": "@item().serverlessDB",
												"type": "Expression"
											}
										}
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "NonQuery",
												"text": {
													"value": "IF NOT EXISTS (SELECT [name] from sys.symmetric_keys WHERE [name] = '##MS_DatabaseMasterKey##')\nBEGIN CREATE MASTER KEY ENCRYPTION BY PASSWORD = '@{activity('MasterKeySecret').output.value}' END\n\nIF NOT EXISTS (SELECT [name] from sys.database_scoped_credentials WHERE [name] = '@{item().scopedCredential}')\nBEGIN CREATE DATABASE SCOPED CREDENTIAL @{item().scopedCredential} WITH IDENTITY = 'Managed Identity'  END \n",
													"type": "Expression"
												}
											}
										],
										"scriptBlockExecutionTimeout": "02:00:00"
									}
								}
							]
						}
					},
					{
						"name": "LinkedServiceList",
						"description": "",
						"type": "WebActivity",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 2,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"method": "GET",
							"headers": {},
							"url": {
								"value": "@concat('https://', pipeline().DataFactory, \n'.dev.azuresynapse.net/linkedservices?api-version=2020-12-01')",
								"type": "Expression"
							},
							"connectVia": {
								"referenceName": "SHIR",
								"type": "IntegrationRuntimeReference"
							},
							"authentication": {
								"type": "MSI",
								"resource": "https://dev.azuresynapse.net"
							}
						}
					},
					{
						"name": "FilterKeyVault",
						"type": "Filter",
						"dependsOn": [
							{
								"activity": "LinkedServiceList",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('LinkedServiceList').output.value",
								"type": "Expression"
							},
							"condition": {
								"value": "@and(equals(item().properties.type, 'AzureKeyVault'), equals(item().name, pipeline().parameters.p_key_vault_linked_service))",
								"type": "Expression"
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"p_serverless_db": {
						"type": "array",
						"defaultValue": [
							{
								"serverlessDB": "templateDB",
								"masterkeySecret": "template-sqlpool-master-key",
								"scopedCredential": "SynapseIdentity"
							}
						]
					},
					"p_key_vault_linked_service": {
						"type": "string",
						"defaultValue": "ivs_dwh_kv"
					}
				},
				"variables": {
					"v_test": {
						"type": "String"
					}
				},
				"folder": {
					"name": "Templates"
				},
				"annotations": [],
				"lastPublishTime": "2023-10-16T14:40:16Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/SHIR')]",
				"[concat(variables('workspaceId'), '/linkedServices/serverless_ARIR')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/StarSchemaDimension')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "StarSchemaDimension",
						"type": "ExecuteDataFlow",
						"dependsOn": [
							{
								"activity": "If Target Delta Exists",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "StarSchemaDimension",
								"type": "DataFlowReference",
								"parameters": {
									"p_src_key_cols": {
										"value": "@pipeline().parameters.p_src_key_cols",
										"type": "Expression"
									},
									"p_src_cdc_col": {
										"value": "'@{pipeline().parameters.p_src_cdc_col}'",
										"type": "Expression"
									},
									"p_surrogate_key_col": {
										"value": "'@{pipeline().parameters.p_surrogate_key_col}'",
										"type": "Expression"
									},
									"c_trg_dss_update_col": {
										"value": "'@{pipeline().parameters.c_trg_dss_update_col}'",
										"type": "Expression"
									},
									"c_trg_dss_create_col": {
										"value": "'@{pipeline().parameters.c_trg_dss_create_col}'",
										"type": "Expression"
									},
									"p_partition_formula": {
										"value": "@concat('\"', pipeline().parameters.p_partition_formula, '\"')",
										"type": "Expression"
									},
									"c_trg_partition_col": {
										"value": "'@{pipeline().parameters.c_trg_partition_col}'",
										"type": "Expression"
									},
									"p_src_schema": {
										"value": "'@{pipeline().parameters.p_src_schema}'",
										"type": "Expression"
									},
									"p_src_object": {
										"value": "'@{pipeline().parameters.p_src_object}'",
										"type": "Expression"
									},
									"p_datetime_from": {
										"value": "'@{variables('v_datetime_from')}'",
										"type": "Expression"
									},
									"p_trg_table": {
										"value": "'@{pipeline().parameters.p_trg_table}'",
										"type": "Expression"
									},
									"p_init_load": {
										"value": "@not(activity('GetTargetDeltaMetadata').output.exists)",
										"type": "Expression"
									},
									"c_trg_container": {
										"value": "'@{pipeline().parameters.c_trg_container}'",
										"type": "Expression"
									},
									"c_trg_root_folder": {
										"value": "'@{pipeline().parameters.c_trg_root_folder}'",
										"type": "Expression"
									}
								},
								"datasetParameters": {
									"DataSource": {
										"p_database": {
											"value": "@pipeline().parameters.c_serverless_db",
											"type": "Expression"
										},
										"p_schema": "dummy",
										"p_table": "dummy"
									},
									"Dimension": {
										"p_database": {
											"value": "@pipeline().parameters.c_serverless_db",
											"type": "Expression"
										},
										"p_schema": "dummy",
										"p_table": "dummy"
									},
									"DimensionMaxKey": {
										"p_database": {
											"value": "@pipeline().parameters.c_serverless_db",
											"type": "Expression"
										},
										"p_schema": "dummy",
										"p_table": "dummy"
									},
									"DimensionZeroRow": {
										"p_database": {
											"value": "@pipeline().parameters.c_serverless_db",
											"type": "Expression"
										},
										"p_schema": "dummy",
										"p_table": "dummy"
									},
									"SourcePartitionPruning": {
										"p_database": {
											"value": "@pipeline().parameters.c_serverless_db",
											"type": "Expression"
										},
										"p_schema": "dummy",
										"p_table": "dummy"
									},
									"dummyPartitionPruning": {
										"p_database": {
											"value": "@pipeline().parameters.c_serverless_db",
											"type": "Expression"
										},
										"p_schema": "dummy",
										"p_table": "dummy"
									},
									"CacheMaxKey": {},
									"sinkZeroRecord": {},
									"sinkDimension": {},
									"sinkPartitionPruning": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					},
					{
						"name": "GetTargetDeltaMetadata",
						"type": "GetMetadata",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "GenericCuratedJsonFolder",
								"type": "DatasetReference",
								"parameters": {
									"p_container": {
										"value": "@pipeline().parameters.c_trg_container",
										"type": "Expression"
									},
									"p_folder": {
										"value": "@concat(pipeline().parameters.c_trg_root_folder, '/', pipeline().parameters.p_trg_table)",
										"type": "Expression"
									}
								}
							},
							"fieldList": [
								"exists"
							],
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							},
							"formatSettings": {
								"type": "JsonReadSettings"
							}
						}
					},
					{
						"name": "If Target Delta Exists",
						"type": "IfCondition",
						"dependsOn": [
							{
								"activity": "GetTargetDeltaMetadata",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "GenericCuratedParquet linked service",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"expression": {
								"value": "@and(activity('GetTargetDeltaMetadata').output.exists, not(empty(pipeline().parameters.p_src_cdc_col)))",
								"type": "Expression"
							},
							"ifFalseActivities": [
								{
									"name": "Set v_datetime_from False",
									"type": "SetVariable",
									"dependsOn": [],
									"policy": {
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"variableName": "v_datetime_from",
										"value": {
											"value": "@pipeline().parameters.p_datetime_from",
											"type": "Expression"
										}
									}
								}
							],
							"ifTrueActivities": [
								{
									"name": "DatetimeFrom",
									"type": "Script",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 2,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "serverless_ARIR",
										"type": "LinkedServiceReference",
										"parameters": {
											"p_database": {
												"value": "@pipeline().parameters.c_serverless_db",
												"type": "Expression"
											}
										}
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "Query",
												"text": {
													"value": "@if(empty(pipeline().parameters.p_datetime_from),\n    concat('select max(', pipeline().parameters.p_src_cdc_col, ') as CDCTimestamp from openrowset( bulk ''',activity('GenericCuratedParquet linked service').output.properties.typeProperties.url, pipeline().parameters.c_trg_container, '/', pipeline().parameters.c_trg_root_folder, '/', pipeline().parameters.p_trg_table, ''', format = ''DELTA'') as result'),\n    concat('select ''', replace(replace(replace(replace(replace(\n                    formatDateTime(\n                        pipeline().parameters.p_datetime_from, \n                        'yyyy-MM-ddTHH:mm:ss.fffffffZ'\n                    ), \n                    '0000Z', 'Z'), '000Z', 'Z'), '00Z', 'Z'), '0Z', 'Z'), '.Z', 'Z'\n                ),\n        ''' as CDCTimestamp'\n    )\n)",
													"type": "Expression"
												}
											}
										],
										"scriptBlockExecutionTimeout": "02:00:00"
									}
								},
								{
									"name": "Set v_datetime_from True",
									"type": "SetVariable",
									"dependsOn": [
										{
											"activity": "DatetimeFrom",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"variableName": "v_datetime_from",
										"value": {
											"value": "@activity('DatetimeFrom').output.resultSets[0].rows[0].CDCTimestamp",
											"type": "Expression"
										}
									}
								}
							]
						}
					},
					{
						"name": "GenericCuratedParquet attributes",
						"type": "WebActivity",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"method": "GET",
							"headers": {},
							"url": {
								"value": "@concat('https://', pipeline().DataFactory, '.dev.azuresynapse.net/datasets/GenericCuratedParquet?api-version=2020-12-01')",
								"type": "Expression"
							},
							"connectVia": {
								"referenceName": "SHIR",
								"type": "IntegrationRuntimeReference"
							},
							"authentication": {
								"type": "MSI",
								"resource": "https://dev.azuresynapse.net/"
							}
						}
					},
					{
						"name": "GenericCuratedParquet linked service",
						"type": "WebActivity",
						"dependsOn": [
							{
								"activity": "GenericCuratedParquet attributes",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"method": "GET",
							"headers": {},
							"url": {
								"value": "@concat('https://', pipeline().DataFactory, '.dev.azuresynapse.net/linkedservices/', activity('GenericCuratedParquet attributes').output.properties.linkedServiceName.referenceName, '?api-version=2020-12-01')",
								"type": "Expression"
							},
							"connectVia": {
								"referenceName": "SHIR",
								"type": "IntegrationRuntimeReference"
							},
							"authentication": {
								"type": "MSI",
								"resource": "https://dev.azuresynapse.net/"
							}
						}
					},
					{
						"name": "createTmpView",
						"type": "Script",
						"dependsOn": [
							{
								"activity": "StarSchemaDimension",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 2,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"linkedServiceName": {
							"referenceName": "serverless_ARIR",
							"type": "LinkedServiceReference",
							"parameters": {
								"p_database": {
									"value": "@pipeline().parameters.c_serverless_db",
									"type": "Expression"
								}
							}
						},
						"typeProperties": {
							"scripts": [
								{
									"type": "Query",
									"text": {
										"value": "create or alter view \n@{pipeline().parameters.p_trg_table}_tmp\nas select * from OPENROWSET(\n\tBULK '@{activity('GenericCuratedParquet linked service').output.properties.typeProperties.url}@{pipeline().parameters.c_trg_container}/@{pipeline().parameters.c_trg_root_folder}/@{pipeline().parameters.p_trg_table}',\n\tFORMAT = 'Delta'\n) as r",
										"type": "Expression"
									}
								}
							],
							"scriptBlockExecutionTimeout": "02:00:00"
						}
					},
					{
						"name": "ExternalTableSQL",
						"type": "Script",
						"dependsOn": [
							{
								"activity": "createTmpView",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"linkedServiceName": {
							"referenceName": "serverless_ARIR",
							"type": "LinkedServiceReference",
							"parameters": {
								"p_database": {
									"value": "@pipeline().parameters.c_serverless_db",
									"type": "Expression"
								}
							}
						},
						"typeProperties": {
							"scripts": [
								{
									"type": "Query",
									"text": {
										"value": "select 'CREATE EXTERNAL TABLE ' +\n'@{pipeline().parameters.p_trg_table} (' + \nchar(10) +\nSTRING_AGG('[' + \ncast(colName as varchar(max)) + '] ' + \ndataType, ',' + char(10)) \nWITHIN GROUP (ORDER BY column_id ASC) + char(10) +\n') WITH (LOCATION = ''@{pipeline().parameters.c_trg_root_folder}/@{pipeline().parameters.p_trg_table}'', DATA_SOURCE = @{pipeline().parameters.c_cur_data_source},  FILE_FORMAT = Delta)' as SQL\nfrom (select \nc.name colName, coalesce(r.dataType,\nCASE \n      WHEN t.[name] IN ('varchar', 'char', 'varbinary') THEN t.[name] + '(' + IIF(c.max_length = -1, 'max', CAST(c.max_length AS VARCHAR(25))) + ')' \n      WHEN t.[name] IN ('nvarchar','nchar') THEN t.[name] + '(' + IIF(c.max_length = -1, 'max', CAST(c.max_length / 2 AS VARCHAR(25)))+ ')'      \n      WHEN t.[name] IN ('decimal', 'numeric') THEN t.[name] + '(' + CAST(c.[precision] AS VARCHAR(25)) + ', ' + CAST(c.[scale] AS VARCHAR(25)) + ')'\n      WHEN t.[name] IN ('datetime2') THEN t.[name] + '(' + CAST(c.[scale] AS VARCHAR(25)) + ')'\n      ELSE t.[name]\nEND) AS dataType,\nc.column_id\nfrom sys.columns c\njoin sys.views v on v.object_id = c.object_id\njoin sys.schemas s on s.schema_id = v.schema_id\njoin sys.types t on c.user_type_id = t.user_type_id \nleft outer join \n@{if(empty(pipeline().parameters.p_data_type_replace), \n'(select null col, null dataType) r',\nconcat('(select * from OpenJson(N''',\nstring(pipeline().parameters.p_data_type_replace),\n''') WITH (col varchar(255), dataType varchar(255)) as r) r'))}\non r.col = c.name\nwhere s.name = 'dbo' and c.name <> '@{pipeline().parameters.c_trg_partition_col}' and v.name = \n'@{pipeline().parameters.p_trg_table}_tmp') q",
										"type": "Expression"
									}
								}
							],
							"scriptBlockExecutionTimeout": "02:00:00"
						}
					},
					{
						"name": "CreateExternalTable",
						"type": "Script",
						"dependsOn": [
							{
								"activity": "ExternalTableSQL",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"linkedServiceName": {
							"referenceName": "serverless_ARIR",
							"type": "LinkedServiceReference",
							"parameters": {
								"p_database": {
									"value": "@pipeline().parameters.c_serverless_db",
									"type": "Expression"
								}
							}
						},
						"typeProperties": {
							"scripts": [
								{
									"type": "Query",
									"text": {
										"value": "begin transaction\n\nif exists (select * from sys.external_tables t join sys.schemas s on s.schema_id = t.schema_id where s.name = 'dbo' and t.name = '@{pipeline().parameters.p_trg_table}')\ndrop external table @{pipeline().parameters.p_trg_table};\n\n@{activity('ExternalTableSQL').output.resultSets[0].rows[0].SQL};\n\ndrop view @{pipeline().parameters.p_trg_table}_tmp;\n\ncommit;\n",
										"type": "Expression"
									}
								}
							],
							"scriptBlockExecutionTimeout": "02:00:00"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"p_trg_table": {
						"type": "string",
						"defaultValue": "DimDataflows"
					},
					"p_datetime_from": {
						"type": "string"
					},
					"p_surrogate_key_col": {
						"type": "string",
						"defaultValue": "dataflows_key"
					},
					"p_src_schema": {
						"type": "string",
						"defaultValue": "enr"
					},
					"p_src_object": {
						"type": "string",
						"defaultValue": "dataflows_REST_API"
					},
					"p_src_key_cols": {
						"type": "array",
						"defaultValue": [
							"name"
						]
					},
					"p_src_cdc_col": {
						"type": "string",
						"defaultValue": "enrTimestamp"
					},
					"p_data_type_replace": {
						"type": "array",
						"defaultValue": [
							{
								"col": "name",
								"dataType": "varchar(255)"
							}
						]
					},
					"p_partition_formula": {
						"type": "string",
						"defaultValue": "'dummy'"
					},
					"c_serverless_db": {
						"type": "string",
						"defaultValue": "templateDB"
					},
					"c_trg_container": {
						"type": "string",
						"defaultValue": "template"
					},
					"c_trg_root_folder": {
						"type": "string",
						"defaultValue": "StarSchemaObjects"
					},
					"c_cur_data_source": {
						"type": "string",
						"defaultValue": "TemplateCuratedSource"
					},
					"c_trg_partition_col": {
						"type": "string",
						"defaultValue": "DIM_PARTITION"
					},
					"c_trg_dss_update_col": {
						"type": "string",
						"defaultValue": "dss_update_time"
					},
					"c_trg_dss_create_col": {
						"type": "string",
						"defaultValue": "dss_create_time"
					}
				},
				"variables": {
					"v_datetime_from": {
						"type": "String"
					}
				},
				"folder": {
					"name": "Templates"
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/dataflows/StarSchemaDimension')]",
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]",
				"[concat(variables('workspaceId'), '/datasets/GenericCuratedJsonFolder')]",
				"[concat(variables('workspaceId'), '/integrationRuntimes/SHIR')]",
				"[concat(variables('workspaceId'), '/linkedServices/serverless_ARIR')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/StarSchemaFact')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "GetTargetDeltaMetadata",
						"type": "GetMetadata",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "GenericCuratedJsonFolder",
								"type": "DatasetReference",
								"parameters": {
									"p_container": {
										"value": "@pipeline().parameters.c_trg_container",
										"type": "Expression"
									},
									"p_folder": {
										"value": "@concat(pipeline().parameters.c_trg_root_folder, '/', pipeline().parameters.p_trg_table)",
										"type": "Expression"
									}
								}
							},
							"fieldList": [
								"exists"
							],
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							},
							"formatSettings": {
								"type": "JsonReadSettings"
							}
						}
					},
					{
						"name": "If Target Delta Exists",
						"type": "IfCondition",
						"dependsOn": [
							{
								"activity": "GetTargetDeltaMetadata",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "GenericCuratedParquet linked service",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"expression": {
								"value": "@and(activity('GetTargetDeltaMetadata').output.exists, not(empty(pipeline().parameters.p_src_cdc_col)))",
								"type": "Expression"
							},
							"ifFalseActivities": [
								{
									"name": "Set v_datetime_from False",
									"type": "SetVariable",
									"dependsOn": [],
									"policy": {
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"variableName": "v_datetime_from",
										"value": {
											"value": "@pipeline().parameters.p_datetime_from",
											"type": "Expression"
										}
									}
								}
							],
							"ifTrueActivities": [
								{
									"name": "DatetimeFrom",
									"type": "Script",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 2,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "serverless_ARIR",
										"type": "LinkedServiceReference",
										"parameters": {
											"p_database": {
												"value": "@pipeline().parameters.c_serverless_db",
												"type": "Expression"
											}
										}
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "Query",
												"text": {
													"value": "@if(empty(pipeline().parameters.p_datetime_from),\n    concat('select max(', pipeline().parameters.p_src_cdc_col, ') as CDCTimestamp from openrowset( bulk ''',activity('GenericCuratedParquet linked service').output.properties.typeProperties.url, pipeline().parameters.c_trg_container, '/', pipeline().parameters.c_trg_root_folder, '/', pipeline().parameters.p_trg_table, ''', format = ''DELTA'') as result'),\n    concat('select ''', replace(replace(replace(replace(replace(\n                    formatDateTime(\n                        pipeline().parameters.p_datetime_from, \n                        'yyyy-MM-ddTHH:mm:ss.fffffffZ'\n                    ), \n                    '0000Z', 'Z'), '000Z', 'Z'), '00Z', 'Z'), '0Z', 'Z'), '.Z', 'Z'\n                ),\n        ''' as CDCTimestamp'\n    )\n)",
													"type": "Expression"
												}
											}
										],
										"scriptBlockExecutionTimeout": "02:00:00"
									}
								},
								{
									"name": "Set v_datetime_from True",
									"type": "SetVariable",
									"dependsOn": [
										{
											"activity": "DatetimeFrom",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"variableName": "v_datetime_from",
										"value": {
											"value": "@activity('DatetimeFrom').output.resultSets[0].rows[0].CDCTimestamp",
											"type": "Expression"
										}
									}
								}
							]
						}
					},
					{
						"name": "GenericCuratedParquet attributes",
						"type": "WebActivity",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"method": "GET",
							"headers": {},
							"url": {
								"value": "@concat('https://', pipeline().DataFactory, '.dev.azuresynapse.net/datasets/GenericCuratedParquet?api-version=2020-12-01')",
								"type": "Expression"
							},
							"connectVia": {
								"referenceName": "SHIR",
								"type": "IntegrationRuntimeReference"
							},
							"authentication": {
								"type": "MSI",
								"resource": "https://dev.azuresynapse.net/"
							}
						}
					},
					{
						"name": "GenericCuratedParquet linked service",
						"type": "WebActivity",
						"dependsOn": [
							{
								"activity": "GenericCuratedParquet attributes",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"method": "GET",
							"headers": {},
							"url": {
								"value": "@concat('https://', pipeline().DataFactory, '.dev.azuresynapse.net/linkedservices/', activity('GenericCuratedParquet attributes').output.properties.linkedServiceName.referenceName, '?api-version=2020-12-01')",
								"type": "Expression"
							},
							"connectVia": {
								"referenceName": "SHIR",
								"type": "IntegrationRuntimeReference"
							},
							"authentication": {
								"type": "MSI",
								"resource": "https://dev.azuresynapse.net/"
							}
						}
					},
					{
						"name": "StagingParquet",
						"type": "Copy",
						"dependsOn": [
							{
								"activity": "If Target Delta Exists",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "SqlDWSource",
								"sqlReaderQuery": {
									"value": "select * from @{pipeline().parameters.p_src_schema}.@{pipeline().parameters.p_src_object} \nwhere @{pipeline().parameters.p_src_cdc_col} > '@{variables('v_datetime_from')}'",
									"type": "Expression"
								},
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"sink": {
								"type": "ParquetSink",
								"storeSettings": {
									"type": "AzureBlobFSWriteSettings"
								},
								"formatSettings": {
									"type": "ParquetWriteSettings"
								}
							},
							"enableStaging": false,
							"translator": {
								"type": "TabularTranslator",
								"typeConversion": true,
								"typeConversionSettings": {
									"allowDataTruncation": true,
									"treatBooleanAsNumber": false
								}
							}
						},
						"inputs": [
							{
								"referenceName": "GenericServerlessSQL",
								"type": "DatasetReference",
								"parameters": {
									"p_database": {
										"value": "@pipeline().parameters.c_serverless_db",
										"type": "Expression"
									},
									"p_schema": {
										"value": "@pipeline().parameters.p_src_schema",
										"type": "Expression"
									},
									"p_table": {
										"value": "@pipeline().parameters.p_src_object",
										"type": "Expression"
									}
								}
							}
						],
						"outputs": [
							{
								"referenceName": "GenericEnrichedParquet",
								"type": "DatasetReference",
								"parameters": {
									"p_container": {
										"value": "@pipeline().parameters.c_stg_container",
										"type": "Expression"
									},
									"p_folder": {
										"value": "@pipeline().parameters.c_stg_root_folder",
										"type": "Expression"
									},
									"p_file": {
										"value": "@concat(pipeline().parameters.p_trg_table, 'Stg')",
										"type": "Expression"
									}
								}
							}
						]
					},
					{
						"name": "If RowCount above 0",
						"type": "IfCondition",
						"dependsOn": [
							{
								"activity": "StagingParquet",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "GenericEnrichedParquet linked service",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"expression": {
								"value": "@greater(activity('StagingParquet').output.rowsCopied, 0)",
								"type": "Expression"
							},
							"ifTrueActivities": [
								{
									"name": "StarSchemaDimension",
									"type": "ExecuteDataFlow",
									"dependsOn": [
										{
											"activity": "ScriptStagingDimKeysSQL",
											"dependencyConditions": [
												"Succeeded"
											]
										},
										{
											"activity": "ScriptFactCreateTime",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataflow": {
											"referenceName": "StarSchemaFact",
											"type": "DataFlowReference",
											"parameters": {
												"p_src_key_cols": {
													"value": "@pipeline().parameters.p_src_key_cols",
													"type": "Expression"
												},
												"c_trg_dss_update_col": {
													"value": "'@{pipeline().parameters.c_trg_dss_update_col}'",
													"type": "Expression"
												},
												"c_trg_dss_create_col": {
													"value": "'@{pipeline().parameters.c_trg_dss_create_col}'",
													"type": "Expression"
												},
												"p_partition_formula": {
													"value": "@concat('\"', pipeline().parameters.p_partition_formula, '\"')",
													"type": "Expression"
												},
												"c_trg_partition_col": {
													"value": "'@{pipeline().parameters.c_trg_partition_col}'",
													"type": "Expression"
												},
												"p_trg_table": {
													"value": "'@{pipeline().parameters.p_trg_table}'",
													"type": "Expression"
												},
												"c_trg_container": {
													"value": "'@{pipeline().parameters.c_trg_container}'",
													"type": "Expression"
												},
												"c_trg_root_folder": {
													"value": "'@{pipeline().parameters.c_trg_root_folder}'",
													"type": "Expression"
												},
												"p_src_query": {
													"value": "@concat('\"', activity('ScriptStagingDimKeysSQL').output.resultSets[0].rows[0].sourceQuery, '\"')",
													"type": "Expression"
												},
												"p_trg_query": {
													"value": "@concat('\"', activity('ScriptFactCreateTime').output.resultSets[0].rows[0].targetQuery, '\"')",
													"type": "Expression"
												}
											},
											"datasetParameters": {
												"DataSource": {
													"p_database": {
														"value": "@pipeline().parameters.c_serverless_db",
														"type": "Expression"
													},
													"p_schema": "dummy",
													"p_table": "dummy"
												},
												"Fact": {
													"p_database": {
														"value": "@pipeline().parameters.c_serverless_db",
														"type": "Expression"
													},
													"p_schema": "dummy",
													"p_table": "dummy"
												},
												"SourcePartitionPruning": {
													"p_database": {
														"value": "@pipeline().parameters.c_serverless_db",
														"type": "Expression"
													},
													"p_schema": "dummy",
													"p_table": "dummy"
												},
												"dummyPartitionPruning": {
													"p_database": {
														"value": "@pipeline().parameters.c_serverless_db",
														"type": "Expression"
													},
													"p_schema": "dummy",
													"p_table": "dummy"
												},
												"sinkDimension": {},
												"sinkPartitionPruning": {}
											},
											"linkedServiceParameters": {}
										},
										"staging": {},
										"compute": {
											"coreCount": 8,
											"computeType": "General"
										},
										"traceLevel": "Fine"
									}
								},
								{
									"name": "createTmpView",
									"type": "Script",
									"dependsOn": [
										{
											"activity": "StarSchemaDimension",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 2,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "serverless_ARIR",
										"type": "LinkedServiceReference",
										"parameters": {
											"p_database": {
												"value": "@pipeline().parameters.c_serverless_db",
												"type": "Expression"
											}
										}
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "Query",
												"text": {
													"value": "create or alter view \n@{pipeline().parameters.p_trg_table}_tmp\nas select * from OPENROWSET(\n\tBULK '@{activity('GenericCuratedParquet linked service').output.properties.typeProperties.url}@{pipeline().parameters.c_trg_container}/@{pipeline().parameters.c_trg_root_folder}/@{pipeline().parameters.p_trg_table}',\n\tFORMAT = 'Delta'\n) as r",
													"type": "Expression"
												}
											}
										],
										"scriptBlockExecutionTimeout": "02:00:00"
									}
								},
								{
									"name": "ExternalTableSQL",
									"type": "Script",
									"dependsOn": [
										{
											"activity": "createTmpView",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "serverless_ARIR",
										"type": "LinkedServiceReference",
										"parameters": {
											"p_database": {
												"value": "@pipeline().parameters.c_serverless_db",
												"type": "Expression"
											}
										}
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "Query",
												"text": {
													"value": "select 'CREATE EXTERNAL TABLE ' +\n'@{pipeline().parameters.p_trg_table} (' + \nchar(10) +\nSTRING_AGG('[' + \ncast(colName as varchar(max)) + '] ' + \ndataType, ',' + char(10)) \nWITHIN GROUP (ORDER BY column_id ASC) + char(10) +\n') WITH (LOCATION = ''@{pipeline().parameters.c_trg_root_folder}/@{pipeline().parameters.p_trg_table}'', DATA_SOURCE = @{pipeline().parameters.c_cur_data_source},  FILE_FORMAT = Delta)' as SQL\nfrom (select \nc.name colName, coalesce(r.dataType,\nCASE \n      WHEN t.[name] IN ('varchar', 'char', 'varbinary') THEN t.[name] + '(' + IIF(c.max_length = -1, 'max', CAST(c.max_length AS VARCHAR(25))) + ')' \n      WHEN t.[name] IN ('nvarchar','nchar') THEN t.[name] + '(' + IIF(c.max_length = -1, 'max', CAST(c.max_length / 2 AS VARCHAR(25)))+ ')'      \n      WHEN t.[name] IN ('decimal', 'numeric') THEN t.[name] + '(' + CAST(c.[precision] AS VARCHAR(25)) + ', ' + CAST(c.[scale] AS VARCHAR(25)) + ')'\n      WHEN t.[name] IN ('datetime2') THEN t.[name] + '(' + CAST(c.[scale] AS VARCHAR(25)) + ')'\n      ELSE t.[name]\nEND) AS dataType,\nc.column_id\nfrom sys.columns c\njoin sys.views v on v.object_id = c.object_id\njoin sys.schemas s on s.schema_id = v.schema_id\njoin sys.types t on c.user_type_id = t.user_type_id \nleft outer join \n@{if(empty(pipeline().parameters.p_data_type_replace), \n'(select null col, null dataType) r',\nconcat('(select * from OpenJson(N''',\nstring(pipeline().parameters.p_data_type_replace),\n''') WITH (col varchar(255), dataType varchar(255)) as r) r'))}\non r.col = c.name\nwhere s.name = 'dbo' and c.name <> '@{pipeline().parameters.c_trg_partition_col}' and v.name = \n'@{pipeline().parameters.p_trg_table}_tmp') q",
													"type": "Expression"
												}
											}
										],
										"scriptBlockExecutionTimeout": "02:00:00"
									}
								},
								{
									"name": "CreateExternalTable",
									"type": "Script",
									"dependsOn": [
										{
											"activity": "ExternalTableSQL",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "serverless_ARIR",
										"type": "LinkedServiceReference",
										"parameters": {
											"p_database": {
												"value": "@pipeline().parameters.c_serverless_db",
												"type": "Expression"
											}
										}
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "Query",
												"text": {
													"value": "begin transaction\n\nif exists (select * from sys.external_tables t join sys.schemas s on s.schema_id = t.schema_id where s.name = 'dbo' and t.name = '@{pipeline().parameters.p_trg_table}')\ndrop external table @{pipeline().parameters.p_trg_table};\n\n@{activity('ExternalTableSQL').output.resultSets[0].rows[0].SQL};\n\ndrop view @{pipeline().parameters.p_trg_table}_tmp;\n\ncommit;\n",
													"type": "Expression"
												}
											}
										],
										"scriptBlockExecutionTimeout": "02:00:00"
									}
								},
								{
									"name": "ScriptStagingDimKeysSQL",
									"type": "Script",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "serverless_ARIR",
										"type": "LinkedServiceReference",
										"parameters": {
											"p_database": {
												"value": "@pipeline().parameters.c_serverless_db",
												"type": "Expression"
											}
										}
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "Query",
												"text": {
													"value": "select 'select ' + \nSTRING_AGG('coalesce(' + coalesce(dimAlias, dimTab) + '.' + dimKey + ', 0) ' + coalesce(keyAlias, dimKey), ', ') + ', ' + 'stg.*' +\n' from openrowset(bulk ''@{activity('GenericEnrichedParquet linked service').output.properties.typeProperties.url}@{pipeline().parameters.c_stg_container}/@{pipeline().parameters.c_stg_root_folder}/@{pipeline().parameters.p_trg_table}Stg.parquet'', format = ''PARQUET'') as stg ' +\nSTRING_AGG('left outer join ' + dimTab + ' ' + coalesce(dimAlias, dimTab) + ' on ' + replace(joinStatement,  dimTab, coalesce(dimAlias, dimTab)), ' ') sourceQuery\nfrom\n(select * from OPENJSON('@{replace(string(pipeline().parameters.p_dw_dim_tabs), '''', '''''')}')\nWITH (\n    dimTab NVARCHAR(max) '$.dimTab',\n    dimAlias NVARCHAR(max) '$.dimAlias',\n    dimKey NVARCHAR(max) '$.dimKey',\n    keyAlias NVARCHAR(max) '$.keyAlias',\n    joinStatement NVARCHAR(max) '$.joinStatement'\n)) q",
													"type": "Expression"
												}
											}
										],
										"scriptBlockExecutionTimeout": "02:00:00"
									}
								},
								{
									"name": "ScriptFactCreateTime",
									"type": "Script",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "serverless_ARIR",
										"type": "LinkedServiceReference",
										"parameters": {
											"p_database": {
												"value": "@pipeline().parameters.c_serverless_db",
												"type": "Expression"
											}
										}
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "Query",
												"text": {
													"value": "@if(activity('GetTargetDeltaMetadata').output.exists, \nconcat('select ''select '' + STRING_AGG(value, '', '') + '', ', pipeline().parameters.c_trg_dss_create_col, ' from ', pipeline().parameters.p_trg_table, ''' targetQuery from OPENJSON (''', string(pipeline().parameters.p_src_key_cols), ''')'), \nconcat('select ''select null as '' + STRING_AGG(value, '', null as '') + '', cast(null as datetime) as ', pipeline().parameters.c_trg_dss_create_col, ' where 1 = 0'' targetQuery from OPENJSON (''', string(pipeline().parameters.p_src_key_cols), ''') as r'))\n\n",
													"type": "Expression"
												}
											}
										],
										"scriptBlockExecutionTimeout": "02:00:00"
									}
								}
							]
						}
					},
					{
						"name": "GenericEnrichedParquet attributes",
						"type": "WebActivity",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"method": "GET",
							"headers": {},
							"url": {
								"value": "@concat('https://', pipeline().DataFactory, '.dev.azuresynapse.net/datasets/GenericEnrichedParquet?api-version=2020-12-01')",
								"type": "Expression"
							},
							"connectVia": {
								"referenceName": "SHIR",
								"type": "IntegrationRuntimeReference"
							},
							"authentication": {
								"type": "MSI",
								"resource": "https://dev.azuresynapse.net/"
							}
						}
					},
					{
						"name": "GenericEnrichedParquet linked service",
						"type": "WebActivity",
						"dependsOn": [
							{
								"activity": "GenericEnrichedParquet attributes",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"method": "GET",
							"headers": {},
							"url": {
								"value": "@concat('https://', pipeline().DataFactory, '.dev.azuresynapse.net/linkedservices/', activity('GenericEnrichedParquet attributes').output.properties.linkedServiceName.referenceName, '?api-version=2020-12-01')",
								"type": "Expression"
							},
							"connectVia": {
								"referenceName": "SHIR",
								"type": "IntegrationRuntimeReference"
							},
							"authentication": {
								"type": "MSI",
								"resource": "https://dev.azuresynapse.net/"
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"p_trg_table": {
						"type": "string",
						"defaultValue": "FactDataflowsDatasets"
					},
					"p_datetime_from": {
						"type": "string"
					},
					"p_surrogate_key_col": {
						"type": "string",
						"defaultValue": "dataflows_key"
					},
					"p_src_schema": {
						"type": "string",
						"defaultValue": "enr"
					},
					"p_src_object": {
						"type": "string",
						"defaultValue": "dataflows_datasets_WIDE"
					},
					"p_src_key_cols": {
						"type": "array",
						"defaultValue": [
							"dataflows_name",
							"datasets_name"
						]
					},
					"p_src_cdc_col": {
						"type": "string",
						"defaultValue": "_DSS_UPDATE_TIME"
					},
					"p_data_type_replace": {
						"type": "array",
						"defaultValue": [
							{
								"col": "dataflows_datasets_name",
								"dataType": "varchar(255)"
							},
							{
								"col": "dataflows_name",
								"dataType": "varchar(255)"
							},
							{
								"col": "datasets_name",
								"dataType": "varchar(255)"
							}
						]
					},
					"p_partition_formula": {
						"type": "string",
						"defaultValue": "'dummy'"
					},
					"c_serverless_db": {
						"type": "string",
						"defaultValue": "templateDB"
					},
					"c_trg_container": {
						"type": "string",
						"defaultValue": "template"
					},
					"c_trg_root_folder": {
						"type": "string",
						"defaultValue": "StarSchemaObjects"
					},
					"c_cur_data_source": {
						"type": "string",
						"defaultValue": "TemplateCuratedSource"
					},
					"c_trg_partition_col": {
						"type": "string",
						"defaultValue": "FACT_PARTITION"
					},
					"c_trg_dss_update_col": {
						"type": "string",
						"defaultValue": "dss_update_time"
					},
					"c_trg_dss_create_col": {
						"type": "string",
						"defaultValue": "dss_create_time"
					},
					"c_stg_container": {
						"type": "string",
						"defaultValue": "template"
					},
					"c_stg_root_folder": {
						"type": "string",
						"defaultValue": "Staging"
					},
					"p_dw_dim_tabs": {
						"type": "array",
						"defaultValue": [
							{
								"dimTab": "DimDataflows",
								"dimAlias": "DimDataflows",
								"dimKey": "dataflows_key",
								"keyAlias": "dataflows_key",
								"joinStatement": "stg.dataflows_name = DimDataflows.name"
							},
							{
								"dimTab": "DimDatasets",
								"dimAlias": "DimDatasets",
								"dimKey": "datasets_key",
								"keyAlias": "datasets_key",
								"joinStatement": "stg.datasets_name = DimDatasets.name"
							}
						]
					}
				},
				"variables": {
					"v_datetime_from": {
						"type": "String"
					}
				},
				"folder": {
					"name": "Templates"
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/GenericCuratedJsonFolder')]",
				"[concat(variables('workspaceId'), '/integrationRuntimes/SHIR')]",
				"[concat(variables('workspaceId'), '/datasets/GenericServerlessSQL')]",
				"[concat(variables('workspaceId'), '/datasets/GenericEnrichedParquet')]",
				"[concat(variables('workspaceId'), '/linkedServices/serverless_ARIR')]",
				"[concat(variables('workspaceId'), '/dataflows/StarSchemaFact')]",
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ADLS_TMPL_DATASOURCE1')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ivs-synapse-WorkspaceDefaultSqlServer",
					"type": "LinkedServiceReference",
					"parameters": {
						"DBName": "ivs_sqlpool"
					}
				},
				"annotations": [],
				"type": "AzureSqlDWTable",
				"schema": [
					{
						"name": "SOURCE1_ID",
						"type": "int",
						"precision": 10
					},
					{
						"name": "SOURCE2_REF_ID",
						"type": "int",
						"precision": 10
					},
					{
						"name": "SOURCE3_REF_ID",
						"type": "int",
						"precision": 10
					},
					{
						"name": "NCHAR_VALUE1",
						"type": "nvarchar"
					},
					{
						"name": "NCHAR_VALUE2",
						"type": "nvarchar"
					},
					{
						"name": "NUMERIC_VALUE1",
						"type": "decimal",
						"precision": 12,
						"scale": 6
					},
					{
						"name": "NUMERIC_VALUE2",
						"type": "decimal",
						"precision": 12,
						"scale": 6
					},
					{
						"name": "DATETIME_VALUE1",
						"type": "datetime",
						"precision": 23,
						"scale": 3
					},
					{
						"name": "DATETIME_VALUE2",
						"type": "datetime",
						"precision": 23,
						"scale": 3
					},
					{
						"name": "CDC_TIMESTAMP",
						"type": "datetime",
						"precision": 23,
						"scale": 3
					}
				],
				"typeProperties": {
					"tableName": "dbo.ADLS_TMPL_DATASOURCE1"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/ivs-synapse-WorkspaceDefaultSqlServer')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ADLS_TMPL_DATASOURCE3')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ivs-synapse-WorkspaceDefaultSqlServer",
					"type": "LinkedServiceReference",
					"parameters": {
						"DBName": "ivs_sqlpool"
					}
				},
				"annotations": [],
				"type": "AzureSqlDWTable",
				"schema": [
					{
						"name": "SOURCE3_ID",
						"type": "int",
						"precision": 10
					},
					{
						"name": "NCHAR_VALUE1",
						"type": "nvarchar"
					},
					{
						"name": "NCHAR_VALUE2",
						"type": "nvarchar"
					},
					{
						"name": "NUMERIC_VALUE1",
						"type": "decimal",
						"precision": 12,
						"scale": 6
					},
					{
						"name": "NUMERIC_VALUE2",
						"type": "decimal",
						"precision": 12,
						"scale": 6
					},
					{
						"name": "DATETIME_VALUE1",
						"type": "datetime",
						"precision": 23,
						"scale": 3
					},
					{
						"name": "DATETIME_VALUE2",
						"type": "datetime",
						"precision": 23,
						"scale": 3
					},
					{
						"name": "CDC_TIMESTAMP",
						"type": "datetime",
						"precision": 23,
						"scale": 3
					}
				],
				"typeProperties": {
					"tableName": "dbo.ADLS_TMPL_DATASOURCE3"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/ivs-synapse-WorkspaceDefaultSqlServer')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DummyJson')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "templaterawst_ARIR",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Json",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "dummy.json",
						"fileSystem": "raw"
					}
				},
				"schema": {}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/templaterawst_ARIR')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/GenericCuratedJsonFolder')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "templatecurst_ARIR",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"p_container": {
						"type": "string"
					},
					"p_folder": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "Json",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": {
							"value": "@dataset().p_folder",
							"type": "Expression"
						},
						"fileSystem": {
							"value": "@dataset().p_container",
							"type": "Expression"
						}
					}
				},
				"schema": {}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/templatecurst_ARIR')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/GenericCuratedParquet')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "templatecurst_ARIR",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"p_container": {
						"type": "string"
					},
					"p_folder": {
						"type": "string"
					},
					"p_file": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "Parquet",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": {
							"value": "@concat(dataset().p_file, '.parquet')",
							"type": "Expression"
						},
						"folderPath": {
							"value": "@dataset().p_folder",
							"type": "Expression"
						},
						"fileSystem": {
							"value": "@dataset().p_container",
							"type": "Expression"
						}
					},
					"compressionCodec": "snappy"
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/templatecurst_ARIR')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/GenericEnrichedJsonFolder')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "templateenrst_ARIR",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"p_container": {
						"type": "string"
					},
					"p_folder": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "Json",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": {
							"value": "@dataset().p_folder",
							"type": "Expression"
						},
						"fileSystem": {
							"value": "@dataset().p_container",
							"type": "Expression"
						}
					}
				},
				"schema": {}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/templateenrst_ARIR')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/GenericEnrichedParquet')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "templateenrst_ARIR",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"p_container": {
						"type": "string"
					},
					"p_folder": {
						"type": "string"
					},
					"p_file": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "Parquet",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": {
							"value": "@concat(dataset().p_file, '.parquet')",
							"type": "Expression"
						},
						"folderPath": {
							"value": "@dataset().p_folder",
							"type": "Expression"
						},
						"fileSystem": {
							"value": "@dataset().p_container",
							"type": "Expression"
						}
					},
					"compressionCodec": "snappy"
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/templateenrst_ARIR')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/GenericRawCSV_NoHeaderNoQuote')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "templaterawst_ARIR",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"p_container": {
						"type": "string"
					},
					"p_folder": {
						"type": "string"
					},
					"p_file": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": {
							"value": "@concat(dataset().p_file, '.csv')",
							"type": "Expression"
						},
						"folderPath": {
							"value": "@dataset().p_folder",
							"type": "Expression"
						},
						"fileSystem": {
							"value": "@dataset().p_container",
							"type": "Expression"
						}
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": false,
					"quoteChar": ""
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/templaterawst_ARIR')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/GenericRawJson')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "templaterawst_ARIR",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"p_container": {
						"type": "string"
					},
					"p_folder": {
						"type": "string"
					},
					"p_file": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "Json",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": {
							"value": "@concat(dataset().p_file, '.json')",
							"type": "Expression"
						},
						"folderPath": {
							"value": "@dataset().p_folder",
							"type": "Expression"
						},
						"fileSystem": {
							"value": "@dataset().p_container",
							"type": "Expression"
						}
					}
				},
				"schema": {}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/templaterawst_ARIR')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/GenericRawJson_NoExtension')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "templaterawst_ARIR",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"p_container": {
						"type": "string"
					},
					"p_folder": {
						"type": "string"
					},
					"p_file": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "Json",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": {
							"value": "@dataset().p_file",
							"type": "Expression"
						},
						"folderPath": {
							"value": "@dataset().p_folder",
							"type": "Expression"
						},
						"fileSystem": {
							"value": "@dataset().p_container",
							"type": "Expression"
						}
					}
				},
				"schema": {}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/templaterawst_ARIR')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/GenericRawParquet')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "templaterawst_ARIR",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"p_container": {
						"type": "string"
					},
					"p_folder": {
						"type": "string"
					},
					"p_file": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "Parquet",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": {
							"value": "@concat(dataset().p_file, '.parquet')",
							"type": "Expression"
						},
						"folderPath": {
							"value": "@dataset().p_folder",
							"type": "Expression"
						},
						"fileSystem": {
							"value": "@dataset().p_container",
							"type": "Expression"
						}
					},
					"compressionCodec": "snappy"
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/templaterawst_ARIR')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/GenericRawParquet_NoExtension')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "templaterawst_ARIR",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"p_container": {
						"type": "string"
					},
					"p_folder": {
						"type": "string"
					},
					"p_file": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "Parquet",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": {
							"value": "@dataset().p_file",
							"type": "Expression"
						},
						"folderPath": {
							"value": "@dataset().p_folder",
							"type": "Expression"
						},
						"fileSystem": {
							"value": "@dataset().p_container",
							"type": "Expression"
						}
					},
					"compressionCodec": "snappy"
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/templaterawst_ARIR')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/GenericServerlessSQL')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "serverless_ARIR",
					"type": "LinkedServiceReference",
					"parameters": {
						"p_database": {
							"value": "@dataset().p_database",
							"type": "Expression"
						}
					}
				},
				"parameters": {
					"p_database": {
						"type": "string"
					},
					"p_schema": {
						"type": "string"
					},
					"p_table": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "AzureSqlDWTable",
				"schema": [],
				"typeProperties": {
					"schema": {
						"value": "@dataset().p_schema",
						"type": "Expression"
					},
					"table": {
						"value": "@dataset().p_table",
						"type": "Expression"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/serverless_ARIR')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/TMPL_DATASOURCE2')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ivs-synapse-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "TMPL_DATASOURCE2.csv",
						"folderPath": "source",
						"fileSystem": "adftemplate"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/ivs-synapse-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/TMPL_DATASOURCE3')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ivs-synapse-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "TMPL_DATASOURCE3.csv",
						"folderPath": "source",
						"fileSystem": "adftemplate"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/ivs-synapse-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/TMPL_DIMENSION1')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ivs-synapse-WorkspaceDefaultSqlServer",
					"type": "LinkedServiceReference",
					"parameters": {
						"DBName": "ivs_sqlpool"
					}
				},
				"annotations": [],
				"type": "AzureSqlDWTable",
				"schema": [
					{
						"name": "DIMENSION1_KEY",
						"type": "int",
						"precision": 10
					},
					{
						"name": "SOURCE2_ID",
						"type": "int",
						"precision": 10
					},
					{
						"name": "NCHAR_ATTRIBUTE1",
						"type": "nchar"
					},
					{
						"name": "NCHAR_ATTRIBUTE2",
						"type": "nchar"
					},
					{
						"name": "DATETIME_ATTRIBUTE1",
						"type": "datetime",
						"precision": 23,
						"scale": 3
					},
					{
						"name": "DATETIME_ATTRIBUTE2",
						"type": "datetime",
						"precision": 23,
						"scale": 3
					},
					{
						"name": "DSS_CREATE_TIME",
						"type": "datetime",
						"precision": 23,
						"scale": 3
					},
					{
						"name": "DSS_UPDATE_TIME",
						"type": "datetime",
						"precision": 23,
						"scale": 3
					}
				],
				"typeProperties": {
					"tableName": "dbo.TMPL_DIMENSION1"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/ivs-synapse-WorkspaceDefaultSqlServer')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/TMPL_DIMENSION2')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ivs-synapse-WorkspaceDefaultSqlServer",
					"type": "LinkedServiceReference",
					"parameters": {
						"DBName": "ivs_sqlpool"
					}
				},
				"annotations": [],
				"type": "AzureSqlDWTable",
				"schema": [
					{
						"name": "DIMENSION2_KEY",
						"type": "int",
						"precision": 10
					},
					{
						"name": "SOURCE3_ID",
						"type": "int",
						"precision": 10
					},
					{
						"name": "NCHAR_ATTRIBUTE1",
						"type": "nchar"
					},
					{
						"name": "NCHAR_ATTRIBUTE2",
						"type": "nchar"
					},
					{
						"name": "DATETIME_ATTRIBUTE1",
						"type": "datetime",
						"precision": 23,
						"scale": 3
					},
					{
						"name": "DATETIME_ATTRIBUTE2",
						"type": "datetime",
						"precision": 23,
						"scale": 3
					},
					{
						"name": "DSS_CREATE_TIME",
						"type": "datetime",
						"precision": 23,
						"scale": 3
					},
					{
						"name": "DSS_UPDATE_TIME",
						"type": "datetime",
						"precision": 23,
						"scale": 3
					}
				],
				"typeProperties": {
					"tableName": "dbo.TMPL_DIMENSION2"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/ivs-synapse-WorkspaceDefaultSqlServer')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/TMPL_FACT')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ivs-synapse-WorkspaceDefaultSqlServer",
					"type": "LinkedServiceReference",
					"parameters": {
						"DBName": "ivs_sqlpool"
					}
				},
				"annotations": [],
				"type": "AzureSqlDWTable",
				"schema": [
					{
						"name": "DIMENSION1_KEY",
						"type": "int",
						"precision": 10
					},
					{
						"name": "DIMENSION2_KEY",
						"type": "int",
						"precision": 10
					},
					{
						"name": "SOURCE1_ID",
						"type": "int",
						"precision": 10
					},
					{
						"name": "SRC1_MEASURE1",
						"type": "decimal",
						"precision": 18,
						"scale": 4
					},
					{
						"name": "SRC1_MEASURE2",
						"type": "decimal",
						"precision": 18,
						"scale": 4
					},
					{
						"name": "SRC2_MEASURE1",
						"type": "decimal",
						"precision": 18,
						"scale": 4
					},
					{
						"name": "SRC2_MEASURE2",
						"type": "decimal",
						"precision": 18,
						"scale": 4
					},
					{
						"name": "SRC3_MEASURE1",
						"type": "decimal",
						"precision": 18,
						"scale": 4
					},
					{
						"name": "SRC3_MEASURE2",
						"type": "decimal",
						"precision": 18,
						"scale": 4
					},
					{
						"name": "SRC1_CDC_TIMESTAMP",
						"type": "datetime",
						"precision": 23,
						"scale": 3
					},
					{
						"name": "DSS_CREATE_TIME",
						"type": "datetime",
						"precision": 23,
						"scale": 3
					},
					{
						"name": "DSS_UPDATE_TIME",
						"type": "datetime",
						"precision": 23,
						"scale": 3
					}
				],
				"typeProperties": {
					"tableName": "dbo.TMPL_FACT"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/ivs-synapse-WorkspaceDefaultSqlServer')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/TMPL_STAGING')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ivs-synapse-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Parquet",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "staging/data",
						"fileSystem": "adftemplate"
					},
					"compressionCodec": "snappy"
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/ivs-synapse-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/TMPL_STAGING_KEY')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ivs-synapse-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Parquet",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "staging/key",
						"fileSystem": "adftemplate"
					},
					"compressionCodec": "snappy"
				},
				"schema": [
					{
						"name": "SRC1_SOURCE1_ID",
						"type": "INT32"
					},
					{
						"name": "SRC1_SOURCE2_REF_ID",
						"type": "INT32"
					},
					{
						"name": "SRC1_SOURCE3_REF_ID",
						"type": "INT32"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/ivs-synapse-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/azuresynapse')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "azuresynapse_REST",
					"type": "LinkedServiceReference",
					"parameters": {
						"p_workspace": {
							"value": "@dataset().p_workspace",
							"type": "Expression"
						}
					}
				},
				"parameters": {
					"p_workspace": {
						"type": "string"
					},
					"p_relative_url": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "RestResource",
				"typeProperties": {
					"relativeUrl": {
						"value": "@dataset().p_relative_url",
						"type": "Expression"
					}
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/azuresynapse_REST')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/serverlessview')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ivs_od_sqlpool",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "AzureSqlDWTable",
				"schema": [
					{
						"name": "PartyId",
						"type": "bigint",
						"precision": 19
					},
					{
						"name": "PartyName",
						"type": "varchar"
					},
					{
						"name": "PartyTypeId",
						"type": "int",
						"precision": 10
					},
					{
						"name": "GlobalLocationNumber",
						"type": "decimal",
						"precision": 13,
						"scale": 0
					},
					{
						"name": "dte",
						"type": "date"
					}
				],
				"typeProperties": {
					"schema": "dbo",
					"table": "Party_delta"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/ivs_od_sqlpool')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AdventureWorksSQL')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "AdventureWorks Cosmos DB SQL API database",
				"annotations": [],
				"type": "CosmosDb",
				"typeProperties": {
					"connectionString": "[parameters('AdventureWorksSQL_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/azuresynapse_REST')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"p_workspace": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "RestService",
				"typeProperties": {
					"url": "[parameters('azuresynapse_REST_properties_typeProperties_url')]",
					"enableServerCertificateValidation": true,
					"authenticationType": "ManagedServiceIdentity",
					"aadResourceId": "[parameters('azuresynapse_REST_properties_typeProperties_aadResourceId')]"
				},
				"connectVia": {
					"referenceName": "SHIR",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/SHIR')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ivs-synapse-WorkspaceDefaultSqlServer')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"DBName": {
						"type": "String"
					}
				},
				"annotations": [],
				"type": "AzureSqlDW",
				"typeProperties": {
					"connectionString": "[parameters('ivs-synapse-WorkspaceDefaultSqlServer_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ivs-synapse-WorkspaceDefaultStorage')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('ivs-synapse-WorkspaceDefaultStorage_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ivs_od_sqlpool')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureSqlDW",
				"typeProperties": {
					"connectionString": "[parameters('ivs_od_sqlpool_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/serverless_ARIR')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"p_database": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "AzureSqlDW",
				"typeProperties": {
					"connectionString": "[parameters('serverless_ARIR_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/template_dedicated_ARIR')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureSqlDW",
				"typeProperties": {
					"connectionString": "[parameters('template_dedicated_ARIR_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/template_kv')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureKeyVault",
				"typeProperties": {
					"baseUrl": "[parameters('template_kv_properties_typeProperties_baseUrl')]"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/templatecurst_ARIR')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('templatecurst_ARIR_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/templateenrst_ARIR')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('templateenrst_ARIR_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/templaterawst_ARIR')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('templaterawst_ARIR_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SchedSQLPoolPaused')]",
			"type": "Microsoft.Synapse/workspaces/triggers",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"runtimeState": "Started",
				"pipelines": [],
				"type": "ScheduleTrigger",
				"typeProperties": {
					"recurrence": {
						"frequency": "Day",
						"interval": 1,
						"startTime": "2021-01-17T04:03:00",
						"timeZone": "Atlantic Standard Time",
						"schedule": {
							"minutes": [
								0
							],
							"hours": [
								1
							]
						}
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AutoResolveIntegrationRuntime')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "Managed",
				"typeProperties": {
					"computeProperties": {
						"location": "AutoResolve",
						"dataFlowProperties": {
							"computeType": "General",
							"coreCount": 8,
							"timeToLive": 0
						}
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SHIR')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "SelfHosted",
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/FromDeltaToWideDelta')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Audit"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "GenericServerlessSQL",
								"type": "DatasetReference"
							},
							"name": "sourceWide"
						},
						{
							"dataset": {
								"referenceName": "GenericServerlessSQL",
								"type": "DatasetReference"
							},
							"name": "sourcePartitionPruning"
						}
					],
					"sinks": [
						{
							"linkedService": {
								"referenceName": "templateenrst_ARIR",
								"type": "LinkedServiceReference"
							},
							"name": "sinkWide"
						},
						{
							"name": "sinkPartitionPruning"
						}
					],
					"transformations": [
						{
							"name": "alterRowWide"
						},
						{
							"name": "derivedWide"
						}
					],
					"scriptLines": [
						"parameters{",
						"     c_trg_object as string ('dataflows_datasets_WIDE'),",
						"     c_trg_container as string ('template'),",
						"     c_trg_root_folder as string ('FromDeltaToWideDelta'),",
						"     p_keyCols as string ('dataflows_datasets_name, dataflows_datasets_propertiestypePropertiessourcesdatasetreferenceName'),",
						"     p_source_query as string (\"select dataflows_datasets.DELTA_PARTITION as dataflows_datasets_DELTA_PARTITION, dataflows_datasets.enrTimestamp as dataflows_datasets_enrTimestamp, dataflows_datasets.name as dataflows_datasets_name, dataflows_datasets.propertiestypePropertiessourcesdatasetreferenceName as dataflows_datasets_propertiestypePropertiessourcesdatasetreferenceName, dataflows_datasets.rawTimestamp as dataflows_datasets_rawTimestamp, dataflows.DELTA_PARTITION as dataflows_DELTA_PARTITION, dataflows.enrTimestamp as dataflows_enrTimestamp, dataflows.etag as dataflows_etag, dataflows.id as dataflows_id, dataflows.name as dataflows_name, dataflows.rawTimestamp as dataflows_rawTimestamp, dataflows.type as dataflows_type, datasets.DELTA_PARTITION as datasets_DELTA_PARTITION, datasets.enrTimestamp as datasets_enrTimestamp, datasets.etag as datasets_etag, datasets.id as datasets_id, datasets.name as datasets_name, datasets.rawTimestamp as datasets_rawTimestamp, datasets.type as datasets_type, dataflows_datasets.DELTA_PARTITION as _PARTITION, cast('2024-03-07T14:10:09.9058210Z' as datetime2) as _DSS_UPDATE_TIME from enr.dataflows_datasets_REST_API as dataflows_datasets left outer join enr.dataflows_REST_API as dataflows on dataflows.name = dataflows_datasets.name left outer join enr.datasets_REST_API as datasets on datasets.name = dataflows_datasets.propertiestypePropertiessourcesdatasetreferenceName where (dataflows_datasets.enrTimestamp > '1900-01-01' or dataflows.enrTimestamp > '1900-01-01' or datasets.enrTimestamp > '1900-01-01')\"),",
						"     p_pruning_query as string (\"select distinct(dataflows_datasets.DELTA_PARTITION) as _PARTITION from enr.dataflows_datasets_REST_API as dataflows_datasets left outer join enr.dataflows_REST_API as dataflows on dataflows.name = dataflows_datasets.name left outer join enr.datasets_REST_API as datasets on datasets.name = dataflows_datasets.propertiestypePropertiessourcesdatasetreferenceName where (dataflows_datasets.enrTimestamp > '1900-01-01' or dataflows.enrTimestamp > '1900-01-01' or datasets.enrTimestamp > '1900-01-01')\"),",
						"     c_trg_partition_col as string ('_PARTITION'),",
						"     p_iteration as integer (0)",
						"}",
						"source(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     query: ($p_source_query),",
						"     format: 'query',",
						"     staged: false) ~> sourceWide",
						"source(output(",
						"          PartitionPruning as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     query: (\"select distinct \" + $c_trg_partition_col + \" as PartitionPruning from (select 'dummy' as \" + $c_trg_partition_col + \" union \" + $p_pruning_query + \") q\"),",
						"     format: 'query',",
						"     staged: false) ~> sourcePartitionPruning",
						"derivedWide alterRow(upsertIf($p_iteration==0),",
						"     updateIf($p_iteration!=0)) ~> alterRowWide",
						"sourceWide derive({_PARTITION} = byName($c_trg_partition_col)) ~> derivedWide",
						"alterRowWide sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     format: 'delta',",
						"     fileSystem: ($c_trg_container),",
						"     folderPath: ($c_trg_root_folder + \"/\" + $c_trg_object),",
						"     mergeSchema: false,",
						"     autoCompact: false,",
						"     optimizedWrite: false,",
						"     vacuum: 0,",
						"     deletable: false,",
						"     insertable: true,",
						"     updateable: false,",
						"     upsertable: false,",
						"     pruneCondition: ['_PARTITION' -> (sinkPartitionPruning#outputs().PartitionPruning)],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     saveOrder: 2,",
						"     partitionBy('key',",
						"          0,",
						"          {_PARTITION}",
						"     )) ~> sinkWide",
						"sourcePartitionPruning sink(validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     store: 'cache',",
						"     format: 'inline',",
						"     output: false,",
						"     saveOrder: 1) ~> sinkPartitionPruning"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/GenericServerlessSQL')]",
				"[concat(variables('workspaceId'), '/linkedServices/templateenrst_ARIR')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/FromJsonToDeltaParquet_Basic')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Templates"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "GenericRawJson_NoExtension",
								"type": "DatasetReference"
							},
							"name": "RawDataset"
						},
						{
							"dataset": {
								"referenceName": "GenericRawJson_NoExtension",
								"type": "DatasetReference"
							},
							"name": "PartitionPruning"
						},
						{
							"dataset": {
								"referenceName": "GenericServerlessSQL",
								"type": "DatasetReference"
							},
							"name": "dummyPartitionPruning"
						}
					],
					"sinks": [
						{
							"linkedService": {
								"referenceName": "templateenrst_ARIR",
								"type": "LinkedServiceReference"
							},
							"name": "EnrichedDeltaLake"
						},
						{
							"name": "sinkPartitionPruning"
						}
					],
					"transformations": [
						{
							"name": "flattenRaw"
						},
						{
							"name": "alterRow"
						},
						{
							"name": "elicitDuplicates"
						},
						{
							"name": "derivedId",
							"description": "Added as Window function cannot interpret byName('Id') as valid for OVER statement"
						},
						{
							"name": "filterDuplicates"
						},
						{
							"name": "removeTempColumns"
						},
						{
							"name": "aggregatePartitionPruning"
						},
						{
							"name": "unionPartitionPruning"
						},
						{
							"name": "collectPartitionPruning"
						},
						{
							"name": "flattenPartition"
						}
					],
					"scriptLines": [
						"parameters{",
						"     c_target_container as string ('sandpit'),",
						"     c_target_folder as string ('FromJsonToDeltaParquet_Basic'),",
						"     c_key_column_name as string ('name'),",
						"     c_cdc_column_name as string ('fileName'),",
						"     c_enriched_cdc_column as string ('enrTimestamp'),",
						"     p_partition_formula as string (\"'dummy'\"),",
						"     p_dss_update_time as string ('2023-10-20T00:00:00Z'),",
						"     c_raw_cdc_column as string ('rawTimestamp')",
						"}",
						"source(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     fileList: true,",
						"     rowUrlColumn: 'fileName',",
						"     documentForm: 'documentPerLine',",
						"     dateFormats: ['yyyy-MM-dd'],",
						"     timestampFormats: ['yyyy-MM-dd\\'T\\'HH:mm:ss.SSS\\'Z\\'','yyyy-MM-dd\\'T\\'HH:mm:ss\\'Z\\''],",
						"     preferredIntegralType: 'long',",
						"     preferredFractionalType: 'decimal') ~> RawDataset",
						"source(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     fileList: true,",
						"     documentForm: 'documentPerLine') ~> PartitionPruning",
						"source(output(",
						"          PARTITION as string,",
						"          CONSTANT as string,",
						"          AGGREGATE as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     query: 'select \\'dummy\\' as PARTITION,\\n\\'CONSTANT\\' as CONSTANT, \\'dummy\\' as AGGREGATE',",
						"     format: 'query',",
						"     staged: false) ~> dummyPartitionPruning",
						"RawDataset foldDown(unroll((byName('value'))),",
						"     mapColumn(",
						"          every(match(locate('@',name)==0),",
						"               replace($0,'value.','') = $$)",
						"     ),",
						"     skipDuplicateMapInputs: false,",
						"     skipDuplicateMapOutputs: false) ~> flattenRaw",
						"removeTempColumns alterRow(upsertIf(true())) ~> alterRow",
						"derivedId window(over(keyColumn),",
						"     desc(toString(byName($c_cdc_column_name)), true),",
						"     rowNum = rowNumber()) ~> elicitDuplicates",
						"flattenRaw derive(keyColumn = toString(byName($c_key_column_name)),",
						"          each(match(true()), $$ = toString($$)),",
						"          each(match(name=='fileName'), $c_enriched_cdc_column = toTimestamp($p_dss_update_time, \"yyyy-MM-dd'T'HH:mm:ss'Z'\"), $c_raw_cdc_column = replace(reverse(substring(reverse(toString($$)), 0, locate('_', reverse(toString($$))) - 1)), '.json')),",
						"          DELTA_PARTITION = expr($p_partition_formula)) ~> derivedId",
						"elicitDuplicates filter(rowNum == 1 && not(isNull(keyColumn))) ~> filterDuplicates",
						"filterDuplicates select(mapColumn(",
						"          each(match(name!='rowNum'&&name!='fileName'&&name!='keyColumn'&&name!='cdcValue'&&left(name,length('properties.'))!='properties.'))",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> removeTempColumns",
						"flattenPartition aggregate(groupBy(PARTITION = expr($p_partition_formula),",
						"          CONSTANT = 'CONSTANT'),",
						"     AGGREGATE = first(expr($p_partition_formula))) ~> aggregatePartitionPruning",
						"aggregatePartitionPruning, dummyPartitionPruning union(byName: true)~> unionPartitionPruning",
						"unionPartitionPruning aggregate(groupBy(CONSTANT),",
						"     PARTITION = distinct(collect(AGGREGATE))) ~> collectPartitionPruning",
						"PartitionPruning foldDown(unroll((byName('value'))),",
						"     mapColumn(",
						"          every(match(locate('@',name)==0),",
						"               replace($0,'value.','') = $$)",
						"     ),",
						"     skipDuplicateMapInputs: false,",
						"     skipDuplicateMapOutputs: false) ~> flattenPartition",
						"alterRow sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     format: 'delta',",
						"     compressionType: 'snappy',",
						"     compressionLevel: 'Fastest',",
						"     fileSystem: ($c_target_container),",
						"     folderPath: ($c_target_folder),",
						"     mergeSchema: true,",
						"     autoCompact: true,",
						"     optimizedWrite: true,",
						"     vacuum: 1,",
						"     deletable: false,",
						"     insertable: false,",
						"     updateable: false,",
						"     upsertable: true,",
						"     keys:(array($c_key_column_name)),",
						"     pruneCondition: ['DELTA_PARTITION' -> (sinkPartitionPruning#outputs().PARTITION_PRUNING)],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     saveOrder: 2,",
						"     partitionBy('key',",
						"          0,",
						"          DELTA_PARTITION",
						"     )) ~> EnrichedDeltaLake",
						"collectPartitionPruning sink(validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     store: 'cache',",
						"     format: 'inline',",
						"     output: false,",
						"     saveOrder: 1,",
						"     mapColumn(",
						"          PARTITION_PRUNING = PARTITION",
						"     )) ~> sinkPartitionPruning"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/GenericRawJson_NoExtension')]",
				"[concat(variables('workspaceId'), '/datasets/GenericServerlessSQL')]",
				"[concat(variables('workspaceId'), '/linkedServices/templateenrst_ARIR')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/FromJsonToDeltaParquet_Relations11')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Templates"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "GenericRawJson_NoExtension",
								"type": "DatasetReference"
							},
							"name": "RawDataset"
						},
						{
							"dataset": {
								"referenceName": "GenericRawJson_NoExtension",
								"type": "DatasetReference"
							},
							"name": "PartitionPruning"
						},
						{
							"dataset": {
								"referenceName": "GenericServerlessSQL",
								"type": "DatasetReference"
							},
							"name": "dummyPartitionPruning"
						}
					],
					"sinks": [
						{
							"linkedService": {
								"referenceName": "templateenrst_ARIR",
								"type": "LinkedServiceReference"
							},
							"name": "EnrichedDeltaLake"
						},
						{
							"name": "sinkPartitionPruning"
						}
					],
					"transformations": [
						{
							"name": "flattenKey"
						},
						{
							"name": "alterRow"
						},
						{
							"name": "elicitDuplicates"
						},
						{
							"name": "derivedColumns",
							"description": "Added as Window function cannot interpret byName('Id') as valid for OVER statement"
						},
						{
							"name": "filterDuplicates"
						},
						{
							"name": "removeTempColumns"
						},
						{
							"name": "flattenKeyPartition"
						},
						{
							"name": "aggregatePartitionPruning"
						},
						{
							"name": "unionPartitionPruning"
						},
						{
							"name": "collectPartitionPruning"
						}
					],
					"scriptLines": [
						"parameters{",
						"     c_target_container as string ('sandpit'),",
						"     c_target_folder as string ('FromJsonToDeltaParquet_RelationsMM'),",
						"     c_key_column_name as string ('name'),",
						"     c_cdc_column_name as string ('fileName'),",
						"     c_enriched_cdc_column as string ('enrTimestamp'),",
						"     p_partition_formula as string (\"'dummy'\"),",
						"     p_dss_update_time as string ('2023-10-20T00:00:00Z'),",
						"     c_raw_cdc_column as string ('rawTimestamp')",
						"}",
						"source(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     fileList: true,",
						"     rowUrlColumn: 'fileName',",
						"     documentForm: 'documentPerLine',",
						"     dateFormats: ['yyyy-MM-dd'],",
						"     timestampFormats: ['yyyy-MM-dd\\'T\\'HH:mm:ss.SSS\\'Z\\'','yyyy-MM-dd\\'T\\'HH:mm:ss\\'Z\\''],",
						"     preferredIntegralType: 'long',",
						"     preferredFractionalType: 'decimal') ~> RawDataset",
						"source(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     fileList: true,",
						"     documentForm: 'documentPerLine') ~> PartitionPruning",
						"source(output(",
						"          PARTITION as string,",
						"          CONSTANT as string,",
						"          AGGREGATE as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     query: 'select \\'dummy\\' as PARTITION,\\n\\'CONSTANT\\' as CONSTANT, \\'dummy\\' as AGGREGATE',",
						"     format: 'query',",
						"     staged: false) ~> dummyPartitionPruning",
						"RawDataset foldDown(unroll((byName('value'))),",
						"     mapColumn(",
						"          every(match(locate('@',name)==0),",
						"               replace($0,'value.','') = $$)",
						"     ),",
						"     skipDuplicateMapInputs: false,",
						"     skipDuplicateMapOutputs: false) ~> flattenKey",
						"removeTempColumns alterRow(upsertIf(true())) ~> alterRow",
						"derivedColumns window(over(keyColumn),",
						"     desc(toString(byName($c_cdc_column_name)), true),",
						"     rowNum = rowNumber()) ~> elicitDuplicates",
						"flattenKey derive(keyColumn = toString(byName($c_key_column_name)),",
						"          each(match(name=='fileName'), $c_enriched_cdc_column = toTimestamp($p_dss_update_time, \"yyyy-MM-dd'T'HH:mm:ss'Z'\"), $c_raw_cdc_column = replace(reverse(substring(reverse(toString($$)), 0, locate('_', reverse(toString($$))) - 1)), '.json')),",
						"          DELTA_PARTITION = expr($p_partition_formula)) ~> derivedColumns",
						"elicitDuplicates filter(rowNum == 1 && not(isNull(keyColumn))) ~> filterDuplicates",
						"filterDuplicates select(mapColumn(",
						"          each(match(name==$c_key_column_name||right(name,length('referenceName'))=='referenceName'||name=='DELTA_PARTITION'||name==$c_raw_cdc_column||name==$c_enriched_cdc_column),",
						"               replace($$,'.','') = $$)",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> removeTempColumns",
						"PartitionPruning foldDown(unroll((byName('value'))),",
						"     mapColumn(",
						"          every(match(locate('@',name)==0),",
						"               replace($0,'value.','') = $$)",
						"     ),",
						"     skipDuplicateMapInputs: false,",
						"     skipDuplicateMapOutputs: false) ~> flattenKeyPartition",
						"flattenKeyPartition aggregate(groupBy(PARTITION = expr($p_partition_formula),",
						"          CONSTANT = 'CONSTANT'),",
						"     AGGREGATE = first(expr($p_partition_formula))) ~> aggregatePartitionPruning",
						"aggregatePartitionPruning, dummyPartitionPruning union(byName: true)~> unionPartitionPruning",
						"unionPartitionPruning aggregate(groupBy(CONSTANT),",
						"     PARTITION = distinct(collect(AGGREGATE))) ~> collectPartitionPruning",
						"alterRow sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     format: 'delta',",
						"     compressionType: 'snappy',",
						"     compressionLevel: 'Fastest',",
						"     fileSystem: ($c_target_container),",
						"     folderPath: ($c_target_folder),",
						"     mergeSchema: true,",
						"     autoCompact: true,",
						"     optimizedWrite: true,",
						"     vacuum: 1,",
						"     deletable: false,",
						"     insertable: false,",
						"     updateable: false,",
						"     upsertable: true,",
						"     keys:(array($c_key_column_name)),",
						"     pruneCondition: ['DELTA_PARTITION' -> (sinkPartitionPruning#outputs().PARTITION_PRUNING)],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     saveOrder: 2,",
						"     partitionBy('key',",
						"          0,",
						"          DELTA_PARTITION",
						"     )) ~> EnrichedDeltaLake",
						"collectPartitionPruning sink(validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     store: 'cache',",
						"     format: 'inline',",
						"     output: false,",
						"     saveOrder: 1,",
						"     mapColumn(",
						"          PARTITION_PRUNING = PARTITION",
						"     )) ~> sinkPartitionPruning"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/GenericRawJson_NoExtension')]",
				"[concat(variables('workspaceId'), '/datasets/GenericServerlessSQL')]",
				"[concat(variables('workspaceId'), '/linkedServices/templateenrst_ARIR')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/FromJsonToDeltaParquet_RelationsMM')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Templates"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "GenericRawJson_NoExtension",
								"type": "DatasetReference"
							},
							"name": "RawDataset"
						},
						{
							"dataset": {
								"referenceName": "GenericRawJson_NoExtension",
								"type": "DatasetReference"
							},
							"name": "PartitionPruning"
						},
						{
							"dataset": {
								"referenceName": "GenericServerlessSQL",
								"type": "DatasetReference"
							},
							"name": "dummyPartitionPruning"
						}
					],
					"sinks": [
						{
							"linkedService": {
								"referenceName": "templateenrst_ARIR",
								"type": "LinkedServiceReference"
							},
							"name": "EnrichedDeltaLake"
						},
						{
							"name": "sinkPartitionPruning"
						}
					],
					"transformations": [
						{
							"name": "flattenKey"
						},
						{
							"name": "alterRow"
						},
						{
							"name": "elicitDuplicates"
						},
						{
							"name": "derivedColumns",
							"description": "Added as Window function cannot interpret byName('Id') as valid for OVER statement"
						},
						{
							"name": "filterDuplicates"
						},
						{
							"name": "removeTempColumns"
						},
						{
							"name": "flattenRel"
						},
						{
							"name": "flattenKeyPartition"
						},
						{
							"name": "flattenRelPartition"
						},
						{
							"name": "aggregatePartitionPruning"
						},
						{
							"name": "unionPartitionPruning"
						},
						{
							"name": "collectPartitionPruning"
						}
					],
					"scriptLines": [
						"parameters{",
						"     c_target_container as string ('sandpit'),",
						"     c_target_folder as string ('FromJsonToDeltaParquet_RelationsMM'),",
						"     c_key_column_name as string ('name'),",
						"     c_cdc_column_name as string ('fileName'),",
						"     c_enriched_cdc_column as string ('enrTimestamp'),",
						"     c_relation_column_name as string ('properties.typeProperties.sources.dataset.referenceName'),",
						"     p_partition_formula as string (\"'dummy'\"),",
						"     p_dss_update_time as string ('2023-10-20T00:00:00Z'),",
						"     c_raw_cdc_column as string ('rawTimestamp')",
						"}",
						"source(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     fileList: true,",
						"     rowUrlColumn: 'fileName',",
						"     documentForm: 'documentPerLine',",
						"     dateFormats: ['yyyy-MM-dd'],",
						"     timestampFormats: ['yyyy-MM-dd\\'T\\'HH:mm:ss.SSS\\'Z\\'','yyyy-MM-dd\\'T\\'HH:mm:ss\\'Z\\''],",
						"     preferredIntegralType: 'long',",
						"     preferredFractionalType: 'decimal') ~> RawDataset",
						"source(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     fileList: true,",
						"     documentForm: 'documentPerLine') ~> PartitionPruning",
						"source(output(",
						"          PARTITION as string,",
						"          CONSTANT as string,",
						"          AGGREGATE as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     query: 'select \\'dummy\\' as PARTITION,\\n\\'CONSTANT\\' as CONSTANT, \\'dummy\\' as AGGREGATE',",
						"     format: 'query',",
						"     staged: false) ~> dummyPartitionPruning",
						"RawDataset foldDown(unroll((byName('value'))),",
						"     mapColumn(",
						"          every(match(locate('@',name)==0),",
						"               replace($0,'value.','') = $$)",
						"     ),",
						"     skipDuplicateMapInputs: false,",
						"     skipDuplicateMapOutputs: false) ~> flattenKey",
						"removeTempColumns alterRow(upsertIf(true())) ~> alterRow",
						"derivedColumns window(over(keyColumn),",
						"     desc(toString(byName($c_cdc_column_name)), true),",
						"     rowNum = rowNumber()) ~> elicitDuplicates",
						"flattenRel derive(keyColumn = toString(byName($c_key_column_name)) + '-' + toString(byName(replace($c_relation_column_name, '.', ''))),",
						"          each(match(name=='fileName'), $c_enriched_cdc_column = toTimestamp($p_dss_update_time, \"yyyy-MM-dd'T'HH:mm:ss'Z'\"), $c_raw_cdc_column = replace(reverse(substring(reverse(toString($$)), 0, locate('_', reverse(toString($$))) - 1)), '.json')),",
						"          DELTA_PARTITION = expr($p_partition_formula)) ~> derivedColumns",
						"elicitDuplicates filter(rowNum == 1 && not(isNull(keyColumn))) ~> filterDuplicates",
						"filterDuplicates select(mapColumn(",
						"          each(match(name==replace($c_key_column_name,'.','')||name==replace($c_relation_column_name,'.','')||name=='DELTA_PARTITION'||name==$c_raw_cdc_column||name==$c_enriched_cdc_column))",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> removeTempColumns",
						"flattenKey foldDown(unroll((byName($c_relation_column_name))),",
						"     mapColumn(",
						"          fileName,",
						"          each(match(name==$c_key_column_name||name==$c_relation_column_name),",
						"               replace($$,'.','') = $$),",
						"          each(match(name!=$c_key_column_name&&name!=$c_relation_column_name&&name!='fileName'),",
						"               $0 = $$)",
						"     ),",
						"     skipDuplicateMapInputs: false,",
						"     skipDuplicateMapOutputs: false) ~> flattenRel",
						"PartitionPruning foldDown(unroll((byName('value'))),",
						"     mapColumn(",
						"          every(match(locate('@',name)==0),",
						"               replace($0,'value.','') = $$)",
						"     ),",
						"     skipDuplicateMapInputs: false,",
						"     skipDuplicateMapOutputs: false) ~> flattenKeyPartition",
						"flattenKeyPartition foldDown(unroll((byName($c_relation_column_name))),",
						"     mapColumn(",
						"          each(match(name==$c_key_column_name||name==$c_relation_column_name),",
						"               replace($$,'.','') = $$),",
						"          each(match(name!=$c_key_column_name&&name!=$c_relation_column_name&&name!='fileName'),",
						"               $0 = $$)",
						"     ),",
						"     skipDuplicateMapInputs: false,",
						"     skipDuplicateMapOutputs: false) ~> flattenRelPartition",
						"flattenRelPartition aggregate(groupBy(PARTITION = expr($p_partition_formula),",
						"          CONSTANT = 'CONSTANT'),",
						"     AGGREGATE = first(expr($p_partition_formula))) ~> aggregatePartitionPruning",
						"aggregatePartitionPruning, dummyPartitionPruning union(byName: true)~> unionPartitionPruning",
						"unionPartitionPruning aggregate(groupBy(CONSTANT),",
						"     PARTITION = distinct(collect(AGGREGATE))) ~> collectPartitionPruning",
						"alterRow sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     format: 'delta',",
						"     compressionType: 'snappy',",
						"     compressionLevel: 'Fastest',",
						"     fileSystem: ($c_target_container),",
						"     folderPath: ($c_target_folder),",
						"     mergeSchema: true,",
						"     autoCompact: true,",
						"     optimizedWrite: true,",
						"     vacuum: 1,",
						"     deletable: false,",
						"     insertable: false,",
						"     updateable: false,",
						"     upsertable: true,",
						"     keys:(array($c_key_column_name, replace($c_relation_column_name, '.', ''))),",
						"     pruneCondition: ['DELTA_PARTITION' -> (sinkPartitionPruning#outputs().PARTITION_PRUNING)],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     saveOrder: 2,",
						"     partitionBy('key',",
						"          0,",
						"          DELTA_PARTITION",
						"     )) ~> EnrichedDeltaLake",
						"collectPartitionPruning sink(validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     store: 'cache',",
						"     format: 'inline',",
						"     output: false,",
						"     saveOrder: 1,",
						"     mapColumn(",
						"          PARTITION_PRUNING = PARTITION",
						"     )) ~> sinkPartitionPruning"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/GenericRawJson_NoExtension')]",
				"[concat(variables('workspaceId'), '/datasets/GenericServerlessSQL')]",
				"[concat(variables('workspaceId'), '/linkedServices/templateenrst_ARIR')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/FromParquetToDeltaParquet')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Templates"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "GenericRawParquet_NoExtension",
								"type": "DatasetReference"
							},
							"name": "RawDataset"
						},
						{
							"dataset": {
								"referenceName": "GenericRawParquet_NoExtension",
								"type": "DatasetReference"
							},
							"name": "RawPartitionPruning"
						},
						{
							"dataset": {
								"referenceName": "GenericServerlessSQL",
								"type": "DatasetReference"
							},
							"name": "dummyPartitionPruning"
						}
					],
					"sinks": [
						{
							"linkedService": {
								"referenceName": "templateenrst_ARIR",
								"type": "LinkedServiceReference"
							},
							"name": "EnrichedDeltaLake"
						},
						{
							"name": "sinkPartitionPruning"
						}
					],
					"transformations": [
						{
							"name": "alterRow"
						},
						{
							"name": "elicitDuplicates"
						},
						{
							"name": "derivedId",
							"description": "Added as Window function cannot interpret byName('Id') as valid for OVER statement"
						},
						{
							"name": "filterDuplicates"
						},
						{
							"name": "removeTempColumns"
						},
						{
							"name": "aggregatePartitionPruning"
						},
						{
							"name": "unionPartitionPruning"
						},
						{
							"name": "collectPartitionPruning"
						}
					],
					"scriptLines": [
						"parameters{",
						"     c_target_container as string ('template'),",
						"     c_key_column_name as string[] ([\"name\"]),",
						"     c_raw_cdc_column as string ('rawTimestamp_ParquetToDeltaParquet'),",
						"     p_dss_update_time as string ('2024-03-06T22:24:32Z'),",
						"     c_enr_cdc_column as string ('enrTimestamp_ParquetToDeltaParquet'),",
						"     p_partition_formula as string (\"'dummy'\"),",
						"     c_target_root_folder as string ('FromParquetToDeltaParquet'),",
						"     p_object as string ('dataflows_SQL'),",
						"     p_processing_mode as string ('bulk')",
						"}",
						"source(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     fileList: true,",
						"     rowUrlColumn: 'fileName',",
						"     format: 'parquet',",
						"     dateFormats: ['yyyy-MM-dd'],",
						"     timestampFormats: ['yyyy-MM-dd\\'T\\'HH:mm:ss.SSS\\'Z\\'','yyyy-MM-dd\\'T\\'HH:mm:ss\\'Z\\''],",
						"     preferredIntegralType: 'long',",
						"     preferredFractionalType: 'decimal') ~> RawDataset",
						"source(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     fileList: true,",
						"     format: 'parquet') ~> RawPartitionPruning",
						"source(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     query: 'select \\'dummy\\' as PARTITION,\\n\\'CONSTANT\\' as CONSTANT, \\'dummy\\' as AGGREGATE',",
						"     format: 'query',",
						"     staged: false) ~> dummyPartitionPruning",
						"removeTempColumns alterRow(upsertIf(true())) ~> alterRow",
						"derivedId window(over(keyColumn),",
						"     desc(toString(byName($c_raw_cdc_column)), true),",
						"     rowNum = rowNumber()) ~> elicitDuplicates",
						"RawDataset derive(keyColumn = md5(byNames($c_key_column_name)),",
						"          each(match(name=='fileName'), $c_raw_cdc_column = iif($p_processing_mode == 'incremental', replace(reverse(substring(reverse(toString($$)), 0, locate('_', reverse(toString($$))) - 1)), '.parquet'), toString(null())), $c_enr_cdc_column = toTimestamp($p_dss_update_time, \"yyyy-MM-dd'T'HH:mm:ss'Z'\")),",
						"          DELTA_PARTITION = expr($p_partition_formula)) ~> derivedId",
						"elicitDuplicates filter(rowNum == 1 && not(isNull(keyColumn))) ~> filterDuplicates",
						"filterDuplicates select(mapColumn(",
						"          each(match(name!='rowNum'&&name!='fileName'&&name!='keyColumn'))",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> removeTempColumns",
						"RawPartitionPruning aggregate(groupBy(PARTITION = expr($p_partition_formula),",
						"          CONSTANT = 'CONSTANT'),",
						"     AGGREGATE = first(expr($p_partition_formula))) ~> aggregatePartitionPruning",
						"aggregatePartitionPruning, dummyPartitionPruning union(byName: true)~> unionPartitionPruning",
						"unionPartitionPruning aggregate(groupBy(CONSTANT),",
						"     PARTITION = collect(AGGREGATE)) ~> collectPartitionPruning",
						"alterRow sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     format: 'delta',",
						"     compressionType: 'snappy',",
						"     compressionLevel: 'Fastest',",
						"     fileSystem: ($c_target_container),",
						"     folderPath: ($c_target_root_folder + '/' + $p_object),",
						"     mergeSchema: false,",
						"     autoCompact: false,",
						"     optimizedWrite: false,",
						"     vacuum: 0,",
						"     deletable: false,",
						"     insertable: false,",
						"     updateable: false,",
						"     upsertable: true,",
						"     keys:($c_key_column_name),",
						"     pruneCondition: ['DELTA_PARTITION' -> (sinkPartitionPruning#outputs().PARTITION_PRUNING)],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     saveOrder: 2,",
						"     partitionBy('key',",
						"          0,",
						"          DELTA_PARTITION",
						"     )) ~> EnrichedDeltaLake",
						"collectPartitionPruning sink(validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     store: 'cache',",
						"     format: 'inline',",
						"     output: false,",
						"     saveOrder: 1,",
						"     mapColumn(",
						"          PARTITION_PRUNING = PARTITION",
						"     )) ~> sinkPartitionPruning"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/GenericRawParquet_NoExtension')]",
				"[concat(variables('workspaceId'), '/datasets/GenericServerlessSQL')]",
				"[concat(variables('workspaceId'), '/linkedServices/templateenrst_ARIR')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/StarSchemaDimension')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Templates"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "GenericServerlessSQL",
								"type": "DatasetReference"
							},
							"name": "DataSource"
						},
						{
							"dataset": {
								"referenceName": "GenericServerlessSQL",
								"type": "DatasetReference"
							},
							"name": "Dimension"
						},
						{
							"dataset": {
								"referenceName": "GenericServerlessSQL",
								"type": "DatasetReference"
							},
							"name": "DimensionMaxKey"
						},
						{
							"dataset": {
								"referenceName": "GenericServerlessSQL",
								"type": "DatasetReference"
							},
							"name": "DimensionZeroRow"
						},
						{
							"dataset": {
								"referenceName": "GenericServerlessSQL",
								"type": "DatasetReference"
							},
							"name": "SourcePartitionPruning"
						},
						{
							"dataset": {
								"referenceName": "GenericServerlessSQL",
								"type": "DatasetReference"
							},
							"name": "dummyPartitionPruning"
						}
					],
					"sinks": [
						{
							"name": "CacheMaxKey"
						},
						{
							"linkedService": {
								"referenceName": "templatecurst_ARIR",
								"type": "LinkedServiceReference"
							},
							"name": "sinkZeroRecord"
						},
						{
							"linkedService": {
								"referenceName": "templatecurst_ARIR",
								"type": "LinkedServiceReference"
							},
							"name": "sinkDimension"
						},
						{
							"name": "sinkPartitionPruning"
						}
					],
					"transformations": [
						{
							"name": "lookupDimension"
						},
						{
							"name": "selectDimension"
						},
						{
							"name": "derivedNewKey"
						},
						{
							"name": "surrogateKey"
						},
						{
							"name": "split1"
						},
						{
							"name": "derivedColumns"
						},
						{
							"name": "derivedExistingKey"
						},
						{
							"name": "union"
						},
						{
							"name": "selectBeforeSink"
						},
						{
							"name": "alterRow"
						},
						{
							"name": "alterZeroRow"
						},
						{
							"name": "sourceLookupKey"
						},
						{
							"name": "dimLookupKey"
						},
						{
							"name": "derivedMaxKey"
						},
						{
							"name": "aggregatePartitionPruning"
						},
						{
							"name": "unionPartitionPruning"
						},
						{
							"name": "collectPartitionPruning"
						}
					],
					"scriptLines": [
						"parameters{",
						"     p_src_key_cols as string[] ([\"name\"]),",
						"     p_src_cdc_col as string ('enrTimestamp'),",
						"     p_surrogate_key_col as string,",
						"     c_trg_dss_update_col as string ('dss_update_time'),",
						"     c_trg_dss_create_col as string ('dss_create_time'),",
						"     p_partition_formula as string (\"'dummy'\"),",
						"     c_trg_partition_col as string ('DIM_PARTITION'),",
						"     p_src_schema as string ('enr'),",
						"     p_src_object as string ('dataflows_REST_API'),",
						"     p_datetime_from as string ('2024-03-06T21:24:57'),",
						"     p_trg_table as string ('DimDataflows'),",
						"     p_init_load as boolean (false()),",
						"     c_trg_container as string ('template'),",
						"     c_trg_root_folder as string ('StarSchemaObjects')",
						"}",
						"source(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     query: (\"select * from \" + $p_src_schema + \".\" + $p_src_object + iif(length(coalesce($p_src_cdc_col, \"\")) == 0, \"\", \" where \" + $p_src_cdc_col + \" > '\" + iif(length(coalesce($p_datetime_from, \"\")) == 0, \"1900-01-01\", $p_datetime_from) + \"'\")),",
						"     format: 'query',",
						"     staged: false) ~> DataSource",
						"source(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     query: (iif(not($p_init_load), \"select \" + $p_surrogate_key_col + reduce($p_src_key_cols, \"\", #acc + \", \" + #item, #result) + iif(length(coalesce($c_trg_dss_create_col, \"\")) == 0, \"\", \", \" + $c_trg_dss_create_col) + \" from \" + $p_trg_table, \"select cast(0 as bigint) as \" + $p_surrogate_key_col + reduce($p_src_key_cols, \"\", #acc + \", '' as \" + #item, #result) + iif(length(coalesce($c_trg_dss_create_col, \"\")) == 0, \"\", \", cast('1900-01-01' as datetime) as \" + $c_trg_dss_create_col + \" where 1 = 0\"))),",
						"     format: 'query',",
						"     staged: false) ~> Dimension",
						"source(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     query: (iif(not($p_init_load), \"select max(\" + $p_surrogate_key_col + \") as \" + $p_surrogate_key_col + \" from \" + $p_trg_table, \"select cast(0 as bigint) as \" + $p_surrogate_key_col)),",
						"     format: 'query',",
						"     staged: false) ~> DimensionMaxKey",
						"source(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     query: (\"select cast(0 as bigint) as \" + $p_surrogate_key_col + reduce($p_src_key_cols, \"\", #acc + \", '' as \" + #item, #result) + \", 'dummy' as \" + $c_trg_partition_col),",
						"     format: 'query',",
						"     staged: false) ~> DimensionZeroRow",
						"source(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     query: (\"select * from \" + $p_src_schema + \".\" + $p_src_object + iif(length(coalesce($p_src_cdc_col, \"\")) == 0, \"\", \" where \" + $p_src_cdc_col + \" > '\" + iif(length(coalesce($p_datetime_from, \"\")) == 0, \"1900-01-01\", $p_datetime_from) + \"'\")),",
						"     format: 'query',",
						"     staged: false) ~> SourcePartitionPruning",
						"source(output(",
						"          PARTITION as string,",
						"          CONSTANT as string,",
						"          AGGREGATE as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     query: 'select \\'dummy\\' as PARTITION,\\n\\'CONSTANT\\' as CONSTANT, \\'dummy\\' as AGGREGATE',",
						"     format: 'query',",
						"     staged: false) ~> dummyPartitionPruning",
						"sourceLookupKey, selectDimension lookup(lookupKey == PREFIX_lookupKey,",
						"     multiple: false,",
						"     pickup: 'any',",
						"     broadcast: 'auto')~> lookupDimension",
						"dimLookupKey select(mapColumn(",
						"          each(match(true()),",
						"               'PREFIX_'+$$ = $$)",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> selectDimension",
						"surrogateKey derive(each(match(name=='surrogateKey'), $p_surrogate_key_col = surrogateKey + coalesce(CacheMaxKey#outputs()[0].surrogateKey, 0))) ~> derivedNewKey",
						"split1@NullKey keyGenerate(output(surrogateKey as long),",
						"     startAt: 1L,",
						"     stepValue: 1L) ~> surrogateKey",
						"derivedColumns split(isNull(toLong(byName('PREFIX_' + $p_surrogate_key_col))),",
						"     disjoint: false) ~> split1@(NullKey, NotNullKey)",
						"lookupDimension derive(each(match(name=='PREFIX_'+$c_trg_dss_create_col), $c_trg_dss_create_col = coalesce($$, currentTimestamp())),",
						"          each(match(name=='PREFIX_'+$p_surrogate_key_col), $c_trg_dss_update_col = currentTimestamp(), $c_trg_partition_col = expr($p_partition_formula))) ~> derivedColumns",
						"split1@NotNullKey derive(each(match(name=='PREFIX_'+$p_surrogate_key_col), $p_surrogate_key_col = $$)) ~> derivedExistingKey",
						"derivedNewKey, derivedExistingKey union(byName: true)~> union",
						"union select(mapColumn(",
						"          each(match(left(name,length('PREFIX_'))!='PREFIX_'&&name!='surrogateKey'&&name!='lookupKey'))",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> selectBeforeSink",
						"selectBeforeSink alterRow(upsertIf(true())) ~> alterRow",
						"DimensionZeroRow alterRow(upsertIf(true())) ~> alterZeroRow",
						"DataSource derive(lookupKey = md5(byNames($p_src_key_cols))) ~> sourceLookupKey",
						"Dimension derive(lookupKey = md5(byNames($p_src_key_cols))) ~> dimLookupKey",
						"DimensionMaxKey derive(surrogateKey = toLong(byName($p_surrogate_key_col))) ~> derivedMaxKey",
						"SourcePartitionPruning aggregate(groupBy(PARTITION = expr($p_partition_formula),",
						"          CONSTANT = 'CONSTANT'),",
						"     AGGREGATE = first(expr($p_partition_formula))) ~> aggregatePartitionPruning",
						"aggregatePartitionPruning, dummyPartitionPruning union(byName: true)~> unionPartitionPruning",
						"unionPartitionPruning aggregate(groupBy(CONSTANT),",
						"     PARTITION = collect(AGGREGATE)) ~> collectPartitionPruning",
						"derivedMaxKey sink(validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     store: 'cache',",
						"     format: 'inline',",
						"     output: false,",
						"     saveOrder: 2,",
						"     mapColumn(",
						"          surrogateKey",
						"     )) ~> CacheMaxKey",
						"alterZeroRow sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     format: 'delta',",
						"     fileSystem: ($c_trg_container),",
						"     folderPath: ($c_trg_root_folder + \"/\" + $p_trg_table),",
						"     mergeSchema: true,",
						"     autoCompact: true,",
						"     optimizedWrite: true,",
						"     vacuum: 0,",
						"     deletable: false,",
						"     insertable: false,",
						"     updateable: false,",
						"     upsertable: true,",
						"     keys:($p_src_key_cols),",
						"     pruneCondition: [($c_trg_partition_col) -> ([\"dummy\"])],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     saveOrder: 1,",
						"     partitionBy('key',",
						"          0,",
						"          byName($c_trg_partition_col)",
						"     )) ~> sinkZeroRecord",
						"alterRow sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     format: 'delta',",
						"     fileSystem: ($c_trg_container),",
						"     folderPath: ($c_trg_root_folder + \"/\" + $p_trg_table),",
						"     mergeSchema: true,",
						"     autoCompact: true,",
						"     optimizedWrite: true,",
						"     vacuum: 0,",
						"     deletable: false,",
						"     insertable: false,",
						"     updateable: false,",
						"     upsertable: true,",
						"     keys:($p_src_key_cols),",
						"     pruneCondition: [($c_trg_partition_col) -> (sinkPartitionPruning#outputs().PARTITION_PRUNING)],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     saveOrder: 3,",
						"     partitionBy('key',",
						"          0,",
						"          byName($c_trg_partition_col)",
						"     )) ~> sinkDimension",
						"collectPartitionPruning sink(validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     store: 'cache',",
						"     format: 'inline',",
						"     output: false,",
						"     saveOrder: 1,",
						"     mapColumn(",
						"          PARTITION_PRUNING = PARTITION",
						"     )) ~> sinkPartitionPruning"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/GenericServerlessSQL')]",
				"[concat(variables('workspaceId'), '/linkedServices/templatecurst_ARIR')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/StarSchemaFact')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Templates"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "GenericServerlessSQL",
								"type": "DatasetReference"
							},
							"name": "DataSource"
						},
						{
							"dataset": {
								"referenceName": "GenericServerlessSQL",
								"type": "DatasetReference"
							},
							"name": "Fact"
						},
						{
							"dataset": {
								"referenceName": "GenericServerlessSQL",
								"type": "DatasetReference"
							},
							"name": "SourcePartitionPruning"
						},
						{
							"dataset": {
								"referenceName": "GenericServerlessSQL",
								"type": "DatasetReference"
							},
							"name": "dummyPartitionPruning"
						}
					],
					"sinks": [
						{
							"linkedService": {
								"referenceName": "templatecurst_ARIR",
								"type": "LinkedServiceReference"
							},
							"name": "sinkDimension"
						},
						{
							"name": "sinkPartitionPruning"
						}
					],
					"transformations": [
						{
							"name": "lookupDimension"
						},
						{
							"name": "selectFact"
						},
						{
							"name": "derivedColumns"
						},
						{
							"name": "selectBeforeSink"
						},
						{
							"name": "alterRow"
						},
						{
							"name": "sourceLookupKey"
						},
						{
							"name": "factLookupKey"
						},
						{
							"name": "aggregatePartitionPruning"
						},
						{
							"name": "unionPartitionPruning"
						},
						{
							"name": "collectPartitionPruning"
						}
					],
					"scriptLines": [
						"parameters{",
						"     p_src_key_cols as string[] ([\"dataflows_name\",\"datasets_name\"]),",
						"     c_trg_dss_update_col as string ('dss_update_time'),",
						"     c_trg_dss_create_col as string ('dss_create_time'),",
						"     p_partition_formula as string (\"'dummy'\"),",
						"     c_trg_partition_col as string ('FACT_PARTITION'),",
						"     p_trg_table as string ('FactDataflowsDatasets'),",
						"     c_trg_container as string ('template'),",
						"     c_trg_root_folder as string ('StarSchemaObjects'),",
						"     p_src_query as string (\"select coalesce(DimDataflows.dataflows_key, 0) dataflows_key, coalesce(DimDatasets.datasets_key, 0) datasets_key, stg.* from openrowset(bulk 'https://ivsenr.dfs.core.windows.net/template/Staging/FactDataflowsDatasetsStg.parquet', format = 'PARQUET') as stg left outer join DimDataflows DimDataflows on stg.dataflows_name = DimDataflows.name left outer join DimDatasets DimDatasets on stg.datasets_name = DimDatasets.name\"),",
						"     p_trg_query as string (\"select null as dataflows_name, null as datasets_name, cast(null as datetime) as dss_create_time where 1 = 0\")",
						"}",
						"source(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     query: ($p_src_query),",
						"     format: 'query',",
						"     staged: false) ~> DataSource",
						"source(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     query: ($p_trg_query),",
						"     format: 'query',",
						"     staged: false) ~> Fact",
						"source(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     query: ($p_src_query),",
						"     format: 'query',",
						"     staged: false) ~> SourcePartitionPruning",
						"source(output(",
						"          PARTITION as string,",
						"          CONSTANT as string,",
						"          AGGREGATE as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     query: 'select \\'dummy\\' as PARTITION,\\n\\'CONSTANT\\' as CONSTANT, \\'dummy\\' as AGGREGATE',",
						"     format: 'query',",
						"     staged: false) ~> dummyPartitionPruning",
						"sourceLookupKey, selectFact lookup(lookupKey == PREFIX_lookupKey,",
						"     multiple: false,",
						"     pickup: 'any',",
						"     broadcast: 'auto')~> lookupDimension",
						"factLookupKey select(mapColumn(",
						"          each(match(true()),",
						"               'PREFIX_'+$$ = $$)",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> selectFact",
						"lookupDimension derive(each(match(name=='PREFIX_'+$c_trg_dss_create_col), $c_trg_dss_create_col = coalesce($$, currentTimestamp()), $c_trg_dss_update_col = currentTimestamp(), $c_trg_partition_col = expr($p_partition_formula))) ~> derivedColumns",
						"derivedColumns select(mapColumn(",
						"          each(match(left(name,length('PREFIX_'))!='PREFIX_'&&name!='surrogateKey'&&name!='lookupKey'))",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> selectBeforeSink",
						"selectBeforeSink alterRow(upsertIf(true())) ~> alterRow",
						"DataSource derive(lookupKey = md5(byNames($p_src_key_cols))) ~> sourceLookupKey",
						"Fact derive(lookupKey = md5(byNames($p_src_key_cols))) ~> factLookupKey",
						"SourcePartitionPruning aggregate(groupBy(PARTITION = expr($p_partition_formula),",
						"          CONSTANT = 'CONSTANT'),",
						"     AGGREGATE = first(expr($p_partition_formula))) ~> aggregatePartitionPruning",
						"aggregatePartitionPruning, dummyPartitionPruning union(byName: true)~> unionPartitionPruning",
						"unionPartitionPruning aggregate(groupBy(CONSTANT),",
						"     PARTITION = collect(AGGREGATE)) ~> collectPartitionPruning",
						"alterRow sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     format: 'delta',",
						"     fileSystem: ($c_trg_container),",
						"     folderPath: ($c_trg_root_folder + \"/\" + $p_trg_table),",
						"     mergeSchema: true,",
						"     autoCompact: true,",
						"     optimizedWrite: true,",
						"     vacuum: 0,",
						"     deletable: false,",
						"     insertable: false,",
						"     updateable: false,",
						"     upsertable: true,",
						"     keys:($p_src_key_cols),",
						"     pruneCondition: [($c_trg_partition_col) -> (sinkPartitionPruning#outputs().PARTITION_PRUNING)],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     saveOrder: 2,",
						"     partitionBy('key',",
						"          0,",
						"          byName($c_trg_partition_col)",
						"     )) ~> sinkDimension",
						"collectPartitionPruning sink(validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     store: 'cache',",
						"     format: 'inline',",
						"     output: false,",
						"     saveOrder: 1,",
						"     mapColumn(",
						"          PARTITION_PRUNING = PARTITION",
						"     )) ~> sinkPartitionPruning"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/GenericServerlessSQL')]",
				"[concat(variables('workspaceId'), '/linkedServices/templatecurst_ARIR')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/TemplateIncrementalStaging')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Templates"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ADLS_TMPL_DATASOURCE1",
								"type": "DatasetReference"
							},
							"name": "MainSource"
						},
						{
							"dataset": {
								"referenceName": "TMPL_DATASOURCE2",
								"type": "DatasetReference"
							},
							"name": "SlaveSource2"
						},
						{
							"dataset": {
								"referenceName": "ADLS_TMPL_DATASOURCE3",
								"type": "DatasetReference"
							},
							"name": "SlaveSource3"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "TMPL_STAGING",
								"type": "DatasetReference"
							},
							"name": "SinkStaging"
						},
						{
							"dataset": {
								"referenceName": "TMPL_STAGING_KEY",
								"type": "DatasetReference"
							},
							"name": "SinkStagingKey"
						}
					],
					"transformations": [
						{
							"name": "SelectMain"
						},
						{
							"name": "SelectSource2"
						},
						{
							"name": "SelectSource3"
						},
						{
							"name": "JoinSource2"
						},
						{
							"name": "JoinSource3"
						},
						{
							"name": "DerivedColumns"
						}
					],
					"script": "parameters{\n\tp_latest_datetime as string ('1900-01-01 00:00:000'),\n\tp_main_source as string ('ADLS_TMPL_DATASOURCE1'),\n\tp_cdc_column as string ('CDC_TIMESTAMP')\n}\nsource(output(\n\t\tSOURCE1_ID as integer,\n\t\tSOURCE2_REF_ID as integer,\n\t\tSOURCE3_REF_ID as integer,\n\t\tNCHAR_VALUE1 as string,\n\t\tNCHAR_VALUE2 as string,\n\t\tNUMERIC_VALUE1 as decimal(12,6),\n\t\tNUMERIC_VALUE2 as decimal(12,6),\n\t\tDATETIME_VALUE1 as timestamp,\n\t\tDATETIME_VALUE2 as timestamp,\n\t\tCDC_TIMESTAMP as timestamp\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tisolationLevel: 'READ_UNCOMMITTED',\n\tformat: 'table',\n\tstaged: false) ~> MainSource\nsource(output(\n\t\tSOURCE2_ID as integer,\n\t\tNCHAR_VALUE1 as string,\n\t\tNCHAR_VALUE2 as string,\n\t\tNUMERIC_VALUE1 as decimal(18,4),\n\t\tNUMERIC_VALUE2 as decimal(18,4),\n\t\tDATETIME_VALUE1 as timestamp,\n\t\tDATETIME_VALUE2 as timestamp\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> SlaveSource2\nsource(output(\n\t\tSOURCE3_ID as integer,\n\t\tNCHAR_VALUE1 as string,\n\t\tNCHAR_VALUE2 as string,\n\t\tNUMERIC_VALUE1 as decimal(12,6),\n\t\tNUMERIC_VALUE2 as decimal(12,6),\n\t\tDATETIME_VALUE1 as timestamp,\n\t\tDATETIME_VALUE2 as timestamp,\n\t\tCDC_TIMESTAMP as timestamp\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tisolationLevel: 'READ_UNCOMMITTED',\n\tformat: 'table',\n\tstaged: false) ~> SlaveSource3\nMainSource select(mapColumn(\n\t\teach(match(true()),\n\t\t\t'SRC1_'+$$ = $$)\n\t),\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true) ~> SelectMain\nSlaveSource2 select(mapColumn(\n\t\teach(match(true()),\n\t\t\t'SRC2_'+$$ = $$)\n\t),\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true) ~> SelectSource2\nSlaveSource3 select(mapColumn(\n\t\teach(match(true()),\n\t\t\t'SRC3_'+$$ = $$)\n\t),\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true) ~> SelectSource3\nSelectMain, SelectSource2 join(SRC1_SOURCE2_REF_ID == SRC2_SOURCE2_ID,\n\tjoinType:'left',\n\tmatchType:'exact',\n\tignoreSpaces: false,\n\tbroadcast: 'auto')~> JoinSource2\nJoinSource2, SelectSource3 join(SRC1_SOURCE3_REF_ID == SRC3_SOURCE3_ID,\n\tjoinType:'left',\n\tmatchType:'exact',\n\tignoreSpaces: false,\n\tbroadcast: 'auto')~> JoinSource3\nJoinSource3 derive(DSS_CREATE_TIME = currentTimestamp()) ~> DerivedColumns\nDerivedColumns sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tformat: 'parquet',\n\ttruncate: true,\n\tumask: 0022,\n\tpreCommands: [],\n\tpostCommands: [],\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true) ~> SinkStaging\nDerivedColumns sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tinput(\n\t\tSRC1_SOURCE1_ID as integer,\n\t\tSRC1_SOURCE2_REF_ID as integer,\n\t\tSRC1_SOURCE3_REF_ID as integer\n\t),\n\tformat: 'parquet',\n\ttruncate: true,\n\tumask: 0022,\n\tpreCommands: [],\n\tpostCommands: [],\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true,\n\tmapColumn(\n\t\tSRC1_SOURCE1_ID,\n\t\tSRC1_SOURCE2_REF_ID,\n\t\tSRC1_SOURCE3_REF_ID\n\t)) ~> SinkStagingKey"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/ADLS_TMPL_DATASOURCE1')]",
				"[concat(variables('workspaceId'), '/datasets/TMPL_DATASOURCE2')]",
				"[concat(variables('workspaceId'), '/datasets/ADLS_TMPL_DATASOURCE3')]",
				"[concat(variables('workspaceId'), '/datasets/TMPL_STAGING')]",
				"[concat(variables('workspaceId'), '/datasets/TMPL_STAGING_KEY')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/WorkspaceSystemIdentity')]",
			"type": "Microsoft.Synapse/workspaces/credentials",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "ManagedIdentity",
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ADLS_TMPL_DATASOURCE1')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE EXTERNAL TABLE [dbo].[ADLS_TMPL_DATASOURCE1] \n(  \n\t [SOURCE1_ID] INT NULL,\n\t [SOURCE2_REF_ID] INT NULL,\n\t [SOURCE3_REF_ID] INT NULL,\n\t [NCHAR_VALUE1] NVARCHAR(255) NULL,\n\t [NCHAR_VALUE2] NVARCHAR(255) NULL,\n\t [NUMERIC_VALUE1] NUMERIC(12,6) NULL,\n\t [NUMERIC_VALUE2] NUMERIC(12,6) NULL,\n\t [DATETIME_VALUE1] DATETIME NULL,\n\t [DATETIME_VALUE2] DATETIME NULL,\n\t [CDC_TIMESTAMP] DATETIME NULL\n)\nWITH  \n(  \n\tLOCATION = '/source/TMPL_DATASOURCE1.csv',  \n\tDATA_SOURCE = TMPL_ExtDSrc_ivsdatastorage ,\n    FILE_FORMAT = TMPL_DelimTextCsv\n) \n\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "ivs_sqlpool",
						"poolName": "ivs_sqlpool"
					}
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ADLS_TMPL_DATASOURCE3')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE EXTERNAL TABLE [dbo].[ADLS_TMPL_DATASOURCE3] \n(  \n\t [SOURCE3_ID] INT NULL,\n\t [NCHAR_VALUE1] NVARCHAR(255) NULL,\n\t [NCHAR_VALUE2] NVARCHAR(255) NULL,\n\t [NUMERIC_VALUE1] NUMERIC(12,6) NULL,\n\t [NUMERIC_VALUE2] NUMERIC(12,6) NULL,\n\t [DATETIME_VALUE1] DATETIME NULL,\n\t [DATETIME_VALUE2] DATETIME NULL,\n\t [CDC_TIMESTAMP] DATETIME NULL\n)\nWITH  \n(  \n\tLOCATION = '/source/TMPL_DATASOURCE3.csv',  \n\tDATA_SOURCE = TMPL_ExtDSrc_ivsdatastorage ,\n    FILE_FORMAT = TMPL_DelimTextCsv\n) ",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "ivs_sqlpool",
						"poolName": "ivs_sqlpool"
					}
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ADLS_TMPL_STAGING_KEY')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE EXTERNAL TABLE [dbo].[ADLS_TMPL_STAGING_KEY] \n(  \n\t [SRC1_SOURCE1_ID] INT NULL,\n\t [SRC1_SOURCE2_REF_ID] INT NULL,\n\t [SRC1_SOURCE3_REF_ID] INT NULL\n)\nWITH  \n(  \n\tLOCATION = 'staging/key',  \n\tDATA_SOURCE = TMPL_ExtDSrc_ivsdatastorage ,\n    FILE_FORMAT = TMPL_ParquetSnappy\n) \n\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "ivs_sqlpool",
						"poolName": "ivs_sqlpool"
					}
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/CosmosSQL')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE CREDENTIAL [cosmos_ivsaccount]\n WITH IDENTITY = 'SHARED ACCESS SIGNATURE',\n SECRET = 'exU9Lv....................................=='\n GO\n\nSELECT TOP 100 *\nFROM OPENROWSET(PROVIDER = 'CosmosDB',\n                CONNECTION = 'Account=ivsaccount;Database=AdventureWorks',\n                OBJECT = 'Sales',\n                SERVER_CREDENTIAL = 'cosmos_ivsaccount'\n) AS [Sales]\n\n\n SELECT orderdate,\n        COUNT(id) AS ordercount\n FROM OPENROWSET(PROVIDER = 'CosmosDB',\n                 CONNECTION = 'Account=ivsaccount;Database=AdventureWorks',\n                 OBJECT = 'Sales',\n                 SERVER_CREDENTIAL = 'cosmos_ivsaccount'\n ) AS [Sales]\n GROUP BY orderdate\n ORDER BY orderdate;",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "ivs-synapse-dldb",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DeltaLake')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "SELECT TOP 10 *\nFROM OPENROWSET(\n    BULK 'https://ivsdatastorage.blob.core.windows.net/synapse/ivs-synapse-dldb/Party/',\n    FORMAT = 'delta') as rows;\n\nCREATE OR ALTER VIEW dbo.Party_delta AS\nSELECT * FROM\nOPENROWSET( BULK 'https://ivsdatastorage.blob.core.windows.net/synapse/ivs-synapse-dldb/Party/', \nFORMAT = 'delta') as r\n\nselect * from dbo.Party_delta",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "ivs_od_sqlpool",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/TMPL_DIMENSION1')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE TABLE [dbo].[TMPL_DIMENSION1]\n(\n    [DIMENSION1_KEY] [int] IDENTITY(1,1) NOT NULL,\n\t[SOURCE2_ID] [int] NOT NULL,\n\t[NCHAR_ATTRIBUTE1] [nchar](20) NULL,\n\t[NCHAR_ATTRIBUTE2] [nchar](20) NULL,\n\t[DATETIME_ATTRIBUTE1] [datetime] NULL,\n\t[DATETIME_ATTRIBUTE2] [datetime] NULL,\n\t[DSS_CREATE_TIME] [datetime] NULL,\n\t[DSS_UPDATE_TIME] [datetime] NULL\n)\nWITH\n(\n    DISTRIBUTION = REPLICATE,\n    CLUSTERED COLUMNSTORE INDEX\n)\nGO\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "ivs_sqlpool",
						"poolName": "ivs_sqlpool"
					}
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/TMPL_DIMENSION2')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE TABLE [dbo].[Table]\n(\n    col1 int NOT NULL\n)\nWITH\n(\n    DISTRIBUTION = HASH (col1),\n    CLUSTERED COLUMNSTORE INDEX\n)\nGO\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"name": "ivs_sqlpool",
						"type": "SqlCompute"
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/TMPL_DelimTextCsv')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE EXTERNAL FILE FORMAT [TMPL_DelimTextCsv] WITH \n(  \n\tFORMAT_TYPE = DELIMITEDTEXT,\n\tFORMAT_OPTIONS(\n          FIELD_TERMINATOR = ',',\n          STRING_DELIMITER = '\"',\n          FIRST_ROW = 2, \n          USE_TYPE_DEFAULT = False)\n)",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "ivs_sqlpool",
						"poolName": "ivs_sqlpool"
					}
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/TMPL_ExtDSrc_ivsdatastorage')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "--CREATE MASTER KEY ENCRYPTION BY PASSWORD = '<password>' ;\n\n--CREATE DATABASE SCOPED CREDENTIAL ADLS_credential\n--WITH\n-- IDENTITY = '<storage_account_name>' ,\n-- SECRET = '<storage_account_key>';\n\nCREATE EXTERNAL DATA SOURCE TMPL_ExtDSrc_ivsdatastorage\nWITH\n  ( LOCATION = 'wasbs://adftemplate@ivsdatastorage.blob.core.windows.net',\n    CREDENTIAL = ADLS_credential,\n    TYPE = HADOOP\n  );",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "ivs_sqlpool",
						"poolName": "ivs_sqlpool"
					}
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/TMPL_FACT')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE TABLE [dbo].[TMPL_FACT]\n(\n    [DIMENSION1_KEY] [int] NOT NULL,\n\t[DIMENSION2_KEY] [int] NOT NULL,\n\t[SOURCE1_ID] [int] NOT NULL,\n\t[SRC1_MEASURE1] [decimal](18, 4) NULL,\n\t[SRC1_MEASURE2] [decimal](18, 4) NULL,\n\t[SRC2_MEASURE1] [decimal](18, 4) NULL,\n\t[SRC2_MEASURE2] [decimal](18, 4) NULL,\n\t[SRC3_MEASURE1] [decimal](18, 4) NULL,\n\t[SRC3_MEASURE2] [decimal](18, 4) NULL,\n\t[SRC1_CDC_TIMESTAMP] [datetime] NULL,\n\t[DSS_CREATE_TIME] [datetime] NULL,\n\t[DSS_UPDATE_TIME] [datetime] NULL\n)\nWITH\n(\n    DISTRIBUTION = HASH (SOURCE1_ID),\n    CLUSTERED COLUMNSTORE INDEX\n)\nGO\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "ivs_sqlpool",
						"poolName": "ivs_sqlpool"
					}
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/TMPL_ParquetSnappy')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE EXTERNAL FILE FORMAT [TMPL_ParquetSnappy] WITH \n(  \n    FORMAT_TYPE = PARQUET,  \n    DATA_COMPRESSION = 'org.apache.hadoop.io.compress.SnappyCodec'\n)",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "ivs_sqlpool",
						"poolName": "ivs_sqlpool"
					}
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Template_cur_source')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Serverless Deploy"
				},
				"content": {
					"query": "IF NOT EXISTS (SELECT * FROM sys.external_data_sources WHERE name = 'TemplateCuratedSource') \n\tCREATE EXTERNAL DATA SOURCE [TemplateCuratedSource] \n\tWITH (\n\t\tLOCATION = 'https://ivscur.blob.core.windows.net/template',\n\t\tCREDENTIAL = [SynapseIdentity] \n\t)",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "templateDB",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Template_delta_format')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Serverless Deploy"
				},
				"content": {
					"query": "IF NOT EXISTS (SELECT * FROM sys.external_file_formats WHERE name = 'Delta') \n\tCREATE EXTERNAL FILE FORMAT Delta\n\tWITH (\n\t\tFORMAT_TYPE = DELTA\n\t)",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "templateDB",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Template_enr_schema')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Serverless Deploy"
				},
				"content": {
					"query": "IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'enr') \nEXEC('CREATE SCHEMA [enr]')",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "templateDB",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/VTMPL_DATASOURCE1')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE VIEW VTMPL_DATASOURCE1 AS\nSELECT *\nFROM OPENROWSET\n  (\n      BULK 'https://ivsdatastorage.blob.core.windows.net/adftemplate/source/TMPL_DATASOURCE1.csv',\n      FORMAT = 'CSV', PARSER_VERSION = '2.0', FIRSTROW = 2\n  )\n  WITH ( SOURCE1_ID integer,\n  \t  SOURCE2_REF_ID integer,\t\n      SOURCE3_REF_ID integer,\t\n      NCHAR_VALUE1 varchar (50),\n      NCHAR_VALUE2 varchar (50),\t\n      NUMERIC_VALUE1 varchar (50),\t\n      NUMERIC_VALUE2 varchar (50),\t\n      DATETIME_VALUE1 varchar (50),\n      DATETIME_VALUE2 varchar (50),\n      CDC_TIMESTAMP varchar (50)\n) AS r",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "ivs_od_sqlpool",
						"poolName": "Built-in"
					}
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ZeroRow')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE PROC [dbo].[ZeroRow]\n\t@p_tabname [varchar](255),\n\t@p_keycolname [varchar](255),\n\t@p_varchar [varchar](255),\n\t@p_numeric [tinyint],\n\t@p_date [date],\n\t@p_time [time],\n\t@p_bit [bit] \n\t\nAS\n\nDECLARE\n\t@v_return_status integer,\n\t@v_count bit = 0,\n\t@v_column_name varchar(255),\n\t@v_data_type varchar(255),\n\t@v_character_maximum_length integer,\n\t@v_is_nullable varchar(3),\n\t@v_notnull_conv varchar(255),\n\t@v_ins_sql_top varchar(max),\n\t@v_ins_sql_bottom varchar(max),\n\t@v_upd_sql varchar(max),\n\t@v_ctrl_sql nvarchar(max) = '',\n\t@v_sql nvarchar(max) = '',\n\t@v_sql_param nvarchar(max) = ''\n\nBEGIN\n    CREATE TABLE #tbl\n\tWITH\n\t( DISTRIBUTION = ROUND_ROBIN\n\t)\n\tAS\n\tselect \n\tROW_NUMBER() OVER(ORDER BY ordinal_position) AS sequence,\n\tcolumn_name,\n\tis_nullable,\n\tdata_type,\n\tcharacter_maximum_length\n\tfrom information_schema.columns\n\twhere table_name = @p_tabname\n\n\tDECLARE @v_loop_limit int = (SELECT COUNT(*) FROM #tbl)\n\t,       @v_i int = 1\n\n\tSET @v_ins_sql_top = '('\n\tSET @v_ins_sql_bottom = '('\n\tSET @v_upd_sql = ''\n\tSET @v_sql_param = N'@v_column_name varchar(255) OUTPUT, ' +\n\t\t\t\t\tN'@v_is_nullable varchar(3) OUTPUT, ' +\n\t\t\t\t\tN'@v_data_type varchar(255) OUTPUT, ' +\n\t\t\t\t\tN'@v_character_maximum_length integer OUTPUT'\n\n\tWHILE @v_i <= @v_loop_limit\n\t  BEGIN\n\n\t\tSET @v_sql = N'SELECT @v_column_name = column_name, ' +\n\t\t\tN'@v_is_nullable = is_nullable, ' +\n\t\t\tN'@v_data_type = data_type, ' +\n\t\t\tN'@v_character_maximum_length = character_maximum_length FROM #tbl WHERE sequence = ' + CAST(@v_i as nvarchar(20))\n\n\t\tEXECUTE sp_executesql @v_sql, @v_sql_param, \n\t\t\t\t\t\t\t\t@v_column_name OUTPUT, \n\t\t\t\t\t\t\t\t@v_is_nullable OUTPUT,\n\t\t\t\t\t\t\t\t@v_data_type OUTPUT, \n\t\t\t\t\t\t\t\t@v_character_maximum_length OUTPUT\n\n\t\tSET @v_ins_sql_top = @v_ins_sql_top + @v_column_name + char(13) + ', '\n\n\t\tIF (@v_data_type = 'char' or @v_data_type = 'varchar' \n\t\tor @v_data_type = 'text' or @v_data_type = 'nchar' \n\t\tor @v_data_type = 'nvarchar' or @v_data_type = 'ntext')\n\t\t\tBEGIN\n\t\t\t\tSET @v_ins_sql_bottom = @v_ins_sql_bottom + char(39) + LEFT(@p_varchar, @v_character_maximum_length) + char(39) + char(13) + ', '\n\t\t\t\tSET @v_upd_sql = @v_upd_sql + @v_column_name + ' = ' + char(39) + LEFT(@p_varchar, @v_character_maximum_length) + char(39) + char(13) + ', '\n\t\t\tEND\n\t\tELSE\n\t\t\tIF (@v_data_type = 'date' or @v_data_type = 'datetime' \n\t\t\tor @v_data_type = 'datetime2' or @v_data_type = 'datetimeoffset' \n\t\t\tor @v_data_type = 'smalldatetime') \n\t\t\tand (try_cast(@p_date as date) is not null \n\t\t\tor @v_column_name = 'DSS_UPDATE_TIME' or @v_column_name = 'DSS_CREATE_TIME')\n\t\t\t\tBEGIN\n\t\t\t\t\tIF @v_column_name = 'DSS_UPDATE_TIME'\n\t\t\t\t\t\tBEGIN\n\t\t\t\t\t\t\tSET @v_ins_sql_bottom = @v_ins_sql_bottom + char(39) + CONVERT(varchar, getdate(), 121) + char(39) + char(13) + ', '\n\t\t\t\t\t\t\tSET @v_upd_sql = @v_upd_sql + @v_column_name + ' = ' + char(39) + CONVERT(varchar, getdate(), 121) + char(39) + char(13) + ', '\n\t\t\t\t\t\tEND\n\t\t\t\t\tELSE\n\t\t\t\t\t\tBEGIN\n\t\t\t\t\t\t\tIF @v_column_name = 'DSS_CREATE_TIME'\n\t\t\t\t\t\t\t\tBEGIN\n\t\t\t\t\t\t\t\t\tSET @v_ins_sql_bottom = @v_ins_sql_bottom + char(39) + CONVERT(varchar, getdate(), 121) + char(39) + char(13) + ', '\n\t\t\t\t\t\t\t\t\tSET @v_upd_sql = @v_upd_sql + @v_column_name + ' = COALESCE(DSS_CREATE_TIME, getdate())' + char(13) + ', '\n\t\t\t\t\t\t\t\tEND\n\t\t\t\t\t\t\tELSE\n\t\t\t\t\t\t\t\tBEGIN\n\t\t\t\t\t\t\t\t\tSET @v_ins_sql_bottom = @v_ins_sql_bottom + char(39) + cast(@p_date as varchar) + char(39) + char(13) + ', '\n\t\t\t\t\t\t\t\t\tSET @v_upd_sql = @v_upd_sql + @v_column_name + ' = ' + char(39) + cast(@p_date as varchar) + char(39) + char(13) + ', '\n\t\t\t\t\t\t\t\tEND\n\t\t\t\t\t\tEND\n\t\t\t\tEND\n\t\t\tELSE\n\t\t\t\tIF @v_data_type = 'time' and try_cast(@p_time as time) is not null\n\t\t\t\t\tBEGIN\n\t\t\t\t\t\tSET @v_ins_sql_bottom = @v_ins_sql_bottom + char(39) + cast(@p_time as varchar) + char(39) + char(13) + ', '\n\t\t\t\t\t\tSET @v_upd_sql = @v_upd_sql + @v_column_name + ' = ' + char(39) + cast(@p_time as varchar) + char(39) + char(13) + ', '\n\t\t\t\t\tEND\n\t\t\t\tELSE\n\t\t\t\t\tIF (@v_data_type = 'bigint' or @v_data_type = 'numeric' \n\t\t\t\t\tor @v_data_type = 'smallint' or @v_data_type = 'decimal' \n\t\t\t\t\tor @v_data_type = 'smallmoney' or @v_data_type = 'int'\n\t\t\t\t\tor @v_data_type = 'tinyint' or @v_data_type = 'money'\n\t\t\t\t\tor @v_data_type = 'float' or @v_data_type = 'real') \n\t\t\t\t\tand try_cast(@p_numeric as tinyint) is not null\n\t\t\t\t\tand UPPER(@v_column_name) <> UPPER(@p_keycolname)\n\t\t\t\t\t\tBEGIN\n\t\t\t\t\t\t\tSET @v_ins_sql_bottom = @v_ins_sql_bottom + cast(@p_numeric as varchar) + char(13) + ', '\n\t\t\t\t\t\t\tSET @v_upd_sql = @v_upd_sql + @v_column_name + ' = ' + cast(@p_numeric as varchar) + char(13) + ', '\n\t\t\t\t\t\tEND\n\t\t\t\t\tELSE\n\t\t\t\t\t\tIF @v_data_type = 'bit' and try_cast(@p_bit as bit) is not null\n\t\t\t\t\t\t\tBEGIN\n\t\t\t\t\t\t\t\tSET @v_ins_sql_bottom = @v_ins_sql_bottom + cast(@p_bit as varchar) + char(13) + ', '\n\t\t\t\t\t\t\t\tSET @v_upd_sql = @v_upd_sql + @v_column_name + ' = ' + cast(@p_bit as varchar) + char(13) + ', '\n\t\t\t\t\t\t\tEND\n\t\t\t\t\t\tELSE\n\t\t\t\t\t\t\tBEGIN\n\t\t\t\t\t\t\t\tIF UPPER(@v_column_name) = @p_keycolname\n\t\t\t\t\t\t\t\t\tBEGIN\n\t\t\t\t\t\t\t\t\t\tSET @v_ins_sql_bottom = @v_ins_sql_bottom + '0' + char(13) + ', '\n\t\t\t\t\t\t\t\t\tEND\n\t\t\t\t\t\t\t\tELSE\n\t\t\t\t\t\t\t\t\tBEGIN\n\t\t\t\t\t\t\t\t\t\tIF @v_is_nullable = 'YES'\n\t\t\t\t\t\t\t\t\t\t\tBEGIN\n\t\t\t\t\t\t\t\t\t\t\t\tSET @v_ins_sql_bottom  = @v_ins_sql_bottom + 'NULL' + char(13) + ', '\n\t\t\t\t\t\t\t\t\t\t\t\tSET @v_upd_sql = @v_upd_sql + @v_column_name + ' = ' + 'NULL' + char(13) + ', '\n\t\t\t\t\t\t\t\t\t\t\tEND\n\t\t\t\t\t\t\t\t\t\tELSE\n\t\t\t\t\t\t\t\t\t\t\tBEGIN\n\t\t\t\t\t\t\t\t\t\t\t\tSET @v_ctrl_sql = N'select @v_val_conv = cast('+ char(39) + char(39) + ' as ' + @v_data_type + N')'\n\t\t\t\t\t\t\t\t\t\t\t\tEXECUTE sp_executesql @v_ctrl_sql, N'@v_val_conv varchar(255) OUTPUT', @v_notnull_conv OUTPUT\n\t\t\t\t\t\t\t\t\t\t\t\tSET @v_ins_sql_bottom  = @v_ins_sql_bottom + @v_notnull_conv + char(13) + ', '\n\t\t\t\t\t\t\t\t\t\t\t\tSET @v_upd_sql = @v_upd_sql + @v_column_name + ' = ' + char(39) + @v_notnull_conv + char(39) + char(13) + ', '\n\t\t\t\t\t\t\t\t\t\t\tEND\n\t\t\t\t\t\t\t\t\tEND\n\t\t\t\t\t\t\tEND\n\n\t\tSET @v_i += 1\n\n\t  END\n\n\tSET @v_ins_sql_top = LEFT(@v_ins_sql_top, LEN(@v_ins_sql_top) - 2) + ')'\n\tSET @v_ins_sql_bottom = LEFT(@v_ins_sql_bottom, LEN(@v_ins_sql_bottom) - 2) + ')'\n\tSET @v_upd_sql = LEFT(@v_upd_sql, LEN(@v_upd_sql) - 2)\n\n\tSET @v_ctrl_sql = N'SELECT @v_count_out = 1 FROM ' + @p_tabname + N' WHERE ' + @p_keycolname + N' = 0'\n\n\tEXECUTE sp_executesql @v_ctrl_sql, N'@v_count_out bit OUTPUT', @v_count OUTPUT\n\n\tSET @v_sql = N'BEGIN' + char(13) + char(13)\n\n\tIF @v_count = 0\n\t\tBEGIN\n\t\t\tSET @v_sql = @v_sql + N'SET IDENTITY_INSERT ' + @p_tabname + N' ON' + char(13) + char(13)\n\t\t\tSET @v_sql = @v_sql + N'INSERT INTO ' + @p_tabname + char(13) + @v_ins_sql_top + char(13)\n\t\t\tSET @v_sql = @v_sql + N'VALUES ' + @v_ins_sql_bottom + char(13) + char(13)\n\t\t\tSET @v_sql = @v_sql + N'SET IDENTITY_INSERT ' + @p_tabname + N' OFF' + char(13) + char(13)\n\t\tEND\n\n\tIF @v_count = 1\n\t\tBEGIN\n\t\t\tSET @v_sql = @v_sql + N'UPDATE ' + @p_tabname + char(13) + N'SET' + char(13) + @v_upd_sql + char(13)\n\t\t\tSET @v_sql = @v_sql + N'WHERE ' + @p_keycolname + N' = 0' + char(13) + char(13)\n\t\tEND\n\n\tSET @v_sql = @v_sql + N'END'\n\n\tEXECUTE sp_executesql @v_sql\n\n\tDROP TABLE #tbl\nEND\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "ivs_sqlpool",
						"poolName": "ivs_sqlpool"
					}
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ApacheSparkPool')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "ivsspark",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "4ca85c32-02f2-4a9d-a9aa-f9e4bbaadba8"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/f939f8f3-2652-4a45-88ae-78a7782ec9df/resourceGroups/ivs-dwh-rg/providers/Microsoft.Synapse/workspaces/ivs-synapse/bigDataPools/ivsspark",
						"name": "ivsspark",
						"type": "Spark",
						"endpoint": "https://ivs-synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/ivsspark",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.1",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Create array from script"
						]
					},
					{
						"cell_type": "code",
						"source": [
							"new_rows = [('CA',22, 45000),(\"WA\",35,65000) ,(\"WA\",50,85000)]\r\n",
							"demo_df = spark.createDataFrame(new_rows, ['state', 'age', 'salary'])\r\n",
							"demo_df.show()"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Create a Spark table, a CSV, and a Parquet file all with copies of the data"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"demo_df.createOrReplaceTempView('demo_df')\r\n",
							"demo_df.write.csv('demo_df', mode='overwrite')\r\n",
							"demo_df.write.parquet('abfss://spark@ivsdatastorage.dfs.core.windows.net/demo_df', mode='overwrite')"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"List the tables on the pool"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"SHOW TABLES"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"See the data in demo_df"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false,
							"tags": []
						},
						"source": [
							"%%sql\r\n",
							"SELECT * from demo_df"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Read a CSV from Azure Data Lake Store Gen2"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"tags": []
						},
						"source": [
							"from pyspark.sql import SparkSession\r\n",
							"from pyspark.sql.types import *\r\n",
							"account_name = \"ivsdatastorage\"\r\n",
							"container_name = \"adftemplate\"\r\n",
							"relative_path = \"source\"\r\n",
							"adls_path = 'abfss://%s@%s.dfs.core.windows.net/%s' % (container_name, account_name, relative_path)\r\n",
							"\r\n",
							"df1 = spark.read.option('header', 'true') \\\r\n",
							"                .option('delimiter', ',') \\\r\n",
							"                .csv(adls_path + '/TMPL_DATASOURCE3.csv')\r\n",
							"\r\n",
							"df1.show()\r\n",
							"\r\n",
							"df1.createOrReplaceTempView('df1')"
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/BloombergToken')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "ivsspark",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "d95e6506-d940-4baa-9d8d-ca0f8c9d9441"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/f939f8f3-2652-4a45-88ae-78a7782ec9df/resourceGroups/ivs-dwh-rg/providers/Microsoft.Synapse/workspaces/ivs-synapse/bigDataPools/ivsspark",
						"name": "ivsspark",
						"type": "Spark",
						"endpoint": "https://ivs-synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/ivsspark",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.1",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"import uuid\r\n",
							"import binascii\r\n",
							"import time\r\n",
							"import jwt\r\n",
							"from urllib.parse import urlparse"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"CLIENT_ID = TokenLibrary.getSecret('ivs-dwh-kv', 'BloombergClientId')\r\n",
							"CLIENT_SECRET = TokenLibrary.getSecret('ivs-dwh-kv', 'BloombergSecret')\r\n",
							"\r\n",
							"IAT = int(time.time())\r\n",
							"JWT_EXPIRATION = 60\r\n",
							"REGION = \"default\"\r\n",
							"URL = \"https://api.bloomberg.com/eap/catalogs/\"\r\n",
							"METHOD = \"GET\"\r\n",
							"\r\n",
							"parsed_uri = urlparse(URL)\r\n",
							"PATH = parsed_uri.path\r\n",
							"HOST = parsed_uri.hostname"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"jwt_string = jwt.encode({\r\n",
							"'iss': CLIENT_ID,\r\n",
							"'iat': IAT,\r\n",
							"'nbf': IAT,\r\n",
							"'exp': IAT + JWT_EXPIRATION,\r\n",
							"'region': REGION,\r\n",
							"'path': PATH,\r\n",
							"'method': METHOD,\r\n",
							"'host': HOST,\r\n",
							"'jti': str(uuid.uuid4()),\r\n",
							"}, binascii.unhexlify(CLIENT_SECRET), algorithm=\"HS256\")\r\n",
							"\r\n",
							"TokenLibrary.putSecret('ivs-dwh-kv', 'BloombergToken', jwt_string)\r\n",
							"\r\n",
							"print(jwt_string)"
						],
						"outputs": [],
						"execution_count": 3
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Canadian Television Schedule')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Data Analysis with Python and PySpark"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "ivsspark",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "12d8dd52-cc54-4616-b7d6-0545be62690b"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/f939f8f3-2652-4a45-88ae-78a7782ec9df/resourceGroups/ivs-dwh-rg/providers/Microsoft.Synapse/workspaces/ivs-synapse/bigDataPools/ivsspark",
						"name": "ivsspark",
						"type": "Spark",
						"endpoint": "https://ivs-synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/ivsspark",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.1",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Simple Data Frame"
						]
					},
					{
						"cell_type": "code",
						"source": [
							"import pyspark.sql.functions as F\r\n",
							"\r\n",
							"my_grocery_list = (\r\n",
							"    ['Banana', 2, 1.74],\r\n",
							"    ['Apple', 4, 2.04],\r\n",
							"    ['Carrot', 1, 1.09],\r\n",
							"    ['Cake', 1, 10.99]\r\n",
							")\r\n",
							"\r\n",
							"df_grocery_list = spark.createDataFrame(\r\n",
							"    my_grocery_list, ['Item', 'Quantity', 'Price']\r\n",
							")\r\n",
							"\r\n",
							"df_grocery_list.printSchema()"
						],
						"outputs": [],
						"execution_count": 43
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Read the source"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Root path var\r\n",
							"adls_path = \"abfss://learning@ivsdatastorage.dfs.core.windows.net/DataAnalysisPythonPySpark\"\r\n",
							"\r\n",
							"#Load text file to data frame\r\n",
							"df_tv_sched = spark.read.text(adls_path + \"/data/broadcast_logs/BroadcastLogs_2018_Q3_M8_sample.CSV\")\r\n",
							"\r\n",
							"#df_tv_sched.show(5, 500)\r\n",
							"\r\n",
							"#Parse csv to data frame\r\n",
							"logs = spark.read.csv(\r\n",
							"    path = adls_path + \"/data/broadcast_logs/BroadcastLogs_2018_Q3_M8_sample.CSV\",\r\n",
							"    sep = \"|\",\r\n",
							"    inferSchema= True,\r\n",
							"    header = True,\r\n",
							"    timestampFormat = \"yyyy-MM-dd\")\r\n",
							"\r\n",
							"logs.printSchema()\r\n",
							"\r\n",
							"#logs.show()"
						],
						"outputs": [],
						"execution_count": 44
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Basic operations"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#select\r\n",
							"logs.select(\"BroadcastLogID\", \"LogServiceID\", \"LogDate\").show(5)\r\n",
							"\r\n",
							"logs.select([\"BroadCastLogID\", \"LogServiceID\", \"LogDate\"]).show(5)\r\n",
							"\r\n",
							"logs.select(F.col(\"BroadCastLogID\"), F.col(\"LogServiceID\"), F.col(\"LogDate\")).show(5)"
						],
						"outputs": [],
						"execution_count": 45
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Peeking at the data frame in chunks of three columns"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import numpy as np\r\n",
							"\r\n",
							"column_split = np.array_split(\r\n",
							"    np.array(logs.columns), len(logs.columns) // 3 #// means integer division\r\n",
							")  \r\n",
							" \r\n",
							"print(column_split)\r\n",
							"\r\n",
							"for x in column_split:\r\n",
							"    logs.select(*x).show(5) #asterix explodes array into list of values\r\n",
							"    #print(*x)\r\n",
							"    #print(x)\r\n",
							"\r\n",
							""
						],
						"outputs": [],
						"execution_count": 46
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Show data frame in table format"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"display(logs.take(10))"
						],
						"outputs": [],
						"execution_count": 47
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Remove columns from dataframe"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"display(logs.drop(\"BroadCastLogID\", \"LogServiceID\").take(10))\r\n",
							"\r\n",
							"#Check if column is a part of data frame\r\n",
							"print(\"BroadCastLogID\" in logs.columns)\r\n",
							"\r\n",
							"#same with select (loop on columns array)\r\n",
							"display(logs.select([x for x in logs.columns if x not in [\"BroadcastLogID\", \"LogServiceID\"]]).take(5))"
						],
						"outputs": [],
						"execution_count": 48
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Exercise 4.1\r\n",
							"Lets take the following file, called sample.csv, which contains three columns:\r\n",
							"\r\n",
							"Item,Quantity,Price\r\n",
							"$Banana, organic$,1,0.99\r\n",
							"Pear,7,1.24\r\n",
							"$Cake, chocolate$,1,14.50\r\n",
							"Complete the following code to ingest the file successfully.\r\n",
							"\r\n",
							"sample = spark.read.csv([...],\r\n",
							"                        sep=[...],\r\n",
							"                        header=[...],\r\n",
							"                        quote=[...],\r\n",
							"                        inferSchema=[...]\r\n",
							")\r\n",
							"(Note: If you want to test your code, sample.csv is available in the books repository under data/sample.csv/sample.csv). "
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Root path var\r\n",
							"adls_path = \"abfss://learning@ivsdatastorage.dfs.core.windows.net/DataAnalysisPythonPySpark\"\r\n",
							"\r\n",
							"df_grocery_list = spark.read.csv(\r\n",
							"    path=adls_path+\"/data/sample/sample.csv\",\r\n",
							"    sep=\",\", \r\n",
							"    header=True, \r\n",
							"    quote=\"$\", \r\n",
							"    inferSchema=True)\r\n",
							"\r\n",
							"df_grocery_list.printSchema()"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Add calculated columns"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"logs.select(F.col(\"Duration\")).show(5)\r\n",
							"\r\n",
							"#Extract time components\r\n",
							"logs.select(\r\n",
							"    F.col(\"Duration\"),\r\n",
							"    F.col(\"Duration\").substr(1,2).cast(\"int\").alias(\"dur_hours\"),\r\n",
							"    F.col(\"Duration\").substr(4,2).cast(\"int\").alias(\"dur_minutes\"),\r\n",
							"    F.col(\"Duration\").substr(7,2).cast(\"int\").alias(\"dur_seconds\")\r\n",
							").distinct().show(5)\r\n",
							"\r\n",
							"#Calculate duration in seconds\r\n",
							"logs.select(\r\n",
							"    F.col(\"Duration\"),\r\n",
							"    (\r\n",
							"        F.col(\"Duration\").substr(1,2).cast(\"int\") * 3600 +\r\n",
							"        F.col(\"Duration\").substr(4,2).cast(\"int\") * 60 +\r\n",
							"        F.col(\"Duration\").substr(7,2).cast(\"int\")\r\n",
							"    ).alias(\"dur_seconds\")\r\n",
							").distinct().show(5)\r\n",
							"\r\n",
							"#Adding calculation as a new column into data frame\r\n",
							"logs = logs.withColumn(\r\n",
							"    \"Duration_seconds\",\r\n",
							"    F.col(\"Duration\").substr(1,2).cast(\"int\") * 3600 +\r\n",
							"    F.col(\"Duration\").substr(4,2).cast(\"int\") * 60 +\r\n",
							"    F.col(\"Duration\").substr(7,2).cast(\"int\")\r\n",
							")\r\n",
							"\r\n",
							"#Rename column\r\n",
							"logs = logs.withColumnRenamed(\"Duration_seconds\", \"dur_sec\")\r\n",
							"\r\n",
							"#Lowercasing all columns (toDF creates new dataframe from another)\r\n",
							"logs = logs.toDF(*[x.lower() for x in logs.columns]) #asterisk converts array into list of values (doesn't work without that)\r\n",
							"\r\n",
							"#Sorting columns\r\n",
							"logs = logs.select(sorted(logs.columns, reverse = True))\r\n",
							"\r\n",
							"logs.printSchema()"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Data profiling"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#for i in logs.columns:\r\n",
							"    #logs.describe(i).show(truncate = False)\r\n",
							"\r\n",
							"\r\n",
							"for i in logs.columns:\r\n",
							"    logs.select(i).summary().show() #stats can be defined as list of columns within summary() statement"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Exercise 4.3\r\n",
							"Reread the data in a logs_raw data frame (the data file is ./data/broadcast_logsBroadcastLogs_2018_Q3_M8.CSV), this time without passing any optional parameters. Print the first five rows of data, as well as the schema. What are the differences in terms of data and schema between logs and logs_raw?"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Root path var\r\n",
							"adls_path = \"abfss://learning@ivsdatastorage.dfs.core.windows.net/DataAnalysisPythonPySpark\"\r\n",
							"\r\n",
							"#Parse csv to data frame\r\n",
							"logs_raw = spark.read.csv(\r\n",
							"    path = adls_path + \"/data/broadcast_logs/BroadcastLogs_2018_Q3_M8_sample.CSV\")\r\n",
							"\r\n",
							"logs_raw.printSchema()\r\n",
							"\r\n",
							"logs_raw.show(5, 500)"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Exercise 4.4\r\n",
							"Create a new data frame, logs_clean, that contains only the columns that do not end with ID."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"logs_clean = logs.select(*[x for x in logs.columns if x[-2:] != \"ID\"])\r\n",
							"\r\n",
							"display(logs_clean.take(10))"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Join operation"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"log_identifier=spark.read.csv(\r\n",
							"    path=adls_path + \"/data/broadcast_logs/ReferenceTables/LogIdentifier.csv\",\r\n",
							"    sep=\"|\",\r\n",
							"    inferSchema=True,\r\n",
							"    header=True\r\n",
							")\r\n",
							"\r\n",
							"log_identifier.printSchema()\r\n",
							"\r\n",
							"#log_identifier.show(5)\r\n",
							"\r\n",
							"#verbose\r\n",
							"#logs.join(\r\n",
							"#    log_identifier,\r\n",
							"#    on=(logs[\"LogServiceID\"] == log_identifier[\"LogServiceID\"]) & (log_identifier[\"PrimaryFG\"] == 1)\r\n",
							"#    how=\"inner\"\r\n",
							"#)\r\n",
							"\r\n",
							"#compact version if column match and inner join (default)\r\n",
							"logs.join(\r\n",
							"    log_identifier,\r\n",
							"    on=\"LogServiceID\"\r\n",
							")\r\n",
							"\r\n",
							"#remove duplicated column from data frame (1)\r\n",
							"logs.join(\r\n",
							"    log_identifier,\r\n",
							"    logs[\"LogServiceID\"] == log_identifier[\"LogServiceID\"]\r\n",
							").drop(log_identifier[\"LogServiceID\"]).printSchema()\r\n",
							"\r\n",
							"#remove duplicated column from data frame (2), works only with F.col in second expression\r\n",
							"logs_and_channels = logs.alias(\"left\").join(\r\n",
							"    log_identifier.alias(\"right\"),\r\n",
							"    logs[\"LogServiceID\"] == log_identifier[\"LogServiceID\"]\r\n",
							")\r\n",
							"\r\n",
							"logs_and_channels.drop(F.col(\"right.LogServiceID\")).printSchema()  \r\n",
							"\r\n",
							"#adding two more reference sources:\r\n",
							"cd_category=spark.read.csv(\r\n",
							"    path=adls_path + \"/data/broadcast_logs/ReferenceTables/CD_Category.csv\",\r\n",
							"    sep=\"|\",\r\n",
							"    inferSchema=True,\r\n",
							"    header=True\r\n",
							")\r\n",
							"\r\n",
							"cd_program_class=spark.read.csv(\r\n",
							"    path=adls_path + \"/data/broadcast_logs/ReferenceTables/CD_ProgramClass.csv\",\r\n",
							"    sep=\"|\",\r\n",
							"    inferSchema=True,\r\n",
							"    header=True\r\n",
							")\r\n",
							"\r\n",
							"full_log = logs_and_channels.join(cd_category, \"CategoryID\", \"left\").join(\r\n",
							"    cd_program_class, how=\"left\", on=\"ProgramClassID\")\r\n",
							"\r\n",
							"full_log.show(5)"
						],
						"outputs": [],
						"execution_count": 59
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/CosmosNotebook')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "ivsspark",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "52687ac9-815a-4bf5-b2ac-0723f52bed46"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/f939f8f3-2652-4a45-88ae-78a7782ec9df/resourceGroups/ivs-dwh-rg/providers/Microsoft.Synapse/workspaces/ivs-synapse/bigDataPools/ivsspark",
						"name": "ivsspark",
						"type": "Spark",
						"endpoint": "https://ivs-synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/ivsspark",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.1",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"collapsed": false
						},
						"source": [
							"# Read from Cosmos DB analytical store into a Spark DataFrame and display 10 rows from the DataFrame\n",
							"# To select a preferred list of regions in a multi-region Cosmos DB account, add .option(\"spark.cosmos.preferredRegions\", \"<Region1>,<Region2>\")\n",
							"\n",
							"df = spark.read\\\n",
							"    .format(\"cosmos.olap\")\\\n",
							"    .option(\"spark.synapse.linkedService\", \"AdventureWorksSQL\")\\\n",
							"    .option(\"spark.cosmos.container\", \"Sales\")\\\n",
							"    .load()\n",
							"\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 1
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DP203Certification')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "ivsspark",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "7884fb01-59e9-4b88-99bd-1ea2b5386fc1"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/f939f8f3-2652-4a45-88ae-78a7782ec9df/resourceGroups/ivs-dwh-rg/providers/Microsoft.Synapse/workspaces/ivs-synapse/bigDataPools/ivsspark",
						"name": "ivsspark",
						"type": "Spark",
						"endpoint": "https://ivs-synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/ivsspark",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.1",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"df = spark.read.load('abfss://spark@ivsdatastorage.dfs.core.windows.net/products.csv',\r\n",
							"    format='csv',\r\n",
							"    header=True\r\n",
							")\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"from pyspark.sql.types import *\r\n",
							"from pyspark.sql.functions import *\r\n",
							"\r\n",
							"productSchema = StructType([\r\n",
							"    StructField(\"ProductID\", IntegerType()),\r\n",
							"    StructField(\"ProductName\", StringType()),\r\n",
							"    StructField(\"Category\", StringType()),\r\n",
							"    StructField(\"ListPrice\", FloatType())\r\n",
							"    ])\r\n",
							"\r\n",
							"df = spark.read.load('abfss://spark@ivsdatastorage.dfs.core.windows.net/products.csv',\r\n",
							"    format='csv',\r\n",
							"    schema=productSchema,\r\n",
							"    header=False)\r\n",
							"\r\n",
							"df.createOrReplaceTempView(\"products\")\r\n",
							"\r\n",
							""
						],
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"\r\n",
							"SELECT Category, COUNT(ProductID) AS ProductCount\r\n",
							"FROM products\r\n",
							"GROUP BY Category\r\n",
							"ORDER BY Category"
						],
						"outputs": [],
						"execution_count": 12
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DimAllTime')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "ivsspark",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "f03486a3-4e98-4a92-bbaa-56b5d40e9192"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/f939f8f3-2652-4a45-88ae-78a7782ec9df/resourceGroups/ivs-dwh-rg/providers/Microsoft.Synapse/workspaces/ivs-synapse/bigDataPools/ivsspark",
						"name": "ivsspark",
						"type": "Spark",
						"endpoint": "https://ivs-synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/ivsspark",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.1",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Read csvs and create temp views"
						]
					},
					{
						"cell_type": "code",
						"source": [
							"fiscal_year = spark.read.csv('abfss://spark@ivsdatastorage.dfs.core.windows.net/source/FiscalYear.csv', \r\n",
							"    header = True)\r\n",
							"\r\n",
							"fiscal_year.createOrReplaceTempView('fy_view')\r\n",
							"\r\n",
							"fiscal_period = spark.read.csv('abfss://spark@ivsdatastorage.dfs.core.windows.net/source/FiscalPeriod.csv', \r\n",
							"    header = True)\r\n",
							"\r\n",
							"fiscal_period.createOrReplaceTempView('fp_view')\r\n",
							""
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Create merged dataframe from temporary views"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"df_stg = spark.sql(\"SELECT concat(CALENDAR, ',YEAR,', FISCALYEAR) DIM_ALL_TIME_ID, \" +\r\n",
							"    \"'YEAR' GRAIN_LEVEL, \"+\r\n",
							"    \"CALENDAR, \" +\r\n",
							"    \"FISCALYEAR, \" +\r\n",
							"    \"CAST(STARTDATE as timestamp) STARTDATE, \" +\r\n",
							"    \"CAST(ENDDATE as timestamp) ENDDATE, \" +\r\n",
							"    \"NULL CALENDARTYPE, \" +\r\n",
							"    \"NULL QUARTER, \" +\r\n",
							"    \"NULL MONTH, \" +\r\n",
							"    \"NULL PERIODNAME, \" +\r\n",
							"    \"NULL SHORTNAME, \" +\r\n",
							"    \"NULL TYPE, \" +\r\n",
							"    \"NULL DAYS, \" +\r\n",
							"    \"NULL PERIODNUMBER \" +\r\n",
							"    \"FROM fy_view \" +\r\n",
							"    \"UNION \" +\r\n",
							"    \"SELECT concat(CALENDAR, ',PERIOD,', FISCALYEAR, ',', replace(PERIODNAME, 'Period ', '')) DIM_ALL_TIME_ID, \" +\r\n",
							"    \"'PERIOD' GRAIN_LEVEL, \" +\r\n",
							"    \"CALENDAR, \" +\r\n",
							"    \"FISCALYEAR, \" +\r\n",
							"    \"CAST(STARTDATE as timestamp) STARTDATE, \" +\r\n",
							"    \"CAST(ENDDATE as timestamp) ENDDATE, \" +\r\n",
							"    \"CALENDARTYPE, \" +\r\n",
							"    \"QUARTER, \" +\r\n",
							"    \"MONTH, \" +\r\n",
							"    \"PERIODNAME, \" +\r\n",
							"    \"SHORTNAME, \" +\r\n",
							"    \"TYPE, \" +\r\n",
							"    \"DAYS, \" +\r\n",
							"    \"cast(replace(PERIODNAME, 'Period ', '') as int) PERIODNUMBER \" +\r\n",
							"    \"FROM fp_view \" +\r\n",
							"    \"WHERE TYPE = 1\")\r\n",
							"\r\n",
							"df_stg.show()"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Add gregorian years and months"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"from pyspark.sql.functions import lit\r\n",
							"\r\n",
							"df_stg = df_stg.select(['DIM_ALL_TIME_ID','GRAIN_LEVEL','CALENDAR','FISCALYEAR','STARTDATE','ENDDATE',\r\n",
							"    'CALENDARTYPE','QUARTER','MONTH','PERIODNAME','SHORTNAME','TYPE','DAYS','PERIODNUMBER', \r\n",
							"    lit(None).cast('integer').alias('CALYEAR'), \r\n",
							"    lit(None).cast('string').alias('CALMONTH'), \r\n",
							"    lit(None).cast('integer').alias('CALMONTH_NUM'), \r\n",
							"    lit(None).cast('integer').alias('CLOSEDMONTH')])\r\n",
							"\r\n",
							"from datetime import date\r\n",
							"from calendar import monthrange\r\n",
							"\r\n",
							"for row in df_stg.where(\"CALENDAR = 'Fiscal' and GRAIN_LEVEL = 'YEAR'\").collect():\r\n",
							"    newrow = spark.createDataFrame([('Gegorian,YEAR,' + row['FISCALYEAR'], 'YEAR', 'Gregorian', row['FISCALYEAR'], row['FISCALYEAR'] + '-01-01', row['FISCALYEAR'] + '-12-31')],\r\n",
							"        ['DIM_ALL_TIME_ID', 'GRAIN_LEVEL', 'CALENDAR', 'CALYEAR', 'STARTDATE', 'ENDDATE'])\r\n",
							"    df_stg = df_stg.unionByName(newrow, allowMissingColumns=True)\r\n",
							"    for i in range(1, 13):\r\n",
							"        newrow = spark.createDataFrame([('Gegorian,MONTH,' + row['FISCALYEAR'] + f'{i:02}', 'MONTH', 'Gregorian', \r\n",
							"            row['FISCALYEAR'], row['FISCALYEAR'] + '-' + f'{i:02}' + '-01', \r\n",
							"            row['FISCALYEAR'] + '-' + f'{i:02}' + '-' + str(monthrange(int(row['FISCALYEAR']), i)[1]),\r\n",
							"            f'{i:02}', i, \r\n",
							"            1 if row['FISCALYEAR'] + '-' + f'{i:02}' + '-' + str(monthrange(int(row['FISCALYEAR']), i)[1]) < str(date.today()) else 0)],\r\n",
							"            ['DIM_ALL_TIME_ID', 'GRAIN_LEVEL', 'CALENDAR', 'CALYEAR', 'STARTDATE', 'ENDDATE', 'CALMONTH', 'CALMONTH_NUM', 'CLOSEDMONTH'])\r\n",
							"        df_stg = df_stg.unionByName(newrow, allowMissingColumns=True)\r\n",
							"\r\n",
							"\r\n",
							"df_stg.where(\"CALENDAR = 'Gregorian' and CALYEAR = 2021\").show()"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Weeks"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"from datetime import datetime, timedelta\r\n",
							"\r\n",
							"df_stg = df_stg.select(['DIM_ALL_TIME_ID','GRAIN_LEVEL','CALENDAR','FISCALYEAR','STARTDATE','ENDDATE',\r\n",
							"    'CALENDARTYPE','QUARTER','MONTH','PERIODNAME','SHORTNAME','TYPE','DAYS','PERIODNUMBER',\r\n",
							"    'CALYEAR','CALMONTH','CALMONTH_NUM','CLOSEDMONTH',\r\n",
							"    lit(None).cast('integer').alias('YEAR_WEEK_IN'),\r\n",
							"    lit(None).cast('integer').alias('WEEK_STARTDATE'),\r\n",
							"    lit(None).cast('integer').alias('WEEK_ENDTDATE'),\r\n",
							"    lit(None).cast('integer').alias('PERIOD_STARTDATE'),\r\n",
							"    lit(None).cast('integer').alias('PERIOD_ENDDATE'),\r\n",
							"    lit(None).cast('integer').alias('YEAR_STARTDATE'),\r\n",
							"    lit(None).cast('integer').alias('YEAR_ENDDATE')])\r\n",
							"\r\n",
							"for row in df_stg.where(\"CALENDAR = 'Fiscal' and GRAIN_LEVEL = 'PERIOD'\").orderBy([\"FISCALYEAR\", \"PERIODNUMBER\"]).collect():\r\n",
							"    yearRow = []\r\n",
							"    weekNum = (row['PERIODNUMBER'] - 1) * 4\r\n",
							"    for i in range(0, int((datetime.strptime(row['ENDDATE'], '%Y-%m-%d %H:%M:%S') - datetime.strptime(row['STARTDATE'], '%Y-%m-%d %H:%M:%S')).days/7)):\r\n",
							"        weekStart = datetime.strptime(row['STARTDATE'], '%Y-%m-%d %H:%M:%S') + timedelta(days = 7*i)\r\n",
							"        weekNum = weekNum + 1\r\n",
							"        weekRow = ['Fiscal,WEEK,' + str(row['FISCALYEAR']) + ',' + str(weekNum), \r\n",
							"            'WEEK', row['CALENDAR'], row['FISCALYEAR'], row['PERIODNAME'],\r\n",
							"            weekStart, weekStart + timedelta(days = 6), row['PERIODNUMBER'],\r\n",
							"            row['QUARTER'], row['MONTH'], weekNum, weekStart, weekStart + timedelta(days = 6)]\r\n",
							"        yearRow.append(weekRow)\r\n",
							"    newYear = spark.createDataFrame(yearRow, ['DIM_ALL_TIME_ID', 'GRAIN_LEVEL', 'CALENDAR', 'FISCALYEAR', 'PERIODNAME', \r\n",
							"        'STARTDATE', 'ENDDATE', 'PERIODNUMBER', 'QUARTER', 'MONTH', 'YEAR_WEEK_IN'])\r\n",
							"    df_stg = df_stg.unionByName(newYear, allowMissingColumns=True)\r\n",
							"\r\n",
							"df_stg.createOrReplaceTempView('AllTimeStg')"
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Fiscal dates"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df_stg = df_stg.select(['DIM_ALL_TIME_ID','GRAIN_LEVEL','CALENDAR','FISCALYEAR','STARTDATE','ENDDATE',\r\n",
							"    'CALENDARTYPE','QUARTER','MONTH','PERIODNAME','SHORTNAME','TYPE','DAYS','PERIODNUMBER',\r\n",
							"    'CALYEAR','CALMONTH','CALMONTH_NUM','CLOSEDMONTH','YEAR_WEEK_IN',\r\n",
							"    lit(None).cast('date').alias('CALENDARDATE')])\r\n",
							"\r\n",
							"weekRow = []\r\n",
							"for row in df_stg.where(\"CALENDAR = 'Fiscal' and GRAIN_LEVEL = 'WEEK'\").collect():\r\n",
							"    for i in range(0, (datetime.strptime(row['ENDDATE'], '%Y-%m-%d %H:%M:%S') - datetime.strptime(row['STARTDATE'], '%Y-%m-%d %H:%M:%S')).days + 1):\r\n",
							"        calDay = datetime.strptime(row['STARTDATE'], '%Y-%m-%d %H:%M:%S') + timedelta(days = i)\r\n",
							"        dayRow = ['Fiscal,DAY,' + str(calDay.year) + f'{calDay.month:02}' + f'{calDay.day:02}', 'DAY', row['CALENDAR'], row['FISCALYEAR'], row['PERIODNAME'],\r\n",
							"            calDay, calDay, calDay, row['PERIODNUMBER'], row['QUARTER'], row['MONTH'], calDay.year, str(calDay.year) + f'{calDay.month:02}', calDay.month,\r\n",
							"            1 if date(calDay.year, calDay.month, monthrange(calDay.year, calDay.month)[1]) < date.today() else 0, row['YEAR_WEEK_IN']]\r\n",
							"        weekRow.append(dayRow)\r\n",
							"\r\n",
							"newWeek = spark.createDataFrame(weekRow, ['DIM_ALL_TIME_ID', 'GRAIN_LEVEL', 'CALENDAR', 'FISCALYEAR', 'PERIODNAME', 'CALENDARDATE', \r\n",
							"    'STARTDATE', 'ENDDATE', 'PERIODNUMBER', 'QUARTER', 'MONTH', 'CALYEAR', 'CALMONTH', 'CALMONTH_NUM', 'CLOSEDMONTH', 'YEAR_WEEK_IN'])\r\n",
							"\r\n",
							"df_stg = df_stg.unionByName(newWeek, allowMissingColumns=True)\r\n",
							"\r\n",
							"df_stg.createOrReplaceTempView('AllTimeStg')\r\n",
							"\r\n",
							"df_stg.where(\"CALENDAR = 'Fiscal' and GRAIN_LEVEL = 'DAY' and FISCALYEAR = 2021 and PERIODNAME = 'Period 1'\").show()\r\n",
							""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"select * from AllTimeStg\r\n",
							"where fiscalyear = 2019\r\n",
							"order by startdate\r\n",
							"limit 20\r\n",
							"\r\n",
							""
						],
						"outputs": [],
						"execution_count": 6
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Lake Database')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "ivsspark",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "7bbea90f-984d-46b3-ac0e-10b17a70747d"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/f939f8f3-2652-4a45-88ae-78a7782ec9df/resourceGroups/ivs-dwh-rg/providers/Microsoft.Synapse/workspaces/ivs-synapse/bigDataPools/ivsspark",
						"name": "ivsspark",
						"type": "Spark",
						"endpoint": "https://ivs-synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/ivsspark",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.1",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"INSERT INTO `ivs-synapse-dldb`.`Party` VALUES (1,'TestParty',1022,557);"
						],
						"outputs": [],
						"execution_count": 12
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"DESCRIBE Extended `ivs-synapse-dldb`.`Party`"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"CONVERT to delta `ivs-synapse-dldb`.`Party`\r\n",
							""
						],
						"outputs": [],
						"execution_count": 15
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"spark.sql(f\"\"\"\r\n",
							"CREATE TABLE Party_delta\r\n",
							"USING DELTA\r\n",
							"LOCATION \"abfss://synapse@ivsdatastorage.dfs.core.windows.net/ivs-synapse-dldb/Party\"\r\n",
							"\"\"\")"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"select * from Party_delta"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"ALTER TABLE Party_delta\r\n",
							"ADD COLUMNS (dte date)\r\n",
							""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"INSERT INTO Party_delta VALUES (2,'TestPartyInserted',9476,265,null);"
						],
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"UPDATE Party_delta SET dte = '2021-03-16'\r\n",
							"    where partyId = 1"
						],
						"outputs": [],
						"execution_count": 19
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"DELETE FROM Party_delta\r\n",
							"where partyid = 2"
						],
						"outputs": [],
						"execution_count": 14
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"DESCRIBE history Party_delta"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"DESCRIBE extended Party_delta"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"optimize Party_delta"
						],
						"outputs": [],
						"execution_count": 3
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Pride and Prejudice')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Data Analysis with Python and PySpark"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "ivsspark",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "445b3b83-887d-44c5-adad-7114bb43ab78"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/f939f8f3-2652-4a45-88ae-78a7782ec9df/resourceGroups/ivs-dwh-rg/providers/Microsoft.Synapse/workspaces/ivs-synapse/bigDataPools/ivsspark",
						"name": "ivsspark",
						"type": "Spark",
						"endpoint": "https://ivs-synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/ivsspark",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.1",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Activate eager evaluation (instead of lazy)"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#from pyspark.sql import SparkSession\r\n",
							" \r\n",
							"#spark = (SparkSession.builder\r\n",
							"#                     .config(\"spark.sql.repl.eagerEval.enabled\", \"True\")\r\n",
							"#                     .getOrCreate())"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Reading data into a data frame with spark.read"
						]
					},
					{
						"cell_type": "code",
						"source": [
							"#Root path var\r\n",
							"adls_path = \"abfss://learning@ivsdatastorage.dfs.core.windows.net/DataAnalysisPythonPySpark\"\r\n",
							"\r\n",
							"#Load text file to data frame\r\n",
							"book = spark.read.text(adls_path + \"/data/gutenberg_books/1342-0.txt\")\r\n",
							"\r\n",
							"book\r\n",
							"\r\n",
							""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Explore schema"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"book.printSchema()\r\n",
							"\r\n",
							"print(book.dtypes)\r\n",
							"\r\n",
							"#print(spark.__doc__)\r\n",
							"\r\n",
							"dir(book)"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Code assistance"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#General recommendations\r\n",
							"print(spark.__doc__)\r\n",
							"\r\n",
							"#Methods available for the object\r\n",
							"dir(book)\r\n",
							"\r\n",
							"#Documentation on the object\r\n",
							"book.__doc__"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Explore data"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#book.show()\r\n",
							"\r\n",
							"book.show(n=10, truncate=100, vertical=True)"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Splitting lines of text into arrays or words"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"from pyspark.sql.functions import split\r\n",
							"\r\n",
							"lines = book.select(split(book.value, ' ').alias('line'))\r\n",
							"\r\n",
							"#Alternative ways to select data:\r\n",
							"#book.select(book.value)\r\n",
							"#book.select(book[\"value\"])\r\n",
							"#book.select(col(\"value\"))\r\n",
							"#book.select(\"value\")\r\n",
							"\r\n",
							"#Alternative ways to alias data:\r\n",
							"# This looks a lot cleaner\r\n",
							"#lines = book.select(split(book.value, \" \").alias(\"line\"))\r\n",
							"# This is messier, and you have to remember the name PySpark assigns automatically\r\n",
							"#lines = book.select(split(book.value, \" \"))\r\n",
							"#lines = lines.withColumnRenamed(\"split(value, , -1)\", \"line\")\r\n",
							"\r\n",
							"lines.show(5, 100)\r\n",
							"\r\n",
							"lines.printSchema()\r\n",
							"\r\n",
							""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Exploding arrays into rows"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"from pyspark.sql.functions import explode\r\n",
							"\r\n",
							"words = lines.select(explode(lines.line).alias(\"word\"))\r\n",
							"\r\n",
							"words.show(30, 30)"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Cleansing data (lowering case, remove punctuation and empty words)"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"from pyspark.sql.functions import lower, regexp_extract\r\n",
							"\r\n",
							"words_lower = words.select(lower(words.word).alias('word_lower'))\r\n",
							"\r\n",
							"words_clean = words_lower.select(regexp_extract(words_lower.word_lower, \"[a-z]+\", 0).alias(\"word\"))\r\n",
							"\r\n",
							"words_not_null = words_clean.filter(words_clean.word != \"\")\r\n",
							"\r\n",
							"words_not_null.show(30,30)"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Exercise 2.2\r\n",
							"Given the following data frame, programmatically count the number of columns that arent strings (answer = only one column isnt a string).\r\n",
							"\r\n",
							"createDataFrame() allows you to create a data frame from a variety of sources, such as a pandas data frame or (in this case) a list of lists."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"exo2_2_df = spark.createDataFrame(\r\n",
							"    [[\"test\", \"more test\", 10_000_000_000]], [\"one\", \"two\", \"three\"]\r\n",
							")\r\n",
							" \r\n",
							"#exo2_2_df.printSchema()\r\n",
							"\r\n",
							"dfcolumns = spark.createDataFrame(exo2_2_df.dtypes, ['name', 'type'])\r\n",
							"\r\n",
							"dfcolumns_filtered = dfcolumns.filter(dfcolumns.type != 'string')\r\n",
							"\r\n",
							"print('Non-string columns number:')\r\n",
							"print(dfcolumns_filtered.count())\r\n",
							""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Exercise 2.3\r\n",
							"Rewrite the following code snippet, removing the withColumnRenamed method. Which version is clearer and easier to read?"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Root path var\r\n",
							"adls_path = \"abfss://learning@ivsdatastorage.dfs.core.windows.net/DataAnalysisPythonPySpark\"\r\n",
							"\r\n",
							"from pyspark.sql.functions import col, length\r\n",
							" \r\n",
							"# The `length` function returns the number of characters in a string column.\r\n",
							" \r\n",
							"exo2_3_df = (\r\n",
							"    spark.read.text(adls_path + \"/data/gutenberg_books/1342-0.txt\")\r\n",
							"    .select(length(col(\"value\")))\r\n",
							"    .withColumnRenamed(\"length(value)\", \"number_of_char\")\r\n",
							")\r\n",
							"\r\n",
							"exo2_3_df.show()\r\n",
							"\r\n",
							"#Version with .withColumnRenamed easier to read"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Exercise 2.4\r\n",
							"Assume a data frame exo2_4_df. The following code block gives an error. What is the problem, and how can you solve it?"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"from pyspark.sql.functions import col, greatest\r\n",
							" \r\n",
							"exo2_4_df = spark.createDataFrame(\r\n",
							"    [[\"key\", 10_000, 20_000]], [\"key\", \"value1\", \"value2\"]\r\n",
							")\r\n",
							" \r\n",
							"exo2_4_df.printSchema()\r\n",
							"# root\r\n",
							"#  |-- key: string (containsNull = true)\r\n",
							"#  |-- value1: long (containsNull = true)\r\n",
							"#  |-- value2: long (containsNull = true)\r\n",
							" \r\n",
							"# `greatest` will return the greatest value of the list of column names,\r\n",
							"# skipping null value\r\n",
							" \r\n",
							"# The following statement will return an error\r\n",
							"from pyspark.sql.utils import AnalysisException\r\n",
							" \r\n",
							"try:\r\n",
							"    exo2_4_mod = exo2_4_df.select(\r\n",
							"        greatest(col(\"value1\"), col(\"value2\")).alias(\"maximum_value\")\r\n",
							"    ).select(\"key\", \"max_value\")\r\n",
							"except AnalysisException as err:\r\n",
							"    print(err)\r\n",
							"\r\n",
							"#modified code\r\n",
							"exo2_4_df.select(col(\"key\"),\r\n",
							"        greatest(col(\"value1\"), col(\"value2\")).alias(\"maximum_value\")\r\n",
							"    ).select(\"key\", \"maximum_value\").show()"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Exercise 2.5\r\n",
							"Lets take our words_nonull data frame, available in the next listing. You can use the code from the repository (code/Ch02/end_of_chapter.py) in your REPL to get the data frame loaded.\r\n",
							"\r\n",
							"a) Remove all of the occurrences of the word is.\r\n",
							"\r\n",
							"b) (Challenge) Using the length function, keep only the words with more than three characters."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#words_not_null.show()\r\n",
							"\r\n",
							"#a\r\n",
							"words_no_is = words_not_null.filter(col(\"word\") != 'is')\r\n",
							"\r\n",
							"#words_no_is.show()\r\n",
							"\r\n",
							"#b\r\n",
							"words_longer_than_3 = (words_not_null.select(col(\"word\"), length(col(\"word\")).alias(\"word_length\"))\r\n",
							"    .filter(col(\"word_length\") > 3)\r\n",
							"    .select(\"word\")\r\n",
							")\r\n",
							"\r\n",
							"#words_longer_than_3.show()"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"The where clause takes a Boolean expression over one or many columns to filter the data frame. Beyond the usual Boolean operators (>, <, ==, <=, >=, !=), PySpark provides other functions that return Boolean columns in the pyspark.sql.functions module.\r\n",
							"\r\n",
							"A good example is the isin() method (applied on a Column object, like col(...).isin(...)), which takes a list of values as a parameter, and will return only the records where the value in the column equals a member of the list.\r\n",
							"\r\n",
							"Lets say you want to remove the words is, not, the and if from your list of words, using a single where() method on the words_nonull data frame. Write the code to do so."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"no_short_words = words_not_null.where(~col(\"word\").isin(\"is\", \"not\", \"the\"))\r\n",
							"\r\n",
							"#no_short_words = words_not_null.where(col(\"word\").isin(\"is\", \"not\", \"the\") == False)\r\n",
							"\r\n",
							"no_short_words.show()"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Exercise 2.7\r\n",
							"One of your friends comes to you with the following code. They have no idea why it doesnt work. Can you diagnose the problem in the try block, explain why it is an error, and provide a fix?"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"from pyspark.sql.functions import col, split\r\n",
							"\r\n",
							"#Root path var\r\n",
							"adls_path = \"abfss://learning@ivsdatastorage.dfs.core.windows.net/DataAnalysisPythonPySpark\"\r\n",
							" \r\n",
							"try:\r\n",
							"    book = spark.read.text(adls_path + \"/data/gutenberg_books/1342-0.txt\")\r\n",
							"    book = book.printSchema()\r\n",
							"    lines = book.select(split(book.value, \" \").alias(\"line\"))\r\n",
							"    words = lines.select(explode(col(\"line\")).alias(\"word\"))\r\n",
							"except AnalysisException as err:\r\n",
							"    print(err)\r\n",
							"\r\n",
							"\r\n",
							"#fix:\r\n",
							"try:\r\n",
							"    book = spark.read.text(adls_path + \"/data/gutenberg_books/1342-0.txt\")\r\n",
							"#    book = book.printSchema()\r\n",
							"    lines = book.select(split(book.value, \" \").alias(\"line\"))\r\n",
							"    words = lines.select(explode(col(\"line\")).alias(\"word\"))\r\n",
							"except AnalysisException as err:\r\n",
							"    print(err)\r\n",
							""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Book wording analysis continuation"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"groups = words_not_null.groupby(col(\"word\"))\r\n",
							"\r\n",
							"print(groups)\r\n",
							"\r\n",
							"result = words_not_null.groupby(col(\"word\")).count()\r\n",
							"\r\n",
							"result.show()"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Exercise 3.1\r\n",
							"\r\n",
							"Starting with the words_not_null seen in this section, which of the following expressions would return the number of words per letter count (e.g., there are X one-letter words, Y two-letter words, etc.)?\r\n",
							"\r\n",
							"Assume that pyspark.sql.functions.col, pyspark.sql.functions.length are imported.\r\n",
							"\r\n",
							"a) words_not_null.select(length(col(\"word\"))).groupby(\"length\").count()\r\n",
							"\r\n",
							"b) words_not_null.select(length(col(\"word\")).alias(\"length\")).groupby(\"length\").count()\r\n",
							"\r\n",
							"c) words_not_null.groupby(\"length\").select(\"length\").count()\r\n",
							"\r\n",
							"d) None of those options would work."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"words_not_null.select(length(col(\"word\")).alias(\"length\")).groupby(\"length\").count().show()"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Book wording analysis continuation"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"result = words_not_null.groupby(col(\"word\")).count().orderBy(col(\"count\"), ascending = False)\r\n",
							"\r\n",
							"#Root path var\r\n",
							"adls_path = \"abfss://learning@ivsdatastorage.dfs.core.windows.net/DataAnalysisPythonPySpark\"\r\n",
							"\r\n",
							"result.write.csv(adls_path + \"/output/Pride and Prejudice/partitioned\")\r\n",
							"\r\n",
							"result.coalesce(1).write.csv(adls_path + \"/output/Pride and Prejudice/single file\")"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Simplifying code"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import pyspark.sql.functions as F\r\n",
							"\r\n",
							"#Root path var\r\n",
							"adls_path = \"abfss://learning@ivsdatastorage.dfs.core.windows.net/DataAnalysisPythonPySpark\"\r\n",
							" \r\n",
							"results = (\r\n",
							"    spark.read.text(adls_path + \"/data/gutenberg_books/1342-0.txt\")\r\n",
							"    .select(F.split(F.col(\"value\"), \" \").alias(\"line\"))\r\n",
							"    .select(F.explode(F.col(\"line\")).alias(\"word\"))\r\n",
							"    .select(F.lower(F.col(\"word\")).alias(\"word\"))\r\n",
							"    .select(F.regexp_extract(F.col(\"word\"), \"[a-z']*\", 0).alias(\"word\"))\r\n",
							"    .where(F.col(\"word\") != \"\")\r\n",
							"    .groupby(\"word\")\r\n",
							"    .count()\r\n",
							"    .orderBy(F.col(\"count\"), ascending = False)\r\n",
							")\r\n",
							"\r\n",
							"results.show()"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Processing more books"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import pyspark.sql.functions as F\r\n",
							"\r\n",
							"#Root path var\r\n",
							"adls_path = \"abfss://learning@ivsdatastorage.dfs.core.windows.net/DataAnalysisPythonPySpark\"\r\n",
							" \r\n",
							"results = (\r\n",
							"    spark.read.text(adls_path + \"/data/gutenberg_books/*.txt\")\r\n",
							"    .select(F.split(F.col(\"value\"), \" \").alias(\"line\"))\r\n",
							"    .select(F.explode(F.col(\"line\")).alias(\"word\"))\r\n",
							"    .select(F.lower(F.col(\"word\")).alias(\"word\"))\r\n",
							"    .select(F.regexp_extract(F.col(\"word\"), \"[a-z']*\", 0).alias(\"word\"))\r\n",
							"    .where(F.col(\"word\") != \"\")\r\n",
							"    .groupby(\"word\")\r\n",
							"    .count()\r\n",
							"    .orderBy(F.col(\"count\"), ascending = False)\r\n",
							")\r\n",
							"\r\n",
							"results.show()"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Exercise 3.3\r\n",
							"By modifying the word_count_submit.py program, return the number of distinct words in Jane Austens Pride and Prejudice. (Hint: results contains one record for each unique word.)\r\n",
							"\r\n",
							"(Challenge) Wrap your program in a function that takes a file name as a parameter. It should return the number of distinct words."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import pyspark.sql.functions as F\r\n",
							"\r\n",
							"#Root path var\r\n",
							"adls_path = \"abfss://learning@ivsdatastorage.dfs.core.windows.net/DataAnalysisPythonPySpark\"\r\n",
							" \r\n",
							"result = (\r\n",
							"    spark.read.text(adls_path + \"/data/gutenberg_books/1342-0.txt\")\r\n",
							"    .select(F.split(F.col(\"value\"), \" \").alias(\"line\"))\r\n",
							"    .select(F.explode(F.col(\"line\")).alias(\"word\"))\r\n",
							"    .select(F.lower(F.col(\"word\")).alias(\"word\"))\r\n",
							"    .select(F.regexp_extract(F.col(\"word\"), \"[a-z']*\", 0).alias(\"word\"))\r\n",
							"    .where(F.col(\"word\") != \"\")\r\n",
							"    .select(F.col(\"word\"))\r\n",
							"    .distinct()\r\n",
							"    .count()\r\n",
							")\r\n",
							"\r\n",
							"print(result)\r\n",
							"\r\n",
							"def bookDistCount(fName):\r\n",
							"    #Root path var\r\n",
							"    adls_path = \"abfss://learning@ivsdatastorage.dfs.core.windows.net/DataAnalysisPythonPySpark\"\r\n",
							"    \r\n",
							"    result = (\r\n",
							"        spark.read.text(adls_path + \"/data/gutenberg_books/\" + fName)\r\n",
							"        .select(F.split(F.col(\"value\"), \" \").alias(\"line\"))\r\n",
							"        .select(F.explode(F.col(\"line\")).alias(\"word\"))\r\n",
							"        .select(F.lower(F.col(\"word\")).alias(\"word\"))\r\n",
							"        .select(F.regexp_extract(F.col(\"word\"), \"[a-z']*\", 0).alias(\"word\"))\r\n",
							"        .where(F.col(\"word\") != \"\")\r\n",
							"        .select(F.col(\"word\"))\r\n",
							"        .distinct()\r\n",
							"        .count()\r\n",
							"    )\r\n",
							"\r\n",
							"    return result\r\n",
							"\r\n",
							"\r\n",
							"print(bookDistCount(\"1661-0.txt\"))"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Exercise 3.4\r\n",
							"Taking word_count_submit.py, modify the script to return a sample of five words that appear only once in Jane Austens Pride and Prejudice."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Root path var\r\n",
							"adls_path = \"abfss://learning@ivsdatastorage.dfs.core.windows.net/DataAnalysisPythonPySpark\"\r\n",
							" \r\n",
							"results = (\r\n",
							"    spark.read.text(adls_path + \"/data/gutenberg_books/1342-0.txt\")\r\n",
							"    .select(F.split(F.col(\"value\"), \" \").alias(\"line\"))\r\n",
							"    .select(F.explode(F.col(\"line\")).alias(\"word\"))\r\n",
							"    .select(F.lower(F.col(\"word\")).alias(\"word\"))\r\n",
							"    .select(F.regexp_extract(F.col(\"word\"), \"[a-z']*\", 0).alias(\"word\"))\r\n",
							"    .where(F.col(\"word\") != \"\")\r\n",
							"    .groupby(\"word\")\r\n",
							"    .count()\r\n",
							"    .where(F.col(\"count\") == 1)\r\n",
							")\r\n",
							"\r\n",
							"results.show(5)"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Exercise 3.5\r\n",
							"Using the substring function (refer to PySparks API or the pyspark shell if needed), return the top five most popular first letters (keep only the first letter of each word).\r\n",
							"\r\n",
							"Compute the number of words starting with a consonant or a vowel. (Hint: The isin() function might be useful.)"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"adls_path = \"abfss://learning@ivsdatastorage.dfs.core.windows.net/DataAnalysisPythonPySpark\"\r\n",
							" \r\n",
							"results = (\r\n",
							"    spark.read.text(adls_path + \"/data/gutenberg_books/1342-0.txt\")\r\n",
							"    .select(F.split(F.col(\"value\"), \" \").alias(\"line\"))\r\n",
							"    .select(F.explode(F.col(\"line\")).alias(\"word\"))\r\n",
							"    .select(F.lower(F.col(\"word\")).alias(\"word\"))\r\n",
							"    .select(F.regexp_extract(F.col(\"word\"), \"[a-z']*\", 0).alias(\"word\"))\r\n",
							"    .where(F.col(\"word\") != \"\")\r\n",
							"    .groupby(F.substring(F.col(\"word\"), 1, 1).alias(\"firstLetter\"))\r\n",
							"    .count()\r\n",
							"    .orderBy(F.col(\"count\"), ascending = False)\r\n",
							")\r\n",
							"\r\n",
							"results.show(5)\r\n",
							"\r\n",
							"results_vowels = (\r\n",
							"    spark.read.text(adls_path + \"/data/gutenberg_books/1342-0.txt\")\r\n",
							"    .select(F.split(F.col(\"value\"), \" \").alias(\"line\"))\r\n",
							"    .select(F.explode(F.col(\"line\")).alias(\"word\"))\r\n",
							"    .select(F.lower(F.col(\"word\")).alias(\"word\"))\r\n",
							"    .select(F.regexp_extract(F.col(\"word\"), \"[a-z']*\", 0).alias(\"word\"))\r\n",
							"    .where(F.col(\"word\") != \"\")\r\n",
							"    .groupby(F.substring(F.col(\"word\"), 1, 1).alias(\"firstLetter\"))\r\n",
							"    .count()\r\n",
							"    .where(F.col(\"firstLetter\").isin(['a','e','i','o','u','y']))\r\n",
							"    .orderBy(F.col(\"count\"), ascending = False)\r\n",
							")\r\n",
							"\r\n",
							"results_vowels.show(5)\r\n",
							"\r\n",
							"results_consonants = (\r\n",
							"    spark.read.text(adls_path + \"/data/gutenberg_books/1342-0.txt\")\r\n",
							"    .select(F.split(F.col(\"value\"), \" \").alias(\"line\"))\r\n",
							"    .select(F.explode(F.col(\"line\")).alias(\"word\"))\r\n",
							"    .select(F.lower(F.col(\"word\")).alias(\"word\"))\r\n",
							"    .select(F.regexp_extract(F.col(\"word\"), \"[a-z']*\", 0).alias(\"word\"))\r\n",
							"    .where(F.col(\"word\") != \"\")\r\n",
							"    .groupby(F.substring(F.col(\"word\"), 1, 1).alias(\"firstLetter\"))\r\n",
							"    .count()\r\n",
							"    .where(~F.col(\"firstLetter\").isin(['a','e','i','o','u','y']))\r\n",
							"    .orderBy(F.col(\"count\"), ascending = False)\r\n",
							")\r\n",
							"\r\n",
							"results_consonants.show(5)"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Exercise 3.6\r\n",
							"Lets say you want to get both the count() and sum() of a GroupedData object. Why doesnt this code work? Map the inputs and outputs of each method.\r\n",
							"\r\n",
							"my_data_frame.groupby(\"my_column\").count().sum()"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"adls_path = \"abfss://learning@ivsdatastorage.dfs.core.windows.net/DataAnalysisPythonPySpark\"\r\n",
							" \r\n",
							"results = (\r\n",
							"    spark.read.text(adls_path + \"/data/gutenberg_books/1342-0.txt\")\r\n",
							"    .select(F.split(F.col(\"value\"), \" \").alias(\"line\"))\r\n",
							"    .select(F.explode(F.col(\"line\")).alias(\"word\"))\r\n",
							"    .select(F.lower(F.col(\"word\")).alias(\"word\"))\r\n",
							"    .select(F.regexp_extract(F.col(\"word\"), \"[a-z']*\", 0).alias(\"word\"))\r\n",
							"    .where(F.col(\"word\") != \"\")\r\n",
							"    .groupby(F.col(\"word\"))\r\n",
							"    .count()\r\n",
							"    .groupby(F.col(\"word\"))\r\n",
							"    .sum(\"count\")\r\n",
							")\r\n",
							"\r\n",
							"results.show()"
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ivssql')]",
			"type": "Microsoft.Synapse/workspaces/sqlPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"collation": "SQL_Latin1_General_CP1_CI_AS",
				"maxSizeBytes": 263882790666240,
				"annotations": []
			},
			"dependsOn": [],
			"location": "westus"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ivsspark')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 5
				},
				"autoScale": {
					"enabled": false,
					"maxNodeCount": 10,
					"minNodeCount": 3
				},
				"nodeCount": 3,
				"nodeSize": "Small",
				"nodeSizeFamily": "MemoryOptimized",
				"sparkVersion": "3.1",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": false,
				"annotations": []
			},
			"dependsOn": [],
			"location": "westus"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ServerlessObjectsDeploy')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "ForEachScript",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "ForEachInitScript",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "ForEachTextReplaceMap",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@variables('v_scripts')",
								"type": "Expression"
							},
							"isSequential": false,
							"activities": [
								{
									"name": "Run SQL Script",
									"type": "Script",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 2,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "serverless_ARIR",
										"type": "LinkedServiceReference",
										"parameters": {
											"p_database": "master"
										}
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "NonQuery",
												"text": {
													"value": "@replace(item().query, '{raw_storage_account}', pipeline().parameters.c_raw_storage_account)",
													"type": "Expression"
												}
											}
										]
									}
								}
							]
						}
					},
					{
						"name": "Copy SQL scripts",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "RestSource",
								"httpRequestTimeout": "00:01:40",
								"requestInterval": "00.00:00:00.010",
								"requestMethod": "GET",
								"paginationRules": {
									"AbsoluteUrl": "$.nextLink"
								}
							},
							"sink": {
								"type": "ParquetSink",
								"storeSettings": {
									"type": "AzureBlobFSWriteSettings"
								},
								"formatSettings": {
									"type": "ParquetWriteSettings"
								}
							},
							"enableStaging": false,
							"translator": {
								"type": "TabularTranslator",
								"mappings": [
									{
										"source": {
											"path": "['id']"
										},
										"sink": {
											"name": "id"
										}
									},
									{
										"source": {
											"path": "['name']"
										},
										"sink": {
											"name": "name"
										}
									},
									{
										"source": {
											"path": "['type']"
										},
										"sink": {
											"name": "type"
										}
									},
									{
										"source": {
											"path": "['etag']"
										},
										"sink": {
											"name": "etag"
										}
									},
									{
										"source": {
											"path": "['properties']['folder']['name']"
										},
										"sink": {
											"name": "folderName"
										}
									},
									{
										"source": {
											"path": "['properties']['content']['query']"
										},
										"sink": {
											"name": "query"
										}
									},
									{
										"source": {
											"path": "['properties']['content']['metadata']['language']"
										},
										"sink": {
											"name": "language"
										}
									},
									{
										"source": {
											"path": "['properties']['content']['currentConnection']['databaseName']"
										},
										"sink": {
											"name": "databaseName"
										}
									},
									{
										"source": {
											"path": "['properties']['content']['currentConnection']['poolName']"
										},
										"sink": {
											"name": "poolName"
										}
									},
									{
										"source": {
											"path": "['properties']['content']['resultLimit']"
										},
										"sink": {
											"name": "resultLimit"
										}
									},
									{
										"source": {
											"path": "['properties']['type']"
										},
										"sink": {
											"name": "connectionType"
										}
									}
								],
								"collectionReference": "$['value']"
							}
						},
						"inputs": [
							{
								"referenceName": "azuresynapse",
								"type": "DatasetReference",
								"parameters": {
									"p_workspace": {
										"value": "@pipeline().DataFactory",
										"type": "Expression"
									},
									"p_relative_url": "/sqlScripts/?api-version=2020-12-01"
								}
							}
						],
						"outputs": [
							{
								"referenceName": "GenericRawParquet",
								"type": "DatasetReference",
								"parameters": {
									"p_container": {
										"value": "@pipeline().parameters.c_raw_container",
										"type": "Expression"
									},
									"p_folder": {
										"value": "@pipeline().parameters.c_raw_folder",
										"type": "Expression"
									},
									"p_file": {
										"value": "@pipeline().parameters.c_raw_file",
										"type": "Expression"
									}
								}
							}
						]
					},
					{
						"name": "Filter Scripts",
						"type": "Script",
						"dependsOn": [
							{
								"activity": "Copy SQL scripts",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 2,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"linkedServiceName": {
							"referenceName": "serverless_ARIR",
							"type": "LinkedServiceReference",
							"parameters": {
								"p_database": "master"
							}
						},
						"typeProperties": {
							"scripts": [
								{
									"type": "Query",
									"text": {
										"value": "SELECT\n    *\nFROM\n    OPENROWSET(\n        BULK 'https://@{pipeline().parameters.c_raw_storage_account}.dfs.core.windows.net/@{pipeline().parameters.c_raw_container}/@{pipeline().parameters.c_raw_folder}/@{pipeline().parameters.c_raw_file}.parquet',\n        FORMAT = 'PARQUET'\n    ) \nWITH (id nvarchar(1000),\nname nvarchar(255),\ntype nvarchar(100),\netag nvarchar(100),\nfolderName nvarchar(1000),\nquery nvarchar(max),\nlanguage nvarchar(100),\ndatabaseName nvarchar(100),\npoolName nvarchar(100),\nresultLimit int,\nconnectionType nvarchar(100)\n) AS [result]\nwhere left(folderName, len('@{pipeline().parameters.c_script_folder}')) = '@{pipeline().parameters.c_script_folder}'\nand charindex('@{pipeline().parameters.c_init_script_suffix}', name) = 0",
										"type": "Expression"
									}
								}
							],
							"scriptBlockExecutionTimeout": "02:00:00"
						}
					},
					{
						"name": "Filter Init Scripts",
						"type": "Script",
						"dependsOn": [
							{
								"activity": "Copy SQL scripts",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "GenericRawParquet linked service",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"linkedServiceName": {
							"referenceName": "serverless_ARIR",
							"type": "LinkedServiceReference",
							"parameters": {
								"p_database": "master"
							}
						},
						"typeProperties": {
							"scripts": [
								{
									"type": "Query",
									"text": {
										"value": "SELECT\n    *\nFROM\n    OPENROWSET(\n        BULK '@{activity('GenericRawParquet linked service').output.properties.typeProperties.url}@{pipeline().parameters.c_raw_container}/@{pipeline().parameters.c_raw_folder}/@{pipeline().parameters.c_raw_file}.parquet',\n        FORMAT = 'PARQUET'\n    ) \nWITH (id nvarchar(1000),\nname nvarchar(255),\ntype nvarchar(100),\netag nvarchar(100),\nfolderName nvarchar(1000),\nquery nvarchar(max),\nlanguage nvarchar(100),\ndatabaseName nvarchar(100),\npoolName nvarchar(100),\nresultLimit int,\nconnectionType nvarchar(100)\n) AS [result]\nwhere left(folderName, len('@{pipeline().parameters.c_script_folder}')) = '@{pipeline().parameters.c_script_folder}'\nand charindex('@{pipeline().parameters.c_init_script_suffix}', name) > 0\n\nunion\n\nSELECT\n    *\nFROM\n    OPENROWSET(\n        BULK '@{activity('GenericRawParquet linked service').output.properties.typeProperties.url}@{pipeline().parameters.c_raw_container}/@{pipeline().parameters.c_raw_folder}/@{pipeline().parameters.c_raw_file}.parquet',\n        FORMAT = 'PARQUET'\n    ) \nWITH (id nvarchar(1000),\nname nvarchar(255),\ntype nvarchar(100),\netag nvarchar(100),\nfolderName nvarchar(1000),\nquery nvarchar(max),\nlanguage nvarchar(100),\ndatabaseName nvarchar(100),\npoolName nvarchar(100),\nresultLimit int,\nconnectionType nvarchar(100)\n) AS [result]\nwhere left(folderName, len('@{pipeline().parameters.c_script_folder}')) = '@{pipeline().parameters.c_script_folder}'\nand charindex('@{pipeline().parameters.c_init_script_suffix}', name) = 0\n\norder by name",
										"type": "Expression"
									}
								}
							],
							"scriptBlockExecutionTimeout": "02:00:00"
						}
					},
					{
						"name": "ForEachInitScript",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "ForEachTextReplaceMap Init",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@variables('v_scripts')",
								"type": "Expression"
							},
							"isSequential": false,
							"activities": [
								{
									"name": "Run Init Script",
									"type": "Script",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 2,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "serverless_ARIR",
										"type": "LinkedServiceReference",
										"parameters": {
											"p_database": "master"
										}
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "NonQuery",
												"text": {
													"value": "@item().query",
													"type": "Expression"
												}
											}
										]
									}
								}
							]
						}
					},
					{
						"name": "ForEachTextReplaceMap Init",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Set v_scripts Init",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@json(string(pipeline().parameters.c_text_replacement))",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "Set v_scripts_tmp Init",
									"type": "SetVariable",
									"dependsOn": [],
									"policy": {
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"variableName": "v_scripts_tmp",
										"value": {
											"value": "@replace(string(variables('v_scripts')), item().textToFind, item().textForReplace)",
											"type": "Expression"
										}
									}
								},
								{
									"name": "Update v_scripts Init",
									"type": "SetVariable",
									"dependsOn": [
										{
											"activity": "Set v_scripts_tmp Init",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"variableName": "v_scripts",
										"value": {
											"value": "@json(variables('v_scripts_tmp'))",
											"type": "Expression"
										}
									}
								}
							]
						}
					},
					{
						"name": "Set v_scripts Init",
						"type": "SetVariable",
						"dependsOn": [
							{
								"activity": "Filter Init Scripts",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"variableName": "v_scripts",
							"value": {
								"value": "@activity('Filter Init Scripts').output.resultSets[0].rows",
								"type": "Expression"
							}
						}
					},
					{
						"name": "ForEachTextReplaceMap",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Set v_scripts",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@json(string(pipeline().parameters.c_text_replacement))",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "Set v_scripts_tmp",
									"type": "SetVariable",
									"dependsOn": [],
									"policy": {
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"variableName": "v_scripts_tmp",
										"value": {
											"value": "@replace(string(variables('v_scripts')), item().textToFind, item().textForReplace)",
											"type": "Expression"
										}
									}
								},
								{
									"name": "Update v_scripts",
									"type": "SetVariable",
									"dependsOn": [
										{
											"activity": "Set v_scripts_tmp",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"variableName": "v_scripts",
										"value": {
											"value": "@json(variables('v_scripts_tmp'))",
											"type": "Expression"
										}
									}
								}
							]
						}
					},
					{
						"name": "Set v_scripts",
						"type": "SetVariable",
						"dependsOn": [
							{
								"activity": "Filter Scripts",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "ForEachInitScript",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"variableName": "v_scripts",
							"value": {
								"value": "@activity('Filter Scripts').output.resultSets[0].rows",
								"type": "Expression"
							}
						}
					},
					{
						"name": "GenericRawParquet attributes",
						"type": "WebActivity",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"method": "GET",
							"headers": {},
							"url": {
								"value": "@concat('https://', pipeline().DataFactory, '.dev.azuresynapse.net/datasets/GenericRawParquet?api-version=2020-12-01')",
								"type": "Expression"
							},
							"connectVia": {
								"referenceName": "SHIR",
								"type": "IntegrationRuntimeReference"
							},
							"authentication": {
								"type": "MSI",
								"resource": "https://dev.azuresynapse.net/"
							}
						}
					},
					{
						"name": "GenericRawParquet linked service",
						"type": "WebActivity",
						"dependsOn": [
							{
								"activity": "GenericRawParquet attributes",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"method": "GET",
							"headers": {},
							"url": {
								"value": "@concat('https://', pipeline().DataFactory, '.dev.azuresynapse.net/linkedservices/', activity('GenericRawParquet attributes').output.properties.linkedServiceName.referenceName, '?api-version=2020-12-01')",
								"type": "Expression"
							},
							"connectVia": {
								"referenceName": "SHIR",
								"type": "IntegrationRuntimeReference"
							},
							"authentication": {
								"type": "MSI",
								"resource": "https://dev.azuresynapse.net/"
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"c_script_folder": {
						"type": "string",
						"defaultValue": "Serverless Deploy"
					},
					"c_raw_container": {
						"type": "string",
						"defaultValue": "template"
					},
					"c_raw_folder": {
						"type": "string",
						"defaultValue": "ServerlessObjectsDeploy"
					},
					"c_raw_file": {
						"type": "string",
						"defaultValue": "sqlScripts"
					},
					"c_text_replacement": {
						"type": "string",
						"defaultValue": [
							{
								"textToFind": "{raw_storage_account}",
								"textForReplace": "kbsmoderndwdevrawst002"
							},
							{
								"textToFind": "{cur_storage_account}",
								"textForReplace": "kbsmoderndwdevcurst002"
							}
						]
					},
					"c_init_script_suffix": {
						"type": "string",
						"defaultValue": "_Init_"
					},
					"c_raw_storage_account": {
						"type": "string",
						"defaultValue": "kbsmoderndwdevrawst002"
					}
				},
				"variables": {
					"v_scripts_tmp": {
						"type": "String"
					},
					"v_scripts": {
						"type": "Array"
					}
				},
				"folder": {
					"name": "Templates"
				},
				"annotations": [],
				"lastPublishTime": "2023-10-16T14:41:01Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/azuresynapse')]",
				"[concat(variables('workspaceId'), '/datasets/GenericRawParquet')]",
				"[concat(variables('workspaceId'), '/linkedServices/serverless_ARIR')]",
				"[concat(variables('workspaceId'), '/integrationRuntimes/SHIR')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ZeroRow_Init_Copy1')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Serverless Deploy"
				},
				"content": {
					"query": "CREATE PROC [dbo].[ZeroRow]\n\t@p_tabname [varchar](255),\n\t@p_keycolname [varchar](255),\n\t@p_varchar [varchar](255),\n\t@p_numeric [tinyint],\n\t@p_date [date],\n\t@p_time [time],\n\t@p_bit [bit] \n\t\nAS\n\nDECLARE\n\t@v_return_status integer,\n\t@v_count bit = 0,\n\t@v_column_name varchar(255),\n\t@v_data_type varchar(255),\n\t@v_character_maximum_length integer,\n\t@v_is_nullable varchar(3),\n\t@v_notnull_conv varchar(255),\n\t@v_ins_sql_top varchar(max),\n\t@v_ins_sql_bottom varchar(max),\n\t@v_upd_sql varchar(max),\n\t@v_ctrl_sql nvarchar(max) = '',\n\t@v_sql nvarchar(max) = '',\n\t@v_sql_param nvarchar(max) = ''\n\nBEGIN\n    CREATE TABLE #tbl\n\tWITH\n\t( DISTRIBUTION = ROUND_ROBIN\n\t)\n\tAS\n\tselect \n\tROW_NUMBER() OVER(ORDER BY ordinal_position) AS sequence,\n\tcolumn_name,\n\tis_nullable,\n\tdata_type,\n\tcharacter_maximum_length\n\tfrom information_schema.columns\n\twhere table_name = @p_tabname\n\n\tDECLARE @v_loop_limit int = (SELECT COUNT(*) FROM #tbl)\n\t,       @v_i int = 1\n\n\tSET @v_ins_sql_top = '('\n\tSET @v_ins_sql_bottom = '('\n\tSET @v_upd_sql = ''\n\tSET @v_sql_param = N'@v_column_name varchar(255) OUTPUT, ' +\n\t\t\t\t\tN'@v_is_nullable varchar(3) OUTPUT, ' +\n\t\t\t\t\tN'@v_data_type varchar(255) OUTPUT, ' +\n\t\t\t\t\tN'@v_character_maximum_length integer OUTPUT'\n\n\tWHILE @v_i <= @v_loop_limit\n\t  BEGIN\n\n\t\tSET @v_sql = N'SELECT @v_column_name = column_name, ' +\n\t\t\tN'@v_is_nullable = is_nullable, ' +\n\t\t\tN'@v_data_type = data_type, ' +\n\t\t\tN'@v_character_maximum_length = character_maximum_length FROM #tbl WHERE sequence = ' + CAST(@v_i as nvarchar(20))\n\n\t\tEXECUTE sp_executesql @v_sql, @v_sql_param, \n\t\t\t\t\t\t\t\t@v_column_name OUTPUT, \n\t\t\t\t\t\t\t\t@v_is_nullable OUTPUT,\n\t\t\t\t\t\t\t\t@v_data_type OUTPUT, \n\t\t\t\t\t\t\t\t@v_character_maximum_length OUTPUT\n\n\t\tSET @v_ins_sql_top = @v_ins_sql_top + @v_column_name + char(13) + ', '\n\n\t\tIF (@v_data_type = 'char' or @v_data_type = 'varchar' \n\t\tor @v_data_type = 'text' or @v_data_type = 'nchar' \n\t\tor @v_data_type = 'nvarchar' or @v_data_type = 'ntext')\n\t\t\tBEGIN\n\t\t\t\tSET @v_ins_sql_bottom = @v_ins_sql_bottom + char(39) + LEFT(@p_varchar, @v_character_maximum_length) + char(39) + char(13) + ', '\n\t\t\t\tSET @v_upd_sql = @v_upd_sql + @v_column_name + ' = ' + char(39) + LEFT(@p_varchar, @v_character_maximum_length) + char(39) + char(13) + ', '\n\t\t\tEND\n\t\tELSE\n\t\t\tIF (@v_data_type = 'date' or @v_data_type = 'datetime' \n\t\t\tor @v_data_type = 'datetime2' or @v_data_type = 'datetimeoffset' \n\t\t\tor @v_data_type = 'smalldatetime') \n\t\t\tand (try_cast(@p_date as date) is not null \n\t\t\tor @v_column_name = 'DSS_UPDATE_TIME' or @v_column_name = 'DSS_CREATE_TIME')\n\t\t\t\tBEGIN\n\t\t\t\t\tIF @v_column_name = 'DSS_UPDATE_TIME'\n\t\t\t\t\t\tBEGIN\n\t\t\t\t\t\t\tSET @v_ins_sql_bottom = @v_ins_sql_bottom + char(39) + CONVERT(varchar, getdate(), 121) + char(39) + char(13) + ', '\n\t\t\t\t\t\t\tSET @v_upd_sql = @v_upd_sql + @v_column_name + ' = ' + char(39) + CONVERT(varchar, getdate(), 121) + char(39) + char(13) + ', '\n\t\t\t\t\t\tEND\n\t\t\t\t\tELSE\n\t\t\t\t\t\tBEGIN\n\t\t\t\t\t\t\tIF @v_column_name = 'DSS_CREATE_TIME'\n\t\t\t\t\t\t\t\tBEGIN\n\t\t\t\t\t\t\t\t\tSET @v_ins_sql_bottom = @v_ins_sql_bottom + char(39) + CONVERT(varchar, getdate(), 121) + char(39) + char(13) + ', '\n\t\t\t\t\t\t\t\t\tSET @v_upd_sql = @v_upd_sql + @v_column_name + ' = COALESCE(DSS_CREATE_TIME, getdate())' + char(13) + ', '\n\t\t\t\t\t\t\t\tEND\n\t\t\t\t\t\t\tELSE\n\t\t\t\t\t\t\t\tBEGIN\n\t\t\t\t\t\t\t\t\tSET @v_ins_sql_bottom = @v_ins_sql_bottom + char(39) + cast(@p_date as varchar) + char(39) + char(13) + ', '\n\t\t\t\t\t\t\t\t\tSET @v_upd_sql = @v_upd_sql + @v_column_name + ' = ' + char(39) + cast(@p_date as varchar) + char(39) + char(13) + ', '\n\t\t\t\t\t\t\t\tEND\n\t\t\t\t\t\tEND\n\t\t\t\tEND\n\t\t\tELSE\n\t\t\t\tIF @v_data_type = 'time' and try_cast(@p_time as time) is not null\n\t\t\t\t\tBEGIN\n\t\t\t\t\t\tSET @v_ins_sql_bottom = @v_ins_sql_bottom + char(39) + cast(@p_time as varchar) + char(39) + char(13) + ', '\n\t\t\t\t\t\tSET @v_upd_sql = @v_upd_sql + @v_column_name + ' = ' + char(39) + cast(@p_time as varchar) + char(39) + char(13) + ', '\n\t\t\t\t\tEND\n\t\t\t\tELSE\n\t\t\t\t\tIF (@v_data_type = 'bigint' or @v_data_type = 'numeric' \n\t\t\t\t\tor @v_data_type = 'smallint' or @v_data_type = 'decimal' \n\t\t\t\t\tor @v_data_type = 'smallmoney' or @v_data_type = 'int'\n\t\t\t\t\tor @v_data_type = 'tinyint' or @v_data_type = 'money'\n\t\t\t\t\tor @v_data_type = 'float' or @v_data_type = 'real') \n\t\t\t\t\tand try_cast(@p_numeric as tinyint) is not null\n\t\t\t\t\tand UPPER(@v_column_name) <> UPPER(@p_keycolname)\n\t\t\t\t\t\tBEGIN\n\t\t\t\t\t\t\tSET @v_ins_sql_bottom = @v_ins_sql_bottom + cast(@p_numeric as varchar) + char(13) + ', '\n\t\t\t\t\t\t\tSET @v_upd_sql = @v_upd_sql + @v_column_name + ' = ' + cast(@p_numeric as varchar) + char(13) + ', '\n\t\t\t\t\t\tEND\n\t\t\t\t\tELSE\n\t\t\t\t\t\tIF @v_data_type = 'bit' and try_cast(@p_bit as bit) is not null\n\t\t\t\t\t\t\tBEGIN\n\t\t\t\t\t\t\t\tSET @v_ins_sql_bottom = @v_ins_sql_bottom + cast(@p_bit as varchar) + char(13) + ', '\n\t\t\t\t\t\t\t\tSET @v_upd_sql = @v_upd_sql + @v_column_name + ' = ' + cast(@p_bit as varchar) + char(13) + ', '\n\t\t\t\t\t\t\tEND\n\t\t\t\t\t\tELSE\n\t\t\t\t\t\t\tBEGIN\n\t\t\t\t\t\t\t\tIF UPPER(@v_column_name) = @p_keycolname\n\t\t\t\t\t\t\t\t\tBEGIN\n\t\t\t\t\t\t\t\t\t\tSET @v_ins_sql_bottom = @v_ins_sql_bottom + '0' + char(13) + ', '\n\t\t\t\t\t\t\t\t\tEND\n\t\t\t\t\t\t\t\tELSE\n\t\t\t\t\t\t\t\t\tBEGIN\n\t\t\t\t\t\t\t\t\t\tIF @v_is_nullable = 'YES'\n\t\t\t\t\t\t\t\t\t\t\tBEGIN\n\t\t\t\t\t\t\t\t\t\t\t\tSET @v_ins_sql_bottom  = @v_ins_sql_bottom + 'NULL' + char(13) + ', '\n\t\t\t\t\t\t\t\t\t\t\t\tSET @v_upd_sql = @v_upd_sql + @v_column_name + ' = ' + 'NULL' + char(13) + ', '\n\t\t\t\t\t\t\t\t\t\t\tEND\n\t\t\t\t\t\t\t\t\t\tELSE\n\t\t\t\t\t\t\t\t\t\t\tBEGIN\n\t\t\t\t\t\t\t\t\t\t\t\tSET @v_ctrl_sql = N'select @v_val_conv = cast('+ char(39) + char(39) + ' as ' + @v_data_type + N')'\n\t\t\t\t\t\t\t\t\t\t\t\tEXECUTE sp_executesql @v_ctrl_sql, N'@v_val_conv varchar(255) OUTPUT', @v_notnull_conv OUTPUT\n\t\t\t\t\t\t\t\t\t\t\t\tSET @v_ins_sql_bottom  = @v_ins_sql_bottom + @v_notnull_conv + char(13) + ', '\n\t\t\t\t\t\t\t\t\t\t\t\tSET @v_upd_sql = @v_upd_sql + @v_column_name + ' = ' + char(39) + @v_notnull_conv + char(39) + char(13) + ', '\n\t\t\t\t\t\t\t\t\t\t\tEND\n\t\t\t\t\t\t\t\t\tEND\n\t\t\t\t\t\t\tEND\n\n\t\tSET @v_i += 1\n\n\t  END\n\n\tSET @v_ins_sql_top = LEFT(@v_ins_sql_top, LEN(@v_ins_sql_top) - 2) + ')'\n\tSET @v_ins_sql_bottom = LEFT(@v_ins_sql_bottom, LEN(@v_ins_sql_bottom) - 2) + ')'\n\tSET @v_upd_sql = LEFT(@v_upd_sql, LEN(@v_upd_sql) - 2)\n\n\tSET @v_ctrl_sql = N'SELECT @v_count_out = 1 FROM ' + @p_tabname + N' WHERE ' + @p_keycolname + N' = 0'\n\n\tEXECUTE sp_executesql @v_ctrl_sql, N'@v_count_out bit OUTPUT', @v_count OUTPUT\n\n\tSET @v_sql = N'BEGIN' + char(13) + char(13)\n\n\tIF @v_count = 0\n\t\tBEGIN\n\t\t\tSET @v_sql = @v_sql + N'SET IDENTITY_INSERT ' + @p_tabname + N' ON' + char(13) + char(13)\n\t\t\tSET @v_sql = @v_sql + N'INSERT INTO ' + @p_tabname + char(13) + @v_ins_sql_top + char(13)\n\t\t\tSET @v_sql = @v_sql + N'VALUES ' + @v_ins_sql_bottom + char(13) + char(13)\n\t\t\tSET @v_sql = @v_sql + N'SET IDENTITY_INSERT ' + @p_tabname + N' OFF' + char(13) + char(13)\n\t\tEND\n\n\tIF @v_count = 1\n\t\tBEGIN\n\t\t\tSET @v_sql = @v_sql + N'UPDATE ' + @p_tabname + char(13) + N'SET' + char(13) + @v_upd_sql + char(13)\n\t\t\tSET @v_sql = @v_sql + N'WHERE ' + @p_keycolname + N' = 0' + char(13) + char(13)\n\t\tEND\n\n\tSET @v_sql = @v_sql + N'END'\n\n\tEXECUTE sp_executesql @v_sql\n\n\tDROP TABLE #tbl\nEND\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "ivs_sqlpool",
						"poolName": "ivs_sqlpool"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		}
	]
}