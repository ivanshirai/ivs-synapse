{
	"name": "DimAllTime",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "ivsspark",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "8ee95e14-4220-4e97-91f0-9129b729ddcf"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/f939f8f3-2652-4a45-88ae-78a7782ec9df/resourceGroups/ivs-dwh-rg/providers/Microsoft.Synapse/workspaces/ivs-synapse/bigDataPools/ivsspark",
				"name": "ivsspark",
				"type": "Spark",
				"endpoint": "https://ivs-synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/ivsspark",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.1",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"Read csvs and create temp views"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"fiscal_year = spark.read.csv('abfss://spark@ivsdatastorage.dfs.core.windows.net/source/FiscalYear.csv', \r\n",
					"    header = True)\r\n",
					"\r\n",
					"fiscal_year.createOrReplaceTempView('fy_view')\r\n",
					"\r\n",
					"fiscal_period = spark.read.csv('abfss://spark@ivsdatastorage.dfs.core.windows.net/source/FiscalPeriod.csv', \r\n",
					"    header = True)\r\n",
					"\r\n",
					"fiscal_period.createOrReplaceTempView('fp_view')\r\n",
					""
				],
				"execution_count": 2
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"Create merged dataframe from temporary views"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"df_stg = spark.sql(\"SELECT concat(CALENDAR, ',YEAR,', FISCALYEAR) DIM_ALL_TIME_ID, \" +\r\n",
					"    \"'YEAR' GRAIN_LEVEL, \"+\r\n",
					"    \"CALENDAR, \" +\r\n",
					"    \"FISCALYEAR, \" +\r\n",
					"    \"CAST(STARTDATE as timestamp) STARTDATE, \" +\r\n",
					"    \"CAST(ENDDATE as timestamp) ENDDATE, \" +\r\n",
					"    \"NULL CALENDARTYPE, \" +\r\n",
					"    \"NULL QUARTER, \" +\r\n",
					"    \"NULL MONTH, \" +\r\n",
					"    \"NULL PERIODNAME, \" +\r\n",
					"    \"NULL SHORTNAME, \" +\r\n",
					"    \"NULL TYPE, \" +\r\n",
					"    \"NULL DAYS \" +\r\n",
					"    \"FROM fy_view \" +\r\n",
					"    \"UNION \" +\r\n",
					"    \"SELECT concat(CALENDAR, ',PERIOD,', FISCALYEAR, ',', replace(PERIODNAME, 'Period ', '')) DIM_ALL_TIME_ID, \" +\r\n",
					"    \"'PERIOD' GRAIN_LEVEL, \" +\r\n",
					"    \"CALENDAR, \" +\r\n",
					"    \"FISCALYEAR, \" +\r\n",
					"    \"CAST(STARTDATE as timestamp) STARTDATE, \" +\r\n",
					"    \"CAST(ENDDATE as timestamp) ENDDATE, \" +\r\n",
					"    \"CALENDARTYPE, \" +\r\n",
					"    \"QUARTER, \" +\r\n",
					"    \"MONTH, \" +\r\n",
					"    \"PERIODNAME, \" +\r\n",
					"    \"SHORTNAME, \" +\r\n",
					"    \"TYPE, \" +\r\n",
					"    \"DAYS \" +\r\n",
					"    \"FROM fp_view \")\r\n",
					"\r\n",
					"df_stg.show()"
				],
				"execution_count": 63
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"Add gregorian years and months"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"from pyspark.sql.functions import lit\r\n",
					"\r\n",
					"df_stg = df_stg.select(['*', lit(None).cast('integer').alias('CALYEAR'), \r\n",
					"    lit(None).cast('string').alias('CALMONTH'), \r\n",
					"    lit(None).cast('integer').alias('CALMONTH_NUM'), \r\n",
					"    lit(None).cast('integer').alias('CLOSEDMONTH')])\r\n",
					"\r\n",
					"from datetime import date\r\n",
					"\r\n",
					"for row in df_stg.where(\"CALENDAR = 'Fiscal' and GRAIN_LEVEL = 'YEAR'\").collect():\r\n",
					"    newrow = spark.createDataFrame([('Gegorian,YEAR,' + row['FISCALYEAR'], 'YEAR', 'Gregorian', row['FISCALYEAR'], row['FISCALYEAR'] + '-01-01', row['FISCALYEAR'] + '-12-31')],\r\n",
					"        ['DIM_ALL_TIME_ID', 'GRAIN_LEVEL', 'CALENDAR', 'CALYEAR', 'STARTDATE', 'ENDDATE'])\r\n",
					"    df_stg = df_stg.unionByName(newrow, allowMissingColumns=True)\r\n",
					"    for i in range(1, 13):\r\n",
					"        newrow = spark.createDataFrame([('Gegorian,MONTH,' + row['FISCALYEAR'] + f'{i:02}', 'MONTH', 'Gregorian', \r\n",
					"            row['FISCALYEAR'], row['FISCALYEAR'] + '-' + f'{i:02}' + '-01', \r\n",
					"            row['FISCALYEAR'] + '-' + f'{i:02}' + '-' + str(calendar.monthrange(int(row['FISCALYEAR']), i)[1]),\r\n",
					"            f'{i:02}', i, \r\n",
					"            1 if row['FISCALYEAR'] + '-' + f'{i:02}' + '-' + str(calendar.monthrange(int(row['FISCALYEAR']), i)[1]) < str(date.today()) else 0)],\r\n",
					"            ['DIM_ALL_TIME_ID', 'GRAIN_LEVEL', 'CALENDAR', 'CALYEAR', 'STARTDATE', 'ENDDATE', 'CALMONTH', 'CALMONTH_NUM', 'CLOSEDMONTH'])\r\n",
					"        df_stg = df_stg.unionByName(newrow, allowMissingColumns=True)\r\n",
					"\r\n",
					"\r\n",
					"df_stg.where(\"GRAIN_LEVEL = 'MONTH' and CALENDAR = 'Gregorian'\").show()"
				],
				"execution_count": 64
			}
		]
	}
}